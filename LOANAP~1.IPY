{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loan_Application =pd.read_csv('C:/Users/user/Desktop/IVY WORK BOOK/PYTHON/Python Datasets/Classification Datasets/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>611</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dependents     Education Self_Employed  ApplicantIncome  \\\n",
       "0            0      Graduate            No             5849   \n",
       "1            1      Graduate            No             4583   \n",
       "2            0      Graduate           Yes             3000   \n",
       "3            0  Not Graduate            No             2583   \n",
       "4            0      Graduate            No             6000   \n",
       "..         ...           ...           ...              ...   \n",
       "609          0      Graduate            No             2900   \n",
       "610         3+      Graduate            No             4106   \n",
       "611          1      Graduate            No             8072   \n",
       "612          2      Graduate            No             7583   \n",
       "613          0      Graduate           Yes             4583   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                  0.0         NaN             360.0             1.0   \n",
       "1               1508.0       128.0             360.0             1.0   \n",
       "2                  0.0        66.0             360.0             1.0   \n",
       "3               2358.0       120.0             360.0             1.0   \n",
       "4                  0.0       141.0             360.0             1.0   \n",
       "..                 ...         ...               ...             ...   \n",
       "609                0.0        71.0             360.0             1.0   \n",
       "610                0.0        40.0             180.0             1.0   \n",
       "611              240.0       253.0             360.0             1.0   \n",
       "612                0.0       187.0             360.0             1.0   \n",
       "613                0.0       133.0             360.0             0.0   \n",
       "\n",
       "    Property_Area Loan_Status  \n",
       "0           Urban           Y  \n",
       "1           Rural           N  \n",
       "2           Urban           Y  \n",
       "3           Urban           Y  \n",
       "4           Urban           Y  \n",
       "..            ...         ...  \n",
       "609         Rural           Y  \n",
       "610         Rural           Y  \n",
       "611         Urban           Y  \n",
       "612         Urban           Y  \n",
       "613     Semiurban           N  \n",
       "\n",
       "[614 rows x 10 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 10)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_Application.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing The Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>611</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dependents     Education Self_Employed  ApplicantIncome  \\\n",
       "1            1      Graduate            No             4583   \n",
       "2            0      Graduate           Yes             3000   \n",
       "3            0  Not Graduate            No             2583   \n",
       "4            0      Graduate            No             6000   \n",
       "5            2      Graduate           Yes             5417   \n",
       "..         ...           ...           ...              ...   \n",
       "609          0      Graduate            No             2900   \n",
       "610         3+      Graduate            No             4106   \n",
       "611          1      Graduate            No             8072   \n",
       "612          2      Graduate            No             7583   \n",
       "613          0      Graduate           Yes             4583   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "1               1508.0       128.0             360.0             1.0   \n",
       "2                  0.0        66.0             360.0             1.0   \n",
       "3               2358.0       120.0             360.0             1.0   \n",
       "4                  0.0       141.0             360.0             1.0   \n",
       "5               4196.0       267.0             360.0             1.0   \n",
       "..                 ...         ...               ...             ...   \n",
       "609                0.0        71.0             360.0             1.0   \n",
       "610                0.0        40.0             180.0             1.0   \n",
       "611              240.0       253.0             360.0             1.0   \n",
       "612                0.0       187.0             360.0             1.0   \n",
       "613                0.0       133.0             360.0             0.0   \n",
       "\n",
       "    Property_Area Loan_Status  \n",
       "1           Rural           N  \n",
       "2           Urban           Y  \n",
       "3           Urban           Y  \n",
       "4           Urban           Y  \n",
       "5           Urban           Y  \n",
       "..            ...         ...  \n",
       "609         Rural           Y  \n",
       "610         Rural           Y  \n",
       "611         Urban           Y  \n",
       "612         Urban           Y  \n",
       "613     Semiurban           N  \n",
       "\n",
       "[492 rows x 10 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_Application.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_Application.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filling The Null values\n",
    "\n",
    "Loan_Application['Self_Employed']=Loan_Application['Self_Employed'].interpolate(method='ffill')\n",
    "\n",
    "Loan_Application['LoanAmount']=Loan_Application['LoanAmount'].interpolate(method='linear')\n",
    "Loan_Application['LoanAmount'].fillna(Median, inplace=True)\n",
    "\n",
    "Loan_Application['Credit_History']=Loan_Application['Credit_History'].interpolate(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "Median= Loan_Application['LoanAmount'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dependents             4\n",
       "Education              2\n",
       "Self_Employed          2\n",
       "ApplicantIncome      505\n",
       "CoapplicantIncome    287\n",
       "LoanAmount           211\n",
       "Loan_Amount_Term      10\n",
       "Credit_History         2\n",
       "Property_Area          3\n",
       "Loan_Status            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_Application.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Dependents'={'1':1,'0':0,'2':2,'3+':3}\n",
    " Education  ={'Graduate':1,'Not Graduate':2}\n",
    "'Self_Employed ={'Yes':1,'No':0}\n",
    " Loan_Status={'Y':1,'N':0}\n",
    " Property_Area ={'Rural':1,'Semiurban':2,'Urban':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={'Rural':1,'Semiurban':2,'Urban':3}\n",
    "\n",
    "Loan_Application['Property_Area']=Loan_Application['Property_Area'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e27d1ecbc8>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Loan_Application.groupby('Loan_Status').size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loan_Application.drop(labels=['Married','Gender','Loan_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2333</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3036</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4006</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12841</td>\n",
       "      <td>10968.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200</td>\n",
       "      <td>700.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3073</td>\n",
       "      <td>8106.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1853</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1299</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5955</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3365</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3717</td>\n",
       "      <td>2925.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2799</td>\n",
       "      <td>2253.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4226</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3750</td>\n",
       "      <td>2083.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4166</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3500</td>\n",
       "      <td>1667.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12500</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2275</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1828</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3667</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4166</td>\n",
       "      <td>7210.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3748</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3941</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2645</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dependents  Education  Self_Employed  ApplicantIncome  CoapplicantIncome  \\\n",
       "0          0.0          1            0.0             5849                0.0   \n",
       "1          1.0          1            0.0             4583             1508.0   \n",
       "2          0.0          1            1.0             3000                0.0   \n",
       "3          0.0          2            0.0             2583             2358.0   \n",
       "4          0.0          1            0.0             6000                0.0   \n",
       "5          2.0          1            1.0             5417             4196.0   \n",
       "6          0.0          2            0.0             2333             1516.0   \n",
       "7          3.0          1            0.0             3036             2504.0   \n",
       "8          2.0          1            0.0             4006             1526.0   \n",
       "9          1.0          1            0.0            12841            10968.0   \n",
       "10         2.0          1            0.0             3200              700.0   \n",
       "11         2.0          1            0.0             2500             1840.0   \n",
       "12         2.0          1            0.0             3073             8106.0   \n",
       "13         0.0          1            0.0             1853             2840.0   \n",
       "14         2.0          1            0.0             1299             1086.0   \n",
       "15         0.0          1            0.0             4950                0.0   \n",
       "16         1.0          2            0.0             3596                0.0   \n",
       "17         0.0          1            0.0             3510                0.0   \n",
       "18         0.0          2            0.0             4887                0.0   \n",
       "19         0.0          1            0.0             2600             3500.0   \n",
       "20         0.0          2            0.0             7660                0.0   \n",
       "21         1.0          1            0.0             5955             5625.0   \n",
       "22         0.0          2            0.0             2600             1911.0   \n",
       "23         2.0          2            0.0             3365             1917.0   \n",
       "24         1.0          1            0.0             3717             2925.0   \n",
       "25         0.0          1            1.0             9560                0.0   \n",
       "26         0.0          1            0.0             2799             2253.0   \n",
       "27         2.0          2            0.0             4226             1040.0   \n",
       "28         0.0          2            0.0             1442                0.0   \n",
       "29         2.0          1            0.0             3750             2083.0   \n",
       "30         1.0          1            0.0             4166             3369.0   \n",
       "31         0.0          1            0.0             3167                0.0   \n",
       "32         1.0          1            1.0             4692                0.0   \n",
       "33         0.0          1            0.0             3500             1667.0   \n",
       "34         3.0          1            0.0            12500             3000.0   \n",
       "35         0.0          1            0.0             2275             2067.0   \n",
       "36         0.0          1            0.0             1828             1330.0   \n",
       "37         0.0          1            0.0             3667             1459.0   \n",
       "38         0.0          1            0.0             4166             7210.0   \n",
       "39         0.0          2            0.0             3748             1668.0   \n",
       "40         0.0          1            0.0             3600                0.0   \n",
       "41         0.0          1            0.0             1800             1213.0   \n",
       "42         0.0          1            0.0             2400                0.0   \n",
       "43         0.0          1            0.0             3941             2336.0   \n",
       "44         0.0          2            1.0             4695                0.0   \n",
       "45         0.0          1            0.0             3410                0.0   \n",
       "46         1.0          1            0.0             5649                0.0   \n",
       "47         0.0          1            0.0             5821                0.0   \n",
       "48         0.0          1            0.0             2645             3440.0   \n",
       "49         0.0          1            0.0             4000             2275.0   \n",
       "\n",
       "    LoanAmount  Loan_Amount_Term  Credit_History  Property_Area  Loan_Status  \n",
       "0        128.0             360.0             1.0              3            1  \n",
       "1        128.0             360.0             1.0              1            0  \n",
       "2         66.0             360.0             1.0              3            1  \n",
       "3        120.0             360.0             1.0              3            1  \n",
       "4        141.0             360.0             1.0              3            1  \n",
       "5        267.0             360.0             1.0              3            1  \n",
       "6         95.0             360.0             1.0              3            1  \n",
       "7        158.0             360.0             0.0              2            0  \n",
       "8        168.0             360.0             1.0              3            1  \n",
       "9        349.0             360.0             1.0              2            0  \n",
       "10        70.0             360.0             1.0              3            1  \n",
       "11       109.0             360.0             1.0              3            1  \n",
       "12       200.0             360.0             1.0              3            1  \n",
       "13       114.0             360.0             1.0              1            0  \n",
       "14        17.0             120.0             1.0              3            1  \n",
       "15       125.0             360.0             1.0              3            1  \n",
       "16       100.0             240.0             1.0              3            1  \n",
       "17        76.0             360.0             0.0              3            0  \n",
       "18       133.0             360.0             1.0              1            0  \n",
       "19       115.0             360.0             1.0              3            1  \n",
       "20       104.0             360.0             0.0              3            0  \n",
       "21       315.0             360.0             1.0              3            1  \n",
       "22       116.0             360.0             0.0              2            0  \n",
       "23       112.0             360.0             0.0              1            0  \n",
       "24       151.0             360.0             0.0              2            0  \n",
       "25       191.0             360.0             1.0              2            1  \n",
       "26       122.0             360.0             1.0              2            1  \n",
       "27       110.0             360.0             1.0              3            1  \n",
       "28        35.0             360.0             1.0              3            0  \n",
       "29       120.0             360.0             1.0              2            1  \n",
       "30       201.0             360.0             1.0              3            0  \n",
       "31        74.0             360.0             1.0              3            0  \n",
       "32       106.0             360.0             1.0              1            0  \n",
       "33       114.0             360.0             1.0              2            1  \n",
       "34       320.0             360.0             1.0              1            0  \n",
       "35       210.0             360.0             1.0              3            1  \n",
       "36       100.0             360.0             0.0              3            0  \n",
       "37       144.0             360.0             1.0              2            1  \n",
       "38       184.0             360.0             1.0              3            1  \n",
       "39       110.0             360.0             1.0              2            1  \n",
       "40        80.0             360.0             1.0              3            0  \n",
       "41        47.0             360.0             1.0              3            1  \n",
       "42        75.0             360.0             1.0              3            1  \n",
       "43       134.0             360.0             1.0              2            1  \n",
       "44        96.0             360.0             1.0              3            1  \n",
       "45        88.0             360.0             1.0              3            1  \n",
       "46        44.0             360.0             1.0              3            1  \n",
       "47       144.0             360.0             1.0              3            1  \n",
       "48       120.0             360.0             0.0              3            0  \n",
       "49       144.0             360.0             1.0              2            1  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_Application.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['Dependents','Education','Self_Employed','Loan_Amount_Term','Credit_History','Property_Area']\n",
    "cont_cols=['ApplicantIncome','CoapplicantIncome','LoanAmount']\n",
    "targetvar=['Loan_Status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.760586</td>\n",
       "      <td>1.218241</td>\n",
       "      <td>0.140065</td>\n",
       "      <td>5403.459283</td>\n",
       "      <td>1621.245798</td>\n",
       "      <td>146.883550</td>\n",
       "      <td>341.628664</td>\n",
       "      <td>0.835505</td>\n",
       "      <td>2.037459</td>\n",
       "      <td>0.687296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.012005</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>0.347338</td>\n",
       "      <td>6109.041673</td>\n",
       "      <td>2926.248369</td>\n",
       "      <td>85.559996</td>\n",
       "      <td>65.656819</td>\n",
       "      <td>0.371027</td>\n",
       "      <td>0.787482</td>\n",
       "      <td>0.463973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2877.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3812.500000</td>\n",
       "      <td>1188.500000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5795.000000</td>\n",
       "      <td>2297.250000</td>\n",
       "      <td>166.750000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81000.000000</td>\n",
       "      <td>41667.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dependents   Education  Self_Employed  ApplicantIncome  \\\n",
       "count  614.000000  614.000000     614.000000       614.000000   \n",
       "mean     0.760586    1.218241       0.140065      5403.459283   \n",
       "std      1.012005    0.413389       0.347338      6109.041673   \n",
       "min      0.000000    1.000000       0.000000       150.000000   \n",
       "25%      0.000000    1.000000       0.000000      2877.500000   \n",
       "50%      0.000000    1.000000       0.000000      3812.500000   \n",
       "75%      2.000000    1.000000       0.000000      5795.000000   \n",
       "max      3.000000    2.000000       1.000000     81000.000000   \n",
       "\n",
       "       CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "count         614.000000  614.000000        614.000000      614.000000   \n",
       "mean         1621.245798  146.883550        341.628664        0.835505   \n",
       "std          2926.248369   85.559996         65.656819        0.371027   \n",
       "min             0.000000    9.000000         12.000000        0.000000   \n",
       "25%             0.000000  100.000000        360.000000        1.000000   \n",
       "50%          1188.500000  128.000000        360.000000        1.000000   \n",
       "75%          2297.250000  166.750000        360.000000        1.000000   \n",
       "max         41667.000000  700.000000        480.000000        1.000000   \n",
       "\n",
       "       Property_Area  Loan_Status  \n",
       "count     614.000000   614.000000  \n",
       "mean        2.037459     0.687296  \n",
       "std         0.787482     0.463973  \n",
       "min         1.000000     0.000000  \n",
       "25%         1.000000     0.000000  \n",
       "50%         2.000000     1.000000  \n",
       "75%         3.000000     1.000000  \n",
       "max         3.000000     1.000000  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_Application.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the pattern of the Continous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, sub=plt.subplots(1, len(cont_cols), figsize=(20,5))\n",
    "for j, plotNumber in zip(cont_cols, range(len(cont_cols))):\n",
    "    Loan_Application[j].hist(figsize=(15,6), ax=sub[plotNumber])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the pattern of the Categorical  variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, sub=plt.subplots(1, len(cat_cols), figsize=(20,5))\n",
    "for colName, plotNumber in zip(cat_cols, range(len(cat_cols))):\n",
    "    Loan_Application.groupby(colName).size().plot(kind='bar',ax=sub[plotNumber])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e27ba95108>"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Loan_Application.corrwith(Loan_Application['ApplicantIncome'], axis=0).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the relationship with Target categorical variable with Continuos Variable(Anova Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "The p values is  0.3368599712937531\n",
      "The p value of ApplicantIncome is not releated with Target Variable\n",
      "************************************************************\n",
      "The p values is  0.09626571920549604\n",
      "The p value of CoapplicantIncome is not releated with Target Variable\n",
      "************************************************************\n",
      "The p values is  0.42717214790080216\n",
      "The p value of LoanAmount is not releated with Target Variable\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "for j in cont_cols:\n",
    "    print('*'*60)\n",
    "    Annovacategory=Loan_Application.groupby('Loan_Status')[j].apply(list)\n",
    "    Annovaresult=f_oneway(*Annovacategory)\n",
    "    print(\"The p values is \", Annovaresult[1])\n",
    "    if(Annovaresult[1]<0.05):\n",
    "        print(\"The p value of\",j,\"is releated with Target Variable\")\n",
    "    else:\n",
    "        print(\"The p value of\",j,\"is not releated with Target Variable\")\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the relationship with Target categorical variable with categorical Variable(chi square Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//////////////////////////////////////////////////\n",
      "The p value of Dependents is 0.8118285101579282\n",
      "The p value of Dependents is not releated with Target Variable\n",
      "//////////////////////////////////////////////////\n",
      "The p value of Education is 1.0\n",
      "The p value of Education is not releated with Target Variable\n",
      "//////////////////////////////////////////////////\n",
      "The p value of Self_Employed is 1.0\n",
      "The p value of Self_Employed is not releated with Target Variable\n",
      "//////////////////////////////////////////////////\n",
      "The p value of Loan_Amount_Term is 1.0\n",
      "The p value of Loan_Amount_Term is not releated with Target Variable\n",
      "//////////////////////////////////////////////////\n",
      "The p value of Credit_History is 1.0\n",
      "The p value of Credit_History is not releated with Target Variable\n",
      "//////////////////////////////////////////////////\n",
      "The p value of Property_Area is 0.013657949752221248\n",
      "The p value of Property_Area is releated with Target Variable\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "for j in cat_cols:\n",
    "    print('/'*50)\n",
    "    crosstabresult=pd.crosstab(index=Loan_Application[j],columns=Loan_Application['Loan_Status'])\n",
    "    crosstabresult.plot.bar(figsize=(10,3), color=['green','blue'])\n",
    "    ChiSqResult = chi2_contingency(crosstabresult)\n",
    "    print(\"The p value of\",j,\"is\",  ChiSqResult[1])\n",
    "    if(ChiSqResult[1]<0.05):\n",
    "        print(\"The p value of\",j,\"is releated with Target Variable\")\n",
    "    else:\n",
    "        print(\"The p value of\",j,\"is not releated with Target Variable\")\n",
    "        \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detecting and treating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependents              2.00\n",
      "Education               0.00\n",
      "Self_Employed           0.00\n",
      "ApplicantIncome      2917.50\n",
      "CoapplicantIncome    2297.25\n",
      "LoanAmount             66.75\n",
      "Loan_Amount_Term        0.00\n",
      "Credit_History          0.00\n",
      "Property_Area           2.00\n",
      "Loan_Status             1.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Q1=Loan_Application.quantile(0.25)\n",
    "Q3=Loan_Application.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loan_Application=Loan_Application[~((Loan_Application<(Q1-1.5*IQR))|(Loan_Application>(Q3+1.5*IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.609023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4047.116541</td>\n",
       "      <td>1399.925263</td>\n",
       "      <td>131.359023</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.093985</td>\n",
       "      <td>0.823308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.934331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1823.707730</td>\n",
       "      <td>1449.149372</td>\n",
       "      <td>49.313857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.768852</td>\n",
       "      <td>0.382127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2807.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3621.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4819.750000</td>\n",
       "      <td>2269.500000</td>\n",
       "      <td>159.750000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>5625.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "count  266.000000      266.0          266.0       266.000000   \n",
       "mean     0.609023        1.0            0.0      4047.116541   \n",
       "std      0.934331        0.0            0.0      1823.707730   \n",
       "min      0.000000        1.0            0.0       150.000000   \n",
       "25%      0.000000        1.0            0.0      2807.500000   \n",
       "50%      0.000000        1.0            0.0      3621.000000   \n",
       "75%      1.000000        1.0            0.0      4819.750000   \n",
       "max      3.000000        1.0            0.0     10000.000000   \n",
       "\n",
       "       CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "count         266.000000  266.000000             266.0           266.0   \n",
       "mean         1399.925263  131.359023             360.0             1.0   \n",
       "std          1449.149372   49.313857               0.0             0.0   \n",
       "min             0.000000    9.000000             360.0             1.0   \n",
       "25%             0.000000  100.000000             360.0             1.0   \n",
       "50%          1436.000000  126.500000             360.0             1.0   \n",
       "75%          2269.500000  159.750000             360.0             1.0   \n",
       "max          5625.000000  265.000000             360.0             1.0   \n",
       "\n",
       "       Property_Area  Loan_Status  \n",
       "count     266.000000   266.000000  \n",
       "mean        2.093985     0.823308  \n",
       "std         0.768852     0.382127  \n",
       "min         1.000000     0.000000  \n",
       "25%         1.250000     1.000000  \n",
       "50%         2.000000     1.000000  \n",
       "75%         3.000000     1.000000  \n",
       "max         3.000000     1.000000  "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_Application.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loan_Application_ml=pd.read_pickle('C:/Users/user/Desktop/IVY WORK BOOK/PYTHON/pickle files/Loan_Application_ml.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e27ec27d88>"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Loan_Application.boxplot(column='LoanAmount', by='Loan_Status', figsize=(15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cols=['Property_Area','CoapplicantIncome','LoanAmount','Credit_History']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting the data into train and test and proceed with the different Machine Learning Algorithm to Asses Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictorvar=['Property_Area','CoapplicantIncome','LoanAmount','Credit_History','Education']\n",
    "Targetvariable=['Loan_Status']\n",
    "\n",
    "X=Loan_Application_ml[Predictorvar].values\n",
    "y=Loan_Application_ml[Targetvariable].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression(Data1,Data2):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    Test_size=[0.30,0.20,0.23,0.26,0.33,0.36,0.42,0.45]\n",
    "    Random_state=[521457,50,32578,5,2567,4789,8547,657]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            lgf=LogisticRegression(C=2,penalty='l2', solver='liblinear')\n",
    "            predictModel=lgf.fit(X_train,y_train)\n",
    "            predictions=predictModel.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy)   \n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.76      1.00      0.87        61\n",
      "\n",
      "    accuracy                           0.76        80\n",
      "   macro avg       0.38      0.50      0.43        80\n",
      "weighted avg       0.58      0.76      0.66        80\n",
      "\n",
      "[[ 0 19]\n",
      " [ 0 61]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.78      1.00      0.87        62\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.39      0.50      0.44        80\n",
      "weighted avg       0.60      0.78      0.68        80\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 62]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.81      1.00      0.90        65\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.41      0.50      0.45        80\n",
      "weighted avg       0.66      0.81      0.73        80\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 65]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      1.00      0.90        66\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.41      0.50      0.45        80\n",
      "weighted avg       0.68      0.82      0.75        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 66]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.83      1.00      0.91        45\n",
      "\n",
      "    accuracy                           0.83        54\n",
      "   macro avg       0.42      0.50      0.45        54\n",
      "weighted avg       0.69      0.83      0.76        54\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 45]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.76      1.00      0.86        41\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.38      0.50      0.43        54\n",
      "weighted avg       0.58      0.76      0.66        54\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 41]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      1.00      0.92        46\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.43      0.50      0.46        54\n",
      "weighted avg       0.73      0.85      0.78        54\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.83      1.00      0.91        45\n",
      "\n",
      "    accuracy                           0.83        54\n",
      "   macro avg       0.42      0.50      0.45        54\n",
      "weighted avg       0.69      0.83      0.76        54\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 45]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.81      1.00      0.90        44\n",
      "\n",
      "    accuracy                           0.81        54\n",
      "   macro avg       0.41      0.50      0.45        54\n",
      "weighted avg       0.66      0.81      0.73        54\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 44]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      1.00      0.92        46\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.43      0.50      0.46        54\n",
      "weighted avg       0.73      0.85      0.78        54\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      1.00      0.92        46\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.43      0.50      0.46        54\n",
      "weighted avg       0.73      0.85      0.78        54\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      1.00      0.92        46\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.43      0.50      0.46        54\n",
      "weighted avg       0.73      0.85      0.78        54\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.77      1.00      0.87        48\n",
      "\n",
      "    accuracy                           0.77        62\n",
      "   macro avg       0.39      0.50      0.44        62\n",
      "weighted avg       0.60      0.77      0.68        62\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 48]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.79      1.00      0.88        49\n",
      "\n",
      "    accuracy                           0.79        62\n",
      "   macro avg       0.40      0.50      0.44        62\n",
      "weighted avg       0.62      0.79      0.70        62\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 49]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.85      1.00      0.92        53\n",
      "\n",
      "    accuracy                           0.85        62\n",
      "   macro avg       0.43      0.50      0.46        62\n",
      "weighted avg       0.73      0.85      0.79        62\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 53]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.82      1.00      0.90        51\n",
      "\n",
      "    accuracy                           0.82        62\n",
      "   macro avg       0.41      0.50      0.45        62\n",
      "weighted avg       0.68      0.82      0.74        62\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0 51]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.81      1.00      0.89        50\n",
      "\n",
      "    accuracy                           0.81        62\n",
      "   macro avg       0.40      0.50      0.45        62\n",
      "weighted avg       0.65      0.81      0.72        62\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 50]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.84      1.00      0.91        52\n",
      "\n",
      "    accuracy                           0.84        62\n",
      "   macro avg       0.42      0.50      0.46        62\n",
      "weighted avg       0.70      0.84      0.77        62\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 52]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.82      1.00      0.90        51\n",
      "\n",
      "    accuracy                           0.82        62\n",
      "   macro avg       0.41      0.50      0.45        62\n",
      "weighted avg       0.68      0.82      0.74        62\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0 51]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.87      1.00      0.93        54\n",
      "\n",
      "    accuracy                           0.87        62\n",
      "   macro avg       0.44      0.50      0.47        62\n",
      "weighted avg       0.76      0.87      0.81        62\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 54]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.77      1.00      0.87        54\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.39      0.50      0.44        70\n",
      "weighted avg       0.60      0.77      0.67        70\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 54]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.77      1.00      0.87        54\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.39      0.50      0.44        70\n",
      "weighted avg       0.60      0.77      0.67        70\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 54]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 32578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.86      1.00      0.92        60\n",
      "\n",
      "    accuracy                           0.86        70\n",
      "   macro avg       0.43      0.50      0.46        70\n",
      "weighted avg       0.73      0.86      0.79        70\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 60]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      1.00      0.91        58\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.69      0.83      0.75        70\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      1.00      0.91        58\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.69      0.83      0.75        70\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.81      1.00      0.90        57\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.66      0.81      0.73        70\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 57]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      1.00      0.91        58\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.69      0.83      0.75        70\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.87      1.00      0.93        61\n",
      "\n",
      "    accuracy                           0.87        70\n",
      "   macro avg       0.44      0.50      0.47        70\n",
      "weighted avg       0.76      0.87      0.81        70\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 61]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.76      1.00      0.86        67\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.38      0.50      0.43        88\n",
      "weighted avg       0.58      0.76      0.66        88\n",
      "\n",
      "[[ 0 21]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.78      1.00      0.88        69\n",
      "\n",
      "    accuracy                           0.78        88\n",
      "   macro avg       0.39      0.50      0.44        88\n",
      "weighted avg       0.61      0.78      0.69        88\n",
      "\n",
      "[[ 0 19]\n",
      " [ 0 69]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.85      1.00      0.92        75\n",
      "\n",
      "    accuracy                           0.85        88\n",
      "   macro avg       0.43      0.50      0.46        88\n",
      "weighted avg       0.73      0.85      0.78        88\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 75]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.80      1.00      0.89        70\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.40      0.50      0.44        88\n",
      "weighted avg       0.63      0.80      0.70        88\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 70]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.84      1.00      0.91        74\n",
      "\n",
      "    accuracy                           0.84        88\n",
      "   macro avg       0.42      0.50      0.46        88\n",
      "weighted avg       0.71      0.84      0.77        88\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 74]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      1.00      0.91        73\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.69      0.83      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      1.00      0.91        73\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.69      0.83      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      1.00      0.91        73\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.69      0.83      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.76      1.00      0.86        73\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.38      0.50      0.43        96\n",
      "weighted avg       0.58      0.76      0.66        96\n",
      "\n",
      "[[ 0 23]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.79      1.00      0.88        76\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.40      0.50      0.44        96\n",
      "weighted avg       0.63      0.79      0.70        96\n",
      "\n",
      "[[ 0 20]\n",
      " [ 0 76]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.85      1.00      0.92        82\n",
      "\n",
      "    accuracy                           0.85        96\n",
      "   macro avg       0.43      0.50      0.46        96\n",
      "weighted avg       0.73      0.85      0.79        96\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 82]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.81      1.00      0.90        78\n",
      "\n",
      "    accuracy                           0.81        96\n",
      "   macro avg       0.41      0.50      0.45        96\n",
      "weighted avg       0.66      0.81      0.73        96\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 78]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      1.00      0.91        80\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.42      0.50      0.45        96\n",
      "weighted avg       0.69      0.83      0.76        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 80]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      1.00      0.92        81\n",
      "\n",
      "    accuracy                           0.84        96\n",
      "   macro avg       0.42      0.50      0.46        96\n",
      "weighted avg       0.71      0.84      0.77        96\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 81]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      1.00      0.92        81\n",
      "\n",
      "    accuracy                           0.84        96\n",
      "   macro avg       0.42      0.50      0.46        96\n",
      "weighted avg       0.71      0.84      0.77        96\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 81]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      1.00      0.91        80\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.42      0.50      0.45        96\n",
      "weighted avg       0.69      0.83      0.76        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 80]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.79      1.00      0.88        88\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.39      0.50      0.44       112\n",
      "weighted avg       0.62      0.79      0.69       112\n",
      "\n",
      "[[ 0 24]\n",
      " [ 0 88]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.80      1.00      0.89        90\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.40      0.50      0.45       112\n",
      "weighted avg       0.65      0.80      0.72       112\n",
      "\n",
      "[[ 0 22]\n",
      " [ 0 90]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      1.00      0.92        95\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.42      0.50      0.46       112\n",
      "weighted avg       0.72      0.85      0.78       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 0 95]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.82      1.00      0.90        92\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.41      0.50      0.45       112\n",
      "weighted avg       0.67      0.82      0.74       112\n",
      "\n",
      "[[ 0 20]\n",
      " [ 0 92]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.82      1.00      0.90        92\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.41      0.50      0.45       112\n",
      "weighted avg       0.67      0.82      0.74       112\n",
      "\n",
      "[[ 0 20]\n",
      " [ 0 92]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.84      1.00      0.91        94\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.42      0.50      0.46       112\n",
      "weighted avg       0.70      0.84      0.77       112\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 94]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      1.00      0.92        95\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.42      0.50      0.46       112\n",
      "weighted avg       0.72      0.85      0.78       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 0 95]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      1.00      0.92        95\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.42      0.50      0.46       112\n",
      "weighted avg       0.72      0.85      0.78       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 0 95]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.78      1.00      0.88        94\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.39      0.50      0.44       120\n",
      "weighted avg       0.61      0.78      0.69       120\n",
      "\n",
      "[[ 0 26]\n",
      " [ 0 94]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.80      1.00      0.89        96\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.40      0.50      0.44       120\n",
      "weighted avg       0.64      0.80      0.71       120\n",
      "\n",
      "[[ 0 24]\n",
      " [ 0 96]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.83      1.00      0.91       100\n",
      "\n",
      "    accuracy                           0.83       120\n",
      "   macro avg       0.42      0.50      0.45       120\n",
      "weighted avg       0.69      0.83      0.76       120\n",
      "\n",
      "[[  0  20]\n",
      " [  0 100]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.82      1.00      0.90        98\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.41      0.50      0.45       120\n",
      "weighted avg       0.67      0.82      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 0 98]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.82      1.00      0.90        98\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.41      0.50      0.45       120\n",
      "weighted avg       0.67      0.82      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 0 98]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.84      1.00      0.91       101\n",
      "\n",
      "    accuracy                           0.84       120\n",
      "   macro avg       0.42      0.50      0.46       120\n",
      "weighted avg       0.71      0.84      0.77       120\n",
      "\n",
      "[[  0  19]\n",
      " [  0 101]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.83      1.00      0.91       100\n",
      "\n",
      "    accuracy                           0.83       120\n",
      "   macro avg       0.42      0.50      0.45       120\n",
      "weighted avg       0.69      0.83      0.76       120\n",
      "\n",
      "[[  0  20]\n",
      " [  0 100]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.86      1.00      0.92       103\n",
      "\n",
      "    accuracy                           0.86       120\n",
      "   macro avg       0.43      0.50      0.46       120\n",
      "weighted avg       0.74      0.86      0.79       120\n",
      "\n",
      "[[  0  17]\n",
      " [  0 103]]\n",
      "Accuracy is  0.79\n",
      "The Average of All acuracies 0.7420312499999999\n"
     ]
    }
   ],
   "source": [
    "length,AVGAccuracy=Logistic_Regression(X,y)\n",
    "Sum_of_Acc=sum(AVGAccuracy)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc/length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_Tree_classification(Data1,Data2):\n",
    "    Test_size=[0.30,0.20,0.23,0.26,0.33,0.36,0.42,0.45]\n",
    "    Random_state=[521457,50,32578,5,2567,4789,8547,657]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            dtree=tree.DecisionTreeClassifier(max_depth=3,criterion='entropy')\n",
    "            predictModeltree=dtree.fit(X_train,y_train)\n",
    "            predictions=predictModeltree.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy,predictModeltree)  \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.76      1.00      0.87        61\n",
      "\n",
      "    accuracy                           0.76        80\n",
      "   macro avg       0.38      0.50      0.43        80\n",
      "weighted avg       0.58      0.76      0.66        80\n",
      "\n",
      "[[ 0 19]\n",
      " [ 0 61]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.77      0.95      0.85        62\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.38      0.48      0.42        80\n",
      "weighted avg       0.59      0.74      0.66        80\n",
      "\n",
      "[[ 0 18]\n",
      " [ 3 59]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      0.99      0.90        67\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.42      0.49      0.45        80\n",
      "weighted avg       0.70      0.82      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 1 66]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.07      0.08        15\n",
      "           1       0.80      0.88      0.84        65\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.46      0.47      0.46        80\n",
      "weighted avg       0.67      0.72      0.70        80\n",
      "\n",
      "[[ 1 14]\n",
      " [ 8 57]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.83      0.96      0.89        67\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.42      0.48      0.44        80\n",
      "weighted avg       0.70      0.80      0.74        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 3 64]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      0.97      0.89        66\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.41      0.48      0.44        80\n",
      "weighted avg       0.68      0.80      0.73        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 2 64]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      0.99      0.90        67\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.42      0.49      0.45        80\n",
      "weighted avg       0.70      0.82      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 1 66]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.11      0.12         9\n",
      "           1       0.83      0.87      0.85        45\n",
      "\n",
      "    accuracy                           0.74        54\n",
      "   macro avg       0.49      0.49      0.49        54\n",
      "weighted avg       0.72      0.74      0.73        54\n",
      "\n",
      "[[ 1  8]\n",
      " [ 6 39]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.75      0.93      0.83        41\n",
      "\n",
      "    accuracy                           0.70        54\n",
      "   macro avg       0.37      0.46      0.41        54\n",
      "weighted avg       0.57      0.70      0.63        54\n",
      "\n",
      "[[ 0 13]\n",
      " [ 3 38]]\n",
      "Accuracy is  0.63\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      1.00      0.92        46\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.43      0.50      0.46        54\n",
      "weighted avg       0.73      0.85      0.78        54\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.81      0.87      0.84        45\n",
      "\n",
      "    accuracy                           0.72        54\n",
      "   macro avg       0.41      0.43      0.42        54\n",
      "weighted avg       0.68      0.72      0.70        54\n",
      "\n",
      "[[ 0  9]\n",
      " [ 6 39]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.81      1.00      0.90        44\n",
      "\n",
      "    accuracy                           0.81        54\n",
      "   macro avg       0.41      0.50      0.45        54\n",
      "weighted avg       0.66      0.81      0.73        54\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 44]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      1.00      0.92        46\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.43      0.50      0.46        54\n",
      "weighted avg       0.73      0.85      0.78        54\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.84      0.93      0.89        46\n",
      "\n",
      "    accuracy                           0.80        54\n",
      "   macro avg       0.42      0.47      0.44        54\n",
      "weighted avg       0.72      0.80      0.76        54\n",
      "\n",
      "[[ 0  8]\n",
      " [ 3 43]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.2 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      1.00      0.92        46\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.43      0.50      0.46        54\n",
      "weighted avg       0.73      0.85      0.78        54\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.07      0.10        14\n",
      "           1       0.76      0.88      0.82        48\n",
      "\n",
      "    accuracy                           0.69        62\n",
      "   macro avg       0.45      0.47      0.46        62\n",
      "weighted avg       0.62      0.69      0.65        62\n",
      "\n",
      "[[ 1 13]\n",
      " [ 6 42]]\n",
      "Accuracy is  0.65\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.79      0.98      0.87        49\n",
      "\n",
      "    accuracy                           0.77        62\n",
      "   macro avg       0.39      0.49      0.44        62\n",
      "weighted avg       0.62      0.77      0.69        62\n",
      "\n",
      "[[ 0 13]\n",
      " [ 1 48]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.11      0.15         9\n",
      "           1       0.86      0.94      0.90        53\n",
      "\n",
      "    accuracy                           0.82        62\n",
      "   macro avg       0.56      0.53      0.53        62\n",
      "weighted avg       0.77      0.82      0.79        62\n",
      "\n",
      "[[ 1  8]\n",
      " [ 3 50]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.80      0.88      0.84        51\n",
      "\n",
      "    accuracy                           0.73        62\n",
      "   macro avg       0.40      0.44      0.42        62\n",
      "weighted avg       0.66      0.73      0.69        62\n",
      "\n",
      "[[ 0 11]\n",
      " [ 6 45]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.81      1.00      0.89        50\n",
      "\n",
      "    accuracy                           0.81        62\n",
      "   macro avg       0.40      0.50      0.45        62\n",
      "weighted avg       0.65      0.81      0.72        62\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 50]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.84      1.00      0.91        52\n",
      "\n",
      "    accuracy                           0.84        62\n",
      "   macro avg       0.42      0.50      0.46        62\n",
      "weighted avg       0.70      0.84      0.77        62\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 52]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.09      0.13        11\n",
      "           1       0.82      0.92      0.87        51\n",
      "\n",
      "    accuracy                           0.77        62\n",
      "   macro avg       0.51      0.51      0.50        62\n",
      "weighted avg       0.71      0.77      0.74        62\n",
      "\n",
      "[[ 1 10]\n",
      " [ 4 47]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.23 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.87      0.98      0.92        54\n",
      "\n",
      "    accuracy                           0.85        62\n",
      "   macro avg       0.43      0.49      0.46        62\n",
      "weighted avg       0.76      0.85      0.80        62\n",
      "\n",
      "[[ 0  8]\n",
      " [ 1 53]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.06      0.09        16\n",
      "           1       0.76      0.89      0.82        54\n",
      "\n",
      "    accuracy                           0.70        70\n",
      "   macro avg       0.45      0.48      0.45        70\n",
      "weighted avg       0.62      0.70      0.65        70\n",
      "\n",
      "[[ 1 15]\n",
      " [ 6 48]]\n",
      "Accuracy is  0.65\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.77      0.98      0.86        54\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.38      0.49      0.43        70\n",
      "weighted avg       0.59      0.76      0.66        70\n",
      "\n",
      "[[ 0 16]\n",
      " [ 1 53]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.10      0.14        10\n",
      "           1       0.86      0.95      0.90        60\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.56      0.53      0.52        70\n",
      "weighted avg       0.78      0.83      0.80        70\n",
      "\n",
      "[[ 1  9]\n",
      " [ 3 57]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.08      0.10        12\n",
      "           1       0.82      0.88      0.85        58\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.47      0.48      0.48        70\n",
      "weighted avg       0.70      0.74      0.72        70\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 11]\n",
      " [ 7 51]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      1.00      0.91        58\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.69      0.83      0.75        70\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.81      0.95      0.87        57\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.40      0.47      0.44        70\n",
      "weighted avg       0.66      0.77      0.71        70\n",
      "\n",
      "[[ 0 13]\n",
      " [ 3 54]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      0.98      0.90        58\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.41      0.49      0.45        70\n",
      "weighted avg       0.68      0.81      0.74        70\n",
      "\n",
      "[[ 0 12]\n",
      " [ 1 57]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.87      0.98      0.92        61\n",
      "\n",
      "    accuracy                           0.86        70\n",
      "   macro avg       0.43      0.49      0.46        70\n",
      "weighted avg       0.76      0.86      0.80        70\n",
      "\n",
      "[[ 0  9]\n",
      " [ 1 60]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.05      0.08        21\n",
      "           1       0.76      0.96      0.85        67\n",
      "\n",
      "    accuracy                           0.74        88\n",
      "   macro avg       0.51      0.50      0.46        88\n",
      "weighted avg       0.64      0.74      0.66        88\n",
      "\n",
      "[[ 1 20]\n",
      " [ 3 64]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.77      0.94      0.85        69\n",
      "\n",
      "    accuracy                           0.74        88\n",
      "   macro avg       0.39      0.47      0.42        88\n",
      "weighted avg       0.61      0.74      0.67        88\n",
      "\n",
      "[[ 0 19]\n",
      " [ 4 65]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.85      1.00      0.92        75\n",
      "\n",
      "    accuracy                           0.85        88\n",
      "   macro avg       0.43      0.50      0.46        88\n",
      "weighted avg       0.73      0.85      0.78        88\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 75]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.06      0.07        18\n",
      "           1       0.78      0.89      0.83        70\n",
      "\n",
      "    accuracy                           0.72        88\n",
      "   macro avg       0.45      0.47      0.45        88\n",
      "weighted avg       0.65      0.72      0.68        88\n",
      "\n",
      "[[ 1 17]\n",
      " [ 8 62]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.84      0.97      0.90        74\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.42      0.49      0.45        88\n",
      "weighted avg       0.70      0.82      0.76        88\n",
      "\n",
      "[[ 0 14]\n",
      " [ 2 72]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.99      0.90        73\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.41      0.49      0.45        88\n",
      "weighted avg       0.69      0.82      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 1 72]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.81      0.89      0.85        73\n",
      "\n",
      "    accuracy                           0.74        88\n",
      "   macro avg       0.41      0.45      0.42        88\n",
      "weighted avg       0.67      0.74      0.70        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 8 65]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.13      0.24        15\n",
      "           1       0.85      1.00      0.92        73\n",
      "\n",
      "    accuracy                           0.85        88\n",
      "   macro avg       0.92      0.57      0.58        88\n",
      "weighted avg       0.87      0.85      0.80        88\n",
      "\n",
      "[[ 2 13]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.04      0.07        23\n",
      "           1       0.76      0.96      0.85        73\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.51      0.50      0.46        96\n",
      "weighted avg       0.64      0.74      0.66        96\n",
      "\n",
      "[[ 1 22]\n",
      " [ 3 70]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.79      0.99      0.88        76\n",
      "\n",
      "    accuracy                           0.78        96\n",
      "   macro avg       0.39      0.49      0.44        96\n",
      "weighted avg       0.62      0.78      0.69        96\n",
      "\n",
      "[[ 0 20]\n",
      " [ 1 75]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.07      0.09        14\n",
      "           1       0.85      0.90      0.88        82\n",
      "\n",
      "    accuracy                           0.78        96\n",
      "   macro avg       0.48      0.49      0.48        96\n",
      "weighted avg       0.74      0.78      0.76        96\n",
      "\n",
      "[[ 1 13]\n",
      " [ 8 74]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.06      0.07        18\n",
      "           1       0.80      0.90      0.85        78\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.46      0.48      0.46        96\n",
      "weighted avg       0.67      0.74      0.70        96\n",
      "\n",
      "[[ 1 17]\n",
      " [ 8 70]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.06      0.08        16\n",
      "           1       0.83      0.90      0.86        80\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.47      0.48      0.47        96\n",
      "weighted avg       0.71      0.76      0.73        96\n",
      "\n",
      "[[ 1 15]\n",
      " [ 8 72]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      0.98      0.90        81\n",
      "\n",
      "    accuracy                           0.82        96\n",
      "   macro avg       0.42      0.49      0.45        96\n",
      "weighted avg       0.71      0.82      0.76        96\n",
      "\n",
      "[[ 0 15]\n",
      " [ 2 79]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.88      0.85        81\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.41      0.44      0.43        96\n",
      "weighted avg       0.70      0.74      0.72        96\n",
      "\n",
      "[[ 0 15]\n",
      " [10 71]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      0.99      0.90        80\n",
      "\n",
      "    accuracy                           0.82        96\n",
      "   macro avg       0.42      0.49      0.45        96\n",
      "weighted avg       0.69      0.82      0.75        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 1 79]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.04      0.07        24\n",
      "           1       0.79      0.95      0.86        88\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.49      0.50      0.47       112\n",
      "weighted avg       0.66      0.76      0.69       112\n",
      "\n",
      "[[ 1 23]\n",
      " [ 4 84]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.09      0.13        22\n",
      "           1       0.81      0.92      0.86        90\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.51      0.51      0.49       112\n",
      "weighted avg       0.69      0.76      0.72       112\n",
      "\n",
      "[[ 2 20]\n",
      " [ 7 83]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      0.98      0.91        95\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.42      0.49      0.45       112\n",
      "weighted avg       0.72      0.83      0.77       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 2 93]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.05      0.07        20\n",
      "           1       0.82      0.91      0.86        92\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.46      0.48      0.47       112\n",
      "weighted avg       0.69      0.76      0.72       112\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 19]\n",
      " [ 8 84]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.82      0.98      0.89        92\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.41      0.49      0.45       112\n",
      "weighted avg       0.67      0.80      0.73       112\n",
      "\n",
      "[[ 0 20]\n",
      " [ 2 90]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.83      0.95      0.89        94\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.42      0.47      0.44       112\n",
      "weighted avg       0.70      0.79      0.74       112\n",
      "\n",
      "[[ 0 18]\n",
      " [ 5 89]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.84      0.97      0.90        95\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.42      0.48      0.45       112\n",
      "weighted avg       0.72      0.82      0.77       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 3 92]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.06      0.10        17\n",
      "           1       0.85      0.97      0.91        95\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.55      0.51      0.50       112\n",
      "weighted avg       0.76      0.83      0.78       112\n",
      "\n",
      "[[ 1 16]\n",
      " [ 3 92]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.04      0.06        26\n",
      "           1       0.78      0.95      0.86        94\n",
      "\n",
      "    accuracy                           0.75       120\n",
      "   macro avg       0.47      0.49      0.46       120\n",
      "weighted avg       0.65      0.75      0.68       120\n",
      "\n",
      "[[ 1 25]\n",
      " [ 5 89]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.04      0.08        24\n",
      "           1       0.81      0.99      0.89        96\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.65      0.52      0.48       120\n",
      "weighted avg       0.74      0.80      0.73       120\n",
      "\n",
      "[[ 1 23]\n",
      " [ 1 95]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.83      1.00      0.91       100\n",
      "\n",
      "    accuracy                           0.83       120\n",
      "   macro avg       0.42      0.50      0.45       120\n",
      "weighted avg       0.69      0.83      0.76       120\n",
      "\n",
      "[[  0  20]\n",
      " [  0 100]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.81      0.98      0.89        98\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.41      0.49      0.44       120\n",
      "weighted avg       0.66      0.80      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 2 96]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.81      0.98      0.89        98\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.41      0.49      0.44       120\n",
      "weighted avg       0.66      0.80      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 2 96]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.84      0.98      0.90       101\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.42      0.49      0.45       120\n",
      "weighted avg       0.71      0.82      0.76       120\n",
      "\n",
      "[[ 0 19]\n",
      " [ 2 99]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.82      0.89      0.85       100\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.41      0.45      0.43       120\n",
      "weighted avg       0.68      0.74      0.71       120\n",
      "\n",
      "[[ 0 20]\n",
      " [11 89]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.06      0.10        17\n",
      "           1       0.86      0.97      0.91       103\n",
      "\n",
      "    accuracy                           0.84       120\n",
      "   macro avg       0.56      0.51      0.50       120\n",
      "weighted avg       0.78      0.84      0.80       120\n",
      "\n",
      "[[  1  16]\n",
      " [  3 100]]\n",
      "Accuracy is  0.80\n",
      "The Average of All acuracies 0.7301562499999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x271e7e4cd48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length,AVGAccuracy,predictModeltree=Decision_Tree_classification(X,y)\n",
    "Sum_of_Acc_Dtree=sum(AVGAccuracy)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc_Dtree/length))\n",
    "feautreimportance=pd.Series(predictModeltree.feature_importances_, index=Predictorvar)\n",
    "feautreimportance.nlargest(10).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_classifier(Data1,Data2):\n",
    "    Test_size=[0.30,0.25,0.21,0.26,0.33,0.36,0.42,0.45]\n",
    "    Random_state=[521457,7505,32578,5,2567,4789,8547,657]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            RFC =RandomForestClassifier(max_depth=3, n_estimators=300,criterion='entropy')\n",
    "            predictModel=RFC.fit(X_train,y_train)\n",
    "            predictions=predictModel.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy, RFC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.76      1.00      0.87        61\n",
      "\n",
      "    accuracy                           0.76        80\n",
      "   macro avg       0.38      0.50      0.43        80\n",
      "weighted avg       0.58      0.76      0.66        80\n",
      "\n",
      "[[ 0 19]\n",
      " [ 0 61]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      1.00      0.90        66\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.41      0.50      0.45        80\n",
      "weighted avg       0.68      0.82      0.75        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 66]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.81      1.00      0.90        65\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.41      0.50      0.45        80\n",
      "weighted avg       0.66      0.81      0.73        80\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 65]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      1.00      0.90        66\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.41      0.50      0.45        80\n",
      "weighted avg       0.68      0.82      0.75        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 66]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.76      1.00      0.86        51\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.38      0.50      0.43        67\n",
      "weighted avg       0.58      0.76      0.66        67\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 51]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.82      1.00      0.90        55\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.41      0.50      0.45        67\n",
      "weighted avg       0.67      0.82      0.74        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 55]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.87      1.00      0.93        58\n",
      "\n",
      "    accuracy                           0.87        67\n",
      "   macro avg       0.43      0.50      0.46        67\n",
      "weighted avg       0.75      0.87      0.80        67\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.82      1.00      0.90        55\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.41      0.50      0.45        67\n",
      "weighted avg       0.67      0.82      0.74        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 55]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.82      1.00      0.90        55\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.41      0.50      0.45        67\n",
      "weighted avg       0.67      0.82      0.74        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 55]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.81      1.00      0.89        54\n",
      "\n",
      "    accuracy                           0.81        67\n",
      "   macro avg       0.40      0.50      0.45        67\n",
      "weighted avg       0.65      0.81      0.72        67\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 54]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.84      1.00      0.91        56\n",
      "\n",
      "    accuracy                           0.84        67\n",
      "   macro avg       0.42      0.50      0.46        67\n",
      "weighted avg       0.70      0.84      0.76        67\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0 56]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.88      1.00      0.94        59\n",
      "\n",
      "    accuracy                           0.88        67\n",
      "   macro avg       0.44      0.50      0.47        67\n",
      "weighted avg       0.78      0.88      0.82        67\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 59]]\n",
      "Accuracy is  0.82\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.82      1.00      0.90        46\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.41      0.50      0.45        56\n",
      "weighted avg       0.67      0.82      0.74        56\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.82      1.00      0.90        46\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.41      0.50      0.45        56\n",
      "weighted avg       0.67      0.82      0.74        56\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 32578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.86      1.00      0.92        48\n",
      "\n",
      "    accuracy                           0.86        56\n",
      "   macro avg       0.43      0.50      0.46        56\n",
      "weighted avg       0.73      0.86      0.79        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 48]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      1.00      0.91        47\n",
      "\n",
      "    accuracy                           0.84        56\n",
      "   macro avg       0.42      0.50      0.46        56\n",
      "weighted avg       0.70      0.84      0.77        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 47]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.80      1.00      0.89        45\n",
      "\n",
      "    accuracy                           0.80        56\n",
      "   macro avg       0.40      0.50      0.45        56\n",
      "weighted avg       0.65      0.80      0.72        56\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0 45]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.86      1.00      0.92        48\n",
      "\n",
      "    accuracy                           0.86        56\n",
      "   macro avg       0.43      0.50      0.46        56\n",
      "weighted avg       0.73      0.86      0.79        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 48]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      1.00      0.91        47\n",
      "\n",
      "    accuracy                           0.84        56\n",
      "   macro avg       0.42      0.50      0.46        56\n",
      "weighted avg       0.70      0.84      0.77        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 47]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.86      1.00      0.92        48\n",
      "\n",
      "    accuracy                           0.86        56\n",
      "   macro avg       0.43      0.50      0.46        56\n",
      "weighted avg       0.73      0.86      0.79        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 48]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.77      1.00      0.87        54\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.39      0.50      0.44        70\n",
      "weighted avg       0.60      0.77      0.67        70\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 54]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.81      1.00      0.90        57\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.66      0.81      0.73        70\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 57]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.86      1.00      0.92        60\n",
      "\n",
      "    accuracy                           0.86        70\n",
      "   macro avg       0.43      0.50      0.46        70\n",
      "weighted avg       0.73      0.86      0.79        70\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 60]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      1.00      0.91        58\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.69      0.83      0.75        70\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      1.00      0.91        58\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.69      0.83      0.75        70\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.81      1.00      0.90        57\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.66      0.81      0.73        70\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 57]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      1.00      0.91        58\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.41      0.50      0.45        70\n",
      "weighted avg       0.69      0.83      0.75        70\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.26 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.87      1.00      0.93        61\n",
      "\n",
      "    accuracy                           0.87        70\n",
      "   macro avg       0.44      0.50      0.47        70\n",
      "weighted avg       0.76      0.87      0.81        70\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 61]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.76      1.00      0.86        67\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.38      0.50      0.43        88\n",
      "weighted avg       0.58      0.76      0.66        88\n",
      "\n",
      "[[ 0 21]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.80      1.00      0.89        70\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.40      0.50      0.44        88\n",
      "weighted avg       0.63      0.80      0.70        88\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 70]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.85      1.00      0.92        75\n",
      "\n",
      "    accuracy                           0.85        88\n",
      "   macro avg       0.43      0.50      0.46        88\n",
      "weighted avg       0.73      0.85      0.78        88\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 75]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.80      1.00      0.89        70\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.40      0.50      0.44        88\n",
      "weighted avg       0.63      0.80      0.70        88\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 70]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.84      1.00      0.91        74\n",
      "\n",
      "    accuracy                           0.84        88\n",
      "   macro avg       0.42      0.50      0.46        88\n",
      "weighted avg       0.71      0.84      0.77        88\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 74]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      1.00      0.91        73\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.69      0.83      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      1.00      0.91        73\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.69      0.83      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      1.00      0.91        73\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.69      0.83      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.76      1.00      0.86        73\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.38      0.50      0.43        96\n",
      "weighted avg       0.58      0.76      0.66        96\n",
      "\n",
      "[[ 0 23]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.80      1.00      0.89        77\n",
      "\n",
      "    accuracy                           0.80        96\n",
      "   macro avg       0.40      0.50      0.45        96\n",
      "weighted avg       0.64      0.80      0.71        96\n",
      "\n",
      "[[ 0 19]\n",
      " [ 0 77]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.85      1.00      0.92        82\n",
      "\n",
      "    accuracy                           0.85        96\n",
      "   macro avg       0.43      0.50      0.46        96\n",
      "weighted avg       0.73      0.85      0.79        96\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 82]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.81      1.00      0.90        78\n",
      "\n",
      "    accuracy                           0.81        96\n",
      "   macro avg       0.41      0.50      0.45        96\n",
      "weighted avg       0.66      0.81      0.73        96\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 78]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      0.99      0.90        80\n",
      "\n",
      "    accuracy                           0.82        96\n",
      "   macro avg       0.42      0.49      0.45        96\n",
      "weighted avg       0.69      0.82      0.75        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 1 79]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      1.00      0.92        81\n",
      "\n",
      "    accuracy                           0.84        96\n",
      "   macro avg       0.42      0.50      0.46        96\n",
      "weighted avg       0.71      0.84      0.77        96\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 81]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      1.00      0.92        81\n",
      "\n",
      "    accuracy                           0.84        96\n",
      "   macro avg       0.42      0.50      0.46        96\n",
      "weighted avg       0.71      0.84      0.77        96\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 81]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      1.00      0.91        80\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.42      0.50      0.45        96\n",
      "weighted avg       0.69      0.83      0.76        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 80]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.79      1.00      0.88        88\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.39      0.50      0.44       112\n",
      "weighted avg       0.62      0.79      0.69       112\n",
      "\n",
      "[[ 0 24]\n",
      " [ 0 88]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.80      1.00      0.89        90\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.40      0.50      0.45       112\n",
      "weighted avg       0.65      0.80      0.72       112\n",
      "\n",
      "[[ 0 22]\n",
      " [ 0 90]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      1.00      0.92        95\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.42      0.50      0.46       112\n",
      "weighted avg       0.72      0.85      0.78       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 0 95]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.82      0.99      0.90        92\n",
      "\n",
      "    accuracy                           0.81       112\n",
      "   macro avg       0.41      0.49      0.45       112\n",
      "weighted avg       0.67      0.81      0.74       112\n",
      "\n",
      "[[ 0 20]\n",
      " [ 1 91]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.82      0.98      0.89        92\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.41      0.49      0.45       112\n",
      "weighted avg       0.67      0.80      0.73       112\n",
      "\n",
      "[[ 0 20]\n",
      " [ 2 90]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.84      1.00      0.91        94\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.42      0.50      0.46       112\n",
      "weighted avg       0.70      0.84      0.77       112\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 94]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      1.00      0.92        95\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.42      0.50      0.46       112\n",
      "weighted avg       0.72      0.85      0.78       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 0 95]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      0.99      0.91        95\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.42      0.49      0.46       112\n",
      "weighted avg       0.72      0.84      0.77       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 1 94]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.78      1.00      0.88        94\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.39      0.50      0.44       120\n",
      "weighted avg       0.61      0.78      0.69       120\n",
      "\n",
      "[[ 0 26]\n",
      " [ 0 94]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.82      1.00      0.90        98\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.41      0.50      0.45       120\n",
      "weighted avg       0.67      0.82      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 0 98]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.83      1.00      0.91       100\n",
      "\n",
      "    accuracy                           0.83       120\n",
      "   macro avg       0.42      0.50      0.45       120\n",
      "weighted avg       0.69      0.83      0.76       120\n",
      "\n",
      "[[  0  20]\n",
      " [  0 100]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.82      0.99      0.89        98\n",
      "\n",
      "    accuracy                           0.81       120\n",
      "   macro avg       0.41      0.49      0.45       120\n",
      "weighted avg       0.67      0.81      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 1 97]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.81      0.98      0.89        98\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.41      0.49      0.44       120\n",
      "weighted avg       0.66      0.80      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 2 96]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.84      1.00      0.91       101\n",
      "\n",
      "    accuracy                           0.84       120\n",
      "   macro avg       0.42      0.50      0.46       120\n",
      "weighted avg       0.71      0.84      0.77       120\n",
      "\n",
      "[[  0  19]\n",
      " [  0 101]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.83      1.00      0.91       100\n",
      "\n",
      "    accuracy                           0.83       120\n",
      "   macro avg       0.42      0.50      0.45       120\n",
      "weighted avg       0.69      0.83      0.76       120\n",
      "\n",
      "[[  0  20]\n",
      " [  0 100]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.86      1.00      0.92       103\n",
      "\n",
      "    accuracy                           0.86       120\n",
      "   macro avg       0.43      0.50      0.46       120\n",
      "weighted avg       0.74      0.86      0.79       120\n",
      "\n",
      "[[  0  17]\n",
      " [  0 103]]\n",
      "Accuracy is  0.79\n",
      "The Average of All acuracies 0.7459374999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x271e849e7c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length,AVGAccuracy,RF=RandomForest_classifier(X,y)\n",
    "Sum_of_Acc_Dtree=sum(AVGAccuracy)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc_Dtree/length))\n",
    "feautreimportance=pd.Series(RF.feature_importances_, index=Predictorvar)\n",
    "feautreimportance.nlargest(10).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adaboost_Classifier(Data1,Data2):\n",
    "    Test_size=[0.30,0.25,0.21,0.22,0.33,0.36,0.42,0.45,0.34]\n",
    "    Random_state=[521457,7505,32578,5,2567,4789,8547,657,42]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            DTC=DecisionTreeClassifier(max_depth=5)\n",
    "            ADA = AdaBoostClassifier(n_estimators=150, base_estimator=DTC ,learning_rate=0.01)\n",
    "            predictModel=ADA.fit(X_train,y_train)\n",
    "            predictions=predictModel.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy,ADA ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.21      0.28        19\n",
      "           1       0.79      0.90      0.84        61\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.59      0.56      0.56        80\n",
      "weighted avg       0.69      0.74      0.71        80\n",
      "\n",
      "[[ 4 15]\n",
      " [ 6 55]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15        14\n",
      "           1       0.82      0.85      0.84        66\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.50      0.50      0.49        80\n",
      "weighted avg       0.71      0.72      0.72        80\n",
      "\n",
      "[[ 2 12]\n",
      " [10 56]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.31      0.33        13\n",
      "           1       0.87      0.90      0.88        67\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.62      0.60      0.61        80\n",
      "weighted avg       0.79      0.80      0.79        80\n",
      "\n",
      "[[ 4  9]\n",
      " [ 7 60]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.79      0.86      0.82        65\n",
      "\n",
      "    accuracy                           0.70        80\n",
      "   macro avg       0.39      0.43      0.41        80\n",
      "weighted avg       0.64      0.70      0.67        80\n",
      "\n",
      "[[ 0 15]\n",
      " [ 9 56]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.11        13\n",
      "           1       0.84      0.93      0.88        67\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.50      0.50      0.49        80\n",
      "weighted avg       0.73      0.79      0.75        80\n",
      "\n",
      "[[ 1 12]\n",
      " [ 5 62]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      0.94      0.87        66\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.41      0.47      0.44        80\n",
      "weighted avg       0.67      0.78      0.72        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 4 62]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31        13\n",
      "           1       0.87      0.87      0.87        67\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.59      0.59      0.59        80\n",
      "weighted avg       0.77      0.77      0.77        80\n",
      "\n",
      "[[ 4  9]\n",
      " [ 9 58]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.15      0.15        13\n",
      "           1       0.84      0.84      0.84        67\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.49      0.49      0.49        80\n",
      "weighted avg       0.72      0.72      0.72        80\n",
      "\n",
      "[[ 2 11]\n",
      " [11 56]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.29      0.33        17\n",
      "           1       0.82      0.87      0.85        63\n",
      "\n",
      "    accuracy                           0.75        80\n",
      "   macro avg       0.60      0.58      0.59        80\n",
      "weighted avg       0.73      0.75      0.74        80\n",
      "\n",
      "[[ 5 12]\n",
      " [ 8 55]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.06      0.09        16\n",
      "           1       0.75      0.90      0.82        51\n",
      "\n",
      "    accuracy                           0.70        67\n",
      "   macro avg       0.46      0.48      0.46        67\n",
      "weighted avg       0.61      0.70      0.65        67\n",
      "\n",
      "[[ 1 15]\n",
      " [ 5 46]]\n",
      "Accuracy is  0.65\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.11        12\n",
      "           1       0.82      0.91      0.86        55\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.70      0.76      0.73        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 5 50]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.33      0.29         9\n",
      "           1       0.89      0.84      0.87        58\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.57      0.59      0.58        67\n",
      "weighted avg       0.80      0.78      0.79        67\n",
      "\n",
      "[[ 3  6]\n",
      " [ 9 49]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.80      0.87      0.83        55\n",
      "\n",
      "    accuracy                           0.72        67\n",
      "   macro avg       0.40      0.44      0.42        67\n",
      "weighted avg       0.66      0.72      0.69        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 7 48]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.08      0.12        12\n",
      "           1       0.82      0.93      0.87        55\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.51      0.51      0.49        67\n",
      "weighted avg       0.71      0.78      0.74        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 4 51]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.78      0.87      0.82        54\n",
      "\n",
      "    accuracy                           0.70        67\n",
      "   macro avg       0.39      0.44      0.41        67\n",
      "weighted avg       0.63      0.70      0.66        67\n",
      "\n",
      "[[ 0 13]\n",
      " [ 7 47]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.09      0.11        11\n",
      "           1       0.83      0.89      0.86        56\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.49      0.49      0.49        67\n",
      "weighted avg       0.72      0.76      0.74        67\n",
      "\n",
      "[[ 1 10]\n",
      " [ 6 50]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.12      0.10         8\n",
      "           1       0.87      0.80      0.83        59\n",
      "\n",
      "    accuracy                           0.72        67\n",
      "   macro avg       0.47      0.46      0.46        67\n",
      "weighted avg       0.78      0.72      0.74        67\n",
      "\n",
      "[[ 1  7]\n",
      " [12 47]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.27      0.32        15\n",
      "           1       0.81      0.88      0.84        52\n",
      "\n",
      "    accuracy                           0.75        67\n",
      "   macro avg       0.60      0.58      0.58        67\n",
      "weighted avg       0.72      0.75      0.73        67\n",
      "\n",
      "[[ 4 11]\n",
      " [ 6 46]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 521457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.10      0.14        10\n",
      "           1       0.83      0.93      0.88        46\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.54      0.52      0.51        56\n",
      "weighted avg       0.72      0.79      0.75        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 3 43]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.10      0.12        10\n",
      "           1       0.82      0.87      0.84        46\n",
      "\n",
      "    accuracy                           0.73        56\n",
      "   macro avg       0.48      0.48      0.48        56\n",
      "weighted avg       0.70      0.73      0.71        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 6 40]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.12      0.12         8\n",
      "           1       0.85      0.85      0.85        48\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.49      0.49      0.49        56\n",
      "weighted avg       0.75      0.75      0.75        56\n",
      "\n",
      "[[ 1  7]\n",
      " [ 7 41]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.82      0.87      0.85        47\n",
      "\n",
      "    accuracy                           0.73        56\n",
      "   macro avg       0.41      0.44      0.42        56\n",
      "weighted avg       0.69      0.73      0.71        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 6 41]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        11\n",
      "           1       0.81      0.93      0.87        45\n",
      "\n",
      "    accuracy                           0.77        56\n",
      "   macro avg       0.53      0.51      0.50        56\n",
      "weighted avg       0.70      0.77      0.72        56\n",
      "\n",
      "[[ 1 10]\n",
      " [ 3 42]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.84      0.88      0.86        48\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.42      0.44      0.43        56\n",
      "weighted avg       0.72      0.75      0.73        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 6 42]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14         9\n",
      "           1       0.84      0.91      0.88        47\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.52      0.51      0.51        56\n",
      "weighted avg       0.74      0.79      0.76        56\n",
      "\n",
      "[[ 1  8]\n",
      " [ 4 43]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.25      0.24         8\n",
      "           1       0.87      0.85      0.86        48\n",
      "\n",
      "    accuracy                           0.77        56\n",
      "   macro avg       0.55      0.55      0.55        56\n",
      "weighted avg       0.78      0.77      0.77        56\n",
      "\n",
      "[[ 2  6]\n",
      " [ 7 41]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.23      0.33        13\n",
      "           1       0.80      0.95      0.87        43\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.70      0.59      0.60        56\n",
      "weighted avg       0.76      0.79      0.75        56\n",
      "\n",
      "[[ 3 10]\n",
      " [ 2 41]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.11        13\n",
      "           1       0.77      0.89      0.83        46\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.47      0.48      0.47        59\n",
      "weighted avg       0.64      0.71      0.67        59\n",
      "\n",
      "[[ 1 12]\n",
      " [ 5 41]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.10      0.13        10\n",
      "           1       0.83      0.92      0.87        49\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.52      0.51      0.50        59\n",
      "weighted avg       0.73      0.78      0.75        59\n",
      "\n",
      "[[ 1  9]\n",
      " [ 4 45]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.22      0.21         9\n",
      "           1       0.86      0.84      0.85        50\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.53      0.53      0.53        59\n",
      "weighted avg       0.76      0.75      0.75        59\n",
      "\n",
      "[[ 2  7]\n",
      " [ 8 42]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.81      0.90      0.85        49\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.41      0.45      0.43        59\n",
      "weighted avg       0.68      0.75      0.71        59\n",
      "\n",
      "[[ 0 10]\n",
      " [ 5 44]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        12\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.53      0.51      0.49        59\n",
      "weighted avg       0.69      0.76      0.71        59\n",
      "\n",
      "[[ 1 11]\n",
      " [ 3 44]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.83      0.88      0.85        50\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.42      0.44      0.43        59\n",
      "weighted avg       0.70      0.75      0.72        59\n",
      "\n",
      "[[ 0  9]\n",
      " [ 6 44]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.09      0.11        11\n",
      "           1       0.80      0.85      0.83        48\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.46      0.47      0.47        59\n",
      "weighted avg       0.68      0.71      0.69        59\n",
      "\n",
      "[[ 1 10]\n",
      " [ 7 41]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.25      0.20         8\n",
      "           1       0.87      0.80      0.84        51\n",
      "\n",
      "    accuracy                           0.73        59\n",
      "   macro avg       0.52      0.53      0.52        59\n",
      "weighted avg       0.78      0.73      0.75        59\n",
      "\n",
      "[[ 2  6]\n",
      " [10 41]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.36      0.42        14\n",
      "           1       0.82      0.89      0.85        45\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.66      0.62      0.63        59\n",
      "weighted avg       0.74      0.76      0.75        59\n",
      "\n",
      "[[ 5  9]\n",
      " [ 5 40]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 521457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.10      0.13        21\n",
      "           1       0.76      0.90      0.82        67\n",
      "\n",
      "    accuracy                           0.70        88\n",
      "   macro avg       0.49      0.50      0.48        88\n",
      "weighted avg       0.63      0.70      0.66        88\n",
      "\n",
      "[[ 2 19]\n",
      " [ 7 60]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14        18\n",
      "           1       0.79      0.89      0.84        70\n",
      "\n",
      "    accuracy                           0.73        88\n",
      "   macro avg       0.50      0.50      0.49        88\n",
      "weighted avg       0.67      0.73      0.70        88\n",
      "\n",
      "[[ 2 16]\n",
      " [ 8 62]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.31      0.30        13\n",
      "           1       0.88      0.87      0.87        75\n",
      "\n",
      "    accuracy                           0.78        88\n",
      "   macro avg       0.58      0.59      0.58        88\n",
      "weighted avg       0.79      0.78      0.79        88\n",
      "\n",
      "[[ 4  9]\n",
      " [10 65]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        18\n",
      "           1       0.78      0.84      0.81        70\n",
      "\n",
      "    accuracy                           0.68        88\n",
      "   macro avg       0.43      0.45      0.44        88\n",
      "weighted avg       0.63      0.68      0.66        88\n",
      "\n",
      "[[ 1 17]\n",
      " [11 59]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18        14\n",
      "           1       0.85      0.92      0.88        74\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.55      0.53      0.53        88\n",
      "weighted avg       0.75      0.80      0.77        88\n",
      "\n",
      "[[ 2 12]\n",
      " [ 6 68]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.07      0.10        15\n",
      "           1       0.83      0.93      0.88        73\n",
      "\n",
      "    accuracy                           0.78        88\n",
      "   macro avg       0.50      0.50      0.49        88\n",
      "weighted avg       0.72      0.78      0.74        88\n",
      "\n",
      "[[ 1 14]\n",
      " [ 5 68]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25        15\n",
      "           1       0.85      0.92      0.88        73\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.59      0.56      0.57        88\n",
      "weighted avg       0.76      0.80      0.77        88\n",
      "\n",
      "[[ 3 12]\n",
      " [ 6 67]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.07      0.07        15\n",
      "           1       0.81      0.84      0.82        73\n",
      "\n",
      "    accuracy                           0.70        88\n",
      "   macro avg       0.45      0.45      0.45        88\n",
      "weighted avg       0.69      0.70      0.70        88\n",
      "\n",
      "[[ 1 14]\n",
      " [12 61]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.15      0.21        20\n",
      "           1       0.79      0.93      0.85        68\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.58      0.54      0.53        88\n",
      "weighted avg       0.69      0.75      0.71        88\n",
      "\n",
      "[[ 3 17]\n",
      " [ 5 63]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.17      0.22        23\n",
      "           1       0.77      0.88      0.82        73\n",
      "\n",
      "    accuracy                           0.71        96\n",
      "   macro avg       0.54      0.53      0.52        96\n",
      "weighted avg       0.66      0.71      0.68        96\n",
      "\n",
      "[[ 4 19]\n",
      " [ 9 64]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14        19\n",
      "           1       0.80      0.90      0.85        77\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.50      0.50      0.49        96\n",
      "weighted avg       0.68      0.74      0.71        96\n",
      "\n",
      "[[ 2 17]\n",
      " [ 8 69]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.21      0.22        14\n",
      "           1       0.87      0.88      0.87        82\n",
      "\n",
      "    accuracy                           0.78        96\n",
      "   macro avg       0.55      0.55      0.55        96\n",
      "weighted avg       0.77      0.78      0.78        96\n",
      "\n",
      "[[ 3 11]\n",
      " [10 72]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        18\n",
      "           1       0.80      0.86      0.83        78\n",
      "\n",
      "    accuracy                           0.71        96\n",
      "   macro avg       0.44      0.46      0.45        96\n",
      "weighted avg       0.66      0.71      0.68        96\n",
      "\n",
      "[[ 1 17]\n",
      " [11 67]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.19      0.21        16\n",
      "           1       0.85      0.89      0.87        80\n",
      "\n",
      "    accuracy                           0.77        96\n",
      "   macro avg       0.55      0.54      0.54        96\n",
      "weighted avg       0.75      0.77      0.76        96\n",
      "\n",
      "[[ 3 13]\n",
      " [ 9 71]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.07      0.09        15\n",
      "           1       0.84      0.93      0.88        81\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.49      0.50      0.49        96\n",
      "weighted avg       0.73      0.79      0.76        96\n",
      "\n",
      "[[ 1 14]\n",
      " [ 6 75]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.27      0.26        15\n",
      "           1       0.86      0.85      0.86        81\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.56      0.56      0.56        96\n",
      "weighted avg       0.77      0.76      0.76        96\n",
      "\n",
      "[[ 4 11]\n",
      " [12 69]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.12      0.14        16\n",
      "           1       0.83      0.86      0.85        80\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.49      0.49      0.49        96\n",
      "weighted avg       0.72      0.74      0.73        96\n",
      "\n",
      "[[ 2 14]\n",
      " [11 69]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.14      0.19        21\n",
      "           1       0.79      0.91      0.84        75\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.55      0.52      0.52        96\n",
      "weighted avg       0.68      0.74      0.70        96\n",
      "\n",
      "[[ 3 18]\n",
      " [ 7 68]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 521457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.12      0.16        24\n",
      "           1       0.79      0.89      0.83        88\n",
      "\n",
      "    accuracy                           0.72       112\n",
      "   macro avg       0.51      0.51      0.50       112\n",
      "weighted avg       0.67      0.72      0.69       112\n",
      "\n",
      "[[ 3 21]\n",
      " [10 78]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.18      0.22        22\n",
      "           1       0.82      0.89      0.85        90\n",
      "\n",
      "    accuracy                           0.75       112\n",
      "   macro avg       0.55      0.54      0.54       112\n",
      "weighted avg       0.71      0.75      0.73       112\n",
      "\n",
      "[[ 4 18]\n",
      " [10 80]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24        17\n",
      "           1       0.86      0.87      0.87        95\n",
      "\n",
      "    accuracy                           0.78       112\n",
      "   macro avg       0.56      0.55      0.56       112\n",
      "weighted avg       0.77      0.78      0.77       112\n",
      "\n",
      "[[ 4 13]\n",
      " [12 83]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.05      0.06        20\n",
      "           1       0.81      0.86      0.83        92\n",
      "\n",
      "    accuracy                           0.71       112\n",
      "   macro avg       0.44      0.45      0.45       112\n",
      "weighted avg       0.67      0.71      0.69       112\n",
      "\n",
      "[[ 1 19]\n",
      " [13 79]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.30      0.35        20\n",
      "           1       0.86      0.91      0.88        92\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.64      0.61      0.62       112\n",
      "weighted avg       0.78      0.80      0.79       112\n",
      "\n",
      "[[ 6 14]\n",
      " [ 8 84]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.22      0.24        18\n",
      "           1       0.85      0.87      0.86        94\n",
      "\n",
      "    accuracy                           0.77       112\n",
      "   macro avg       0.55      0.55      0.55       112\n",
      "weighted avg       0.76      0.77      0.76       112\n",
      "\n",
      "[[ 4 14]\n",
      " [12 82]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.41      0.33        17\n",
      "           1       0.88      0.80      0.84        95\n",
      "\n",
      "    accuracy                           0.74       112\n",
      "   macro avg       0.58      0.61      0.58       112\n",
      "weighted avg       0.79      0.74      0.76       112\n",
      "\n",
      "[[ 7 10]\n",
      " [19 76]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.24      0.22        17\n",
      "           1       0.86      0.83      0.84        95\n",
      "\n",
      "    accuracy                           0.74       112\n",
      "   macro avg       0.53      0.53      0.53       112\n",
      "weighted avg       0.76      0.74      0.75       112\n",
      "\n",
      "[[ 4 13]\n",
      " [16 79]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.12      0.16        24\n",
      "           1       0.79      0.89      0.83        88\n",
      "\n",
      "    accuracy                           0.72       112\n",
      "   macro avg       0.51      0.51      0.50       112\n",
      "weighted avg       0.67      0.72      0.69       112\n",
      "\n",
      "[[ 3 21]\n",
      " [10 78]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.12      0.15        26\n",
      "           1       0.78      0.88      0.83        94\n",
      "\n",
      "    accuracy                           0.72       120\n",
      "   macro avg       0.50      0.50      0.49       120\n",
      "weighted avg       0.66      0.72      0.68       120\n",
      "\n",
      "[[ 3 23]\n",
      " [11 83]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.23      0.29        22\n",
      "           1       0.84      0.92      0.88        98\n",
      "\n",
      "    accuracy                           0.79       120\n",
      "   macro avg       0.61      0.57      0.58       120\n",
      "weighted avg       0.76      0.79      0.77       120\n",
      "\n",
      "[[ 5 17]\n",
      " [ 8 90]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.15      0.18        20\n",
      "           1       0.84      0.89      0.86       100\n",
      "\n",
      "    accuracy                           0.77       120\n",
      "   macro avg       0.53      0.52      0.52       120\n",
      "weighted avg       0.74      0.77      0.75       120\n",
      "\n",
      "[[ 3 17]\n",
      " [11 89]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.14      0.15        22\n",
      "           1       0.82      0.86      0.84        98\n",
      "\n",
      "    accuracy                           0.73       120\n",
      "   macro avg       0.50      0.50      0.49       120\n",
      "weighted avg       0.70      0.72      0.71       120\n",
      "\n",
      "[[ 3 19]\n",
      " [14 84]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.27      0.30        22\n",
      "           1       0.84      0.88      0.86        98\n",
      "\n",
      "    accuracy                           0.77       120\n",
      "   macro avg       0.59      0.58      0.58       120\n",
      "weighted avg       0.75      0.77      0.76       120\n",
      "\n",
      "[[ 6 16]\n",
      " [12 86]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.21      0.23        19\n",
      "           1       0.86      0.88      0.87       101\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.55      0.55      0.55       120\n",
      "weighted avg       0.76      0.78      0.77       120\n",
      "\n",
      "[[ 4 15]\n",
      " [12 89]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.20      0.17        20\n",
      "           1       0.83      0.78      0.80       100\n",
      "\n",
      "    accuracy                           0.68       120\n",
      "   macro avg       0.49      0.49      0.49       120\n",
      "weighted avg       0.72      0.68      0.70       120\n",
      "\n",
      "[[ 4 16]\n",
      " [22 78]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.24      0.21        17\n",
      "           1       0.87      0.83      0.85       103\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.52      0.53      0.53       120\n",
      "weighted avg       0.77      0.74      0.76       120\n",
      "\n",
      "[[ 4 13]\n",
      " [18 85]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.11      0.16        27\n",
      "           1       0.78      0.92      0.85        93\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.54      0.52      0.50       120\n",
      "weighted avg       0.67      0.74      0.69       120\n",
      "\n",
      "[[ 3 24]\n",
      " [ 7 86]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 521457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        22\n",
      "           1       0.76      0.91      0.83        69\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.50      0.50      0.48        91\n",
      "weighted avg       0.64      0.71      0.66        91\n",
      "\n",
      "[[ 2 20]\n",
      " [ 6 63]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.17      0.21        18\n",
      "           1       0.81      0.89      0.85        73\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.54      0.53      0.53        91\n",
      "weighted avg       0.71      0.75      0.72        91\n",
      "\n",
      "[[ 3 15]\n",
      " [ 8 65]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.15      0.17        13\n",
      "           1       0.86      0.88      0.87        78\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.52      0.52      0.52        91\n",
      "weighted avg       0.77      0.78      0.77        91\n",
      "\n",
      "[[ 2 11]\n",
      " [ 9 69]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.06      0.06        18\n",
      "           1       0.78      0.82      0.80        73\n",
      "\n",
      "    accuracy                           0.67        91\n",
      "   macro avg       0.43      0.44      0.43        91\n",
      "weighted avg       0.64      0.67      0.65        91\n",
      "\n",
      "[[ 1 17]\n",
      " [13 60]]\n",
      "Accuracy is  0.65\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.13      0.15        15\n",
      "           1       0.84      0.88      0.86        76\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.51      0.51      0.51        91\n",
      "weighted avg       0.73      0.76      0.74        91\n",
      "\n",
      "[[ 2 13]\n",
      " [ 9 67]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.07      0.09        15\n",
      "           1       0.83      0.92      0.88        76\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.49      0.49      0.48        91\n",
      "weighted avg       0.72      0.78      0.75        91\n",
      "\n",
      "[[ 1 14]\n",
      " [ 6 70]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.33      0.31        15\n",
      "           1       0.86      0.84      0.85        76\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.58      0.59      0.58        91\n",
      "weighted avg       0.77      0.76      0.76        91\n",
      "\n",
      "[[ 5 10]\n",
      " [12 64]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.07      0.07        15\n",
      "           1       0.82      0.82      0.82        76\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.44      0.44      0.44        91\n",
      "weighted avg       0.69      0.69      0.69        91\n",
      "\n",
      "[[ 1 14]\n",
      " [14 62]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15        20\n",
      "           1       0.79      0.94      0.86        71\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.56      0.52      0.51        91\n",
      "weighted avg       0.69      0.76      0.70        91\n",
      "\n",
      "[[ 2 18]\n",
      " [ 4 67]]\n",
      "Accuracy is  0.70\n",
      "The Average of All acuracies 0.7275308641975307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x271e858e208>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length,AVGAccuracy,AD=Adaboost_Classifier(X,y)\n",
    "Sum_of_Acc_Dtree=sum(AVGAccuracy)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc_Dtree/length))\n",
    "feautreimportance=pd.Series(AD.feature_importances_, index=Predictorvar)\n",
    "feautreimportance.nlargest(10).plot(kind='bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xgboost_classifier(Data1,Data2):\n",
    "    Test_size=[0.30,0.25,0.21,0.22,0.33,0.36,0.42,0.45,0.34]\n",
    "    Random_state=[521457,7505,32578,5,2567,4789,8547,657,42]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            xgb=XGBClassifier(max_depth=5, learning_rate=0.01, n_estimators=400, objective='binary:logistic', booster='gbtree')\n",
    "            predictModel=xgb.fit(X_train,y_train)\n",
    "            predictions=predictModel.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy,xgb ) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.75      0.95      0.84        61\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.38      0.48      0.42        80\n",
      "weighted avg       0.57      0.72      0.64        80\n",
      "\n",
      "[[ 0 19]\n",
      " [ 3 58]]\n",
      "Accuracy is  0.64\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.07      0.12        14\n",
      "           1       0.83      0.97      0.90        66\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.58      0.52      0.51        80\n",
      "weighted avg       0.74      0.81      0.76        80\n",
      "\n",
      "[[ 1 13]\n",
      " [ 2 64]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.15      0.20        13\n",
      "           1       0.85      0.93      0.89        67\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.57      0.54      0.54        80\n",
      "weighted avg       0.76      0.80      0.77        80\n",
      "\n",
      "[[ 2 11]\n",
      " [ 5 62]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.07      0.09        15\n",
      "           1       0.81      0.89      0.85        65\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.47      0.48      0.47        80\n",
      "weighted avg       0.68      0.74      0.70        80\n",
      "\n",
      "[[ 1 14]\n",
      " [ 7 58]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.83      0.94      0.88        67\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.41      0.47      0.44        80\n",
      "weighted avg       0.69      0.79      0.74        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 4 63]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      0.95      0.88        66\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.41      0.48      0.44        80\n",
      "weighted avg       0.68      0.79      0.73        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 3 63]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.11        13\n",
      "           1       0.84      0.93      0.88        67\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.50      0.50      0.49        80\n",
      "weighted avg       0.73      0.79      0.75        80\n",
      "\n",
      "[[ 1 12]\n",
      " [ 5 62]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        13\n",
      "           1       0.84      0.96      0.90        67\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.55      0.52      0.51        80\n",
      "weighted avg       0.75      0.81      0.77        80\n",
      "\n",
      "[[ 1 12]\n",
      " [ 3 64]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.78      0.95      0.86        63\n",
      "\n",
      "    accuracy                           0.75        80\n",
      "   macro avg       0.39      0.48      0.43        80\n",
      "weighted avg       0.61      0.75      0.68        80\n",
      "\n",
      "[[ 0 17]\n",
      " [ 3 60]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.06      0.11        16\n",
      "           1       0.77      0.96      0.85        51\n",
      "\n",
      "    accuracy                           0.75        67\n",
      "   macro avg       0.55      0.51      0.48        67\n",
      "weighted avg       0.66      0.75      0.67        67\n",
      "\n",
      "[[ 1 15]\n",
      " [ 2 49]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        12\n",
      "           1       0.83      0.95      0.88        55\n",
      "\n",
      "    accuracy                           0.79        67\n",
      "   macro avg       0.54      0.51      0.50        67\n",
      "weighted avg       0.72      0.79      0.75        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 3 52]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.22      0.21         9\n",
      "           1       0.88      0.86      0.87        58\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.54      0.54      0.54        67\n",
      "weighted avg       0.79      0.78      0.78        67\n",
      "\n",
      "[[ 2  7]\n",
      " [ 8 50]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.81      0.93      0.86        55\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.40      0.46      0.43        67\n",
      "weighted avg       0.66      0.76      0.71        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 4 51]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.08      0.13        12\n",
      "           1       0.83      0.96      0.89        55\n",
      "\n",
      "    accuracy                           0.81        67\n",
      "   macro avg       0.58      0.52      0.51        67\n",
      "weighted avg       0.74      0.81      0.76        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 2 53]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.80      0.98      0.88        54\n",
      "\n",
      "    accuracy                           0.79        67\n",
      "   macro avg       0.40      0.49      0.44        67\n",
      "weighted avg       0.65      0.79      0.71        67\n",
      "\n",
      "[[ 0 13]\n",
      " [ 1 53]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.09      0.12        11\n",
      "           1       0.84      0.91      0.87        56\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.50      0.50      0.49        67\n",
      "weighted avg       0.73      0.78      0.75        67\n",
      "\n",
      "[[ 1 10]\n",
      " [ 5 51]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.12      0.17         8\n",
      "           1       0.89      0.95      0.92        59\n",
      "\n",
      "    accuracy                           0.85        67\n",
      "   macro avg       0.57      0.54      0.54        67\n",
      "weighted avg       0.81      0.85      0.83        67\n",
      "\n",
      "[[ 1  7]\n",
      " [ 3 56]]\n",
      "Accuracy is  0.83\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.77      0.94      0.84        52\n",
      "\n",
      "    accuracy                           0.73        67\n",
      "   macro avg       0.38      0.47      0.42        67\n",
      "weighted avg       0.59      0.73      0.66        67\n",
      "\n",
      "[[ 0 15]\n",
      " [ 3 49]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.81      0.93      0.87        46\n",
      "\n",
      "    accuracy                           0.77        56\n",
      "   macro avg       0.41      0.47      0.43        56\n",
      "weighted avg       0.67      0.77      0.71        56\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 10]\n",
      " [ 3 43]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.10      0.13        10\n",
      "           1       0.82      0.91      0.87        46\n",
      "\n",
      "    accuracy                           0.77        56\n",
      "   macro avg       0.51      0.51      0.50        56\n",
      "weighted avg       0.71      0.77      0.74        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 4 42]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.12      0.12         8\n",
      "           1       0.85      0.85      0.85        48\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.49      0.49      0.49        56\n",
      "weighted avg       0.75      0.75      0.75        56\n",
      "\n",
      "[[ 1  7]\n",
      " [ 7 41]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.83      0.96      0.89        47\n",
      "\n",
      "    accuracy                           0.80        56\n",
      "   macro avg       0.42      0.48      0.45        56\n",
      "weighted avg       0.70      0.80      0.75        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 2 45]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.09      0.14        11\n",
      "           1       0.81      0.96      0.88        45\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.57      0.52      0.51        56\n",
      "weighted avg       0.72      0.79      0.73        56\n",
      "\n",
      "[[ 1 10]\n",
      " [ 2 43]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      0.96      0.90        48\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.43      0.48      0.45        56\n",
      "weighted avg       0.73      0.82      0.77        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 2 46]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14         9\n",
      "           1       0.84      0.91      0.88        47\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.52      0.51      0.51        56\n",
      "weighted avg       0.74      0.79      0.76        56\n",
      "\n",
      "[[ 1  8]\n",
      " [ 4 43]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.12      0.17         8\n",
      "           1       0.87      0.94      0.90        48\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.56      0.53      0.53        56\n",
      "weighted avg       0.78      0.82      0.80        56\n",
      "\n",
      "[[ 1  7]\n",
      " [ 3 45]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.75      0.93      0.83        43\n",
      "\n",
      "    accuracy                           0.71        56\n",
      "   macro avg       0.38      0.47      0.42        56\n",
      "weighted avg       0.58      0.71      0.64        56\n",
      "\n",
      "[[ 0 13]\n",
      " [ 3 40]]\n",
      "Accuracy is  0.64\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.76      0.91      0.83        46\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.38      0.46      0.42        59\n",
      "weighted avg       0.60      0.71      0.65        59\n",
      "\n",
      "[[ 0 13]\n",
      " [ 4 42]]\n",
      "Accuracy is  0.65\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.10      0.12        10\n",
      "           1       0.83      0.90      0.86        49\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.50      0.50      0.49        59\n",
      "weighted avg       0.72      0.76      0.74        59\n",
      "\n",
      "[[ 1  9]\n",
      " [ 5 44]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.22      0.22         9\n",
      "           1       0.86      0.86      0.86        50\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.54      0.54      0.54        59\n",
      "weighted avg       0.76      0.76      0.76        59\n",
      "\n",
      "[[ 2  7]\n",
      " [ 7 43]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.82      0.96      0.89        49\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.41      0.48      0.44        59\n",
      "weighted avg       0.68      0.80      0.74        59\n",
      "\n",
      "[[ 0 10]\n",
      " [ 2 47]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.08      0.13        12\n",
      "           1       0.80      0.96      0.87        47\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.57      0.52      0.50        59\n",
      "weighted avg       0.71      0.78      0.72        59\n",
      "\n",
      "[[ 1 11]\n",
      " [ 2 45]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      0.96      0.90        50\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.42      0.48      0.45        59\n",
      "weighted avg       0.71      0.81      0.76        59\n",
      "\n",
      "[[ 0  9]\n",
      " [ 2 48]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.80      0.94      0.87        48\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.40      0.47      0.43        59\n",
      "weighted avg       0.65      0.76      0.70        59\n",
      "\n",
      "[[ 0 11]\n",
      " [ 3 45]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.12      0.17         8\n",
      "           1       0.87      0.94      0.91        51\n",
      "\n",
      "    accuracy                           0.83        59\n",
      "   macro avg       0.56      0.53      0.54        59\n",
      "weighted avg       0.79      0.83      0.81        59\n",
      "\n",
      "[[ 1  7]\n",
      " [ 3 48]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.76      0.98      0.85        45\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.38      0.49      0.43        59\n",
      "weighted avg       0.58      0.75      0.65        59\n",
      "\n",
      "[[ 0 14]\n",
      " [ 1 44]]\n",
      "Accuracy is  0.65\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.05      0.09        21\n",
      "           1       0.77      0.99      0.86        67\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.63      0.52      0.47        88\n",
      "weighted avg       0.70      0.76      0.68        88\n",
      "\n",
      "[[ 1 20]\n",
      " [ 1 66]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 7505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.06      0.09        18\n",
      "           1       0.80      0.94      0.86        70\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.50      0.50      0.47        88\n",
      "weighted avg       0.67      0.76      0.70        88\n",
      "\n",
      "[[ 1 17]\n",
      " [ 4 66]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.15      0.20        13\n",
      "           1       0.86      0.93      0.90        75\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.57      0.54      0.55        88\n",
      "weighted avg       0.78      0.82      0.79        88\n",
      "\n",
      "[[ 2 11]\n",
      " [ 5 70]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.06      0.07        18\n",
      "           1       0.78      0.87      0.82        70\n",
      "\n",
      "    accuracy                           0.70        88\n",
      "   macro avg       0.44      0.46      0.45        88\n",
      "weighted avg       0.64      0.70      0.67        88\n",
      "\n",
      "[[ 1 17]\n",
      " [ 9 61]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.84      0.97      0.90        74\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.42      0.49      0.45        88\n",
      "weighted avg       0.70      0.82      0.76        88\n",
      "\n",
      "[[ 0 14]\n",
      " [ 2 72]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.97      0.89        73\n",
      "\n",
      "    accuracy                           0.81        88\n",
      "   macro avg       0.41      0.49      0.45        88\n",
      "weighted avg       0.68      0.81      0.74        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 2 71]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.13      0.18        15\n",
      "           1       0.84      0.93      0.88        73\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.56      0.53      0.53        88\n",
      "weighted avg       0.75      0.80      0.76        88\n",
      "\n",
      "[[ 2 13]\n",
      " [ 5 68]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.07      0.11        15\n",
      "           1       0.83      0.96      0.89        73\n",
      "\n",
      "    accuracy                           0.81        88\n",
      "   macro avg       0.54      0.51      0.50        88\n",
      "weighted avg       0.73      0.81      0.76        88\n",
      "\n",
      "[[ 1 14]\n",
      " [ 3 70]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.76      0.96      0.85        68\n",
      "\n",
      "    accuracy                           0.74        88\n",
      "   macro avg       0.38      0.48      0.42        88\n",
      "weighted avg       0.59      0.74      0.66        88\n",
      "\n",
      "[[ 0 20]\n",
      " [ 3 65]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.04      0.07        23\n",
      "           1       0.76      0.95      0.84        73\n",
      "\n",
      "    accuracy                           0.73        96\n",
      "   macro avg       0.48      0.49      0.46        96\n",
      "weighted avg       0.62      0.73      0.66        96\n",
      "\n",
      "[[ 1 22]\n",
      " [ 4 69]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.05      0.08        19\n",
      "           1       0.80      0.94      0.86        77\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.48      0.49      0.47        96\n",
      "weighted avg       0.67      0.76      0.71        96\n",
      "\n",
      "[[ 1 18]\n",
      " [ 5 72]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.21      0.24        14\n",
      "           1       0.87      0.90      0.89        82\n",
      "\n",
      "    accuracy                           0.80        96\n",
      "   macro avg       0.57      0.56      0.56        96\n",
      "weighted avg       0.78      0.80      0.79        96\n",
      "\n",
      "[[ 3 11]\n",
      " [ 8 74]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.06      0.07        18\n",
      "           1       0.80      0.88      0.84        78\n",
      "\n",
      "    accuracy                           0.73        96\n",
      "   macro avg       0.45      0.47      0.46        96\n",
      "weighted avg       0.67      0.73      0.70        96\n",
      "\n",
      "[[ 1 17]\n",
      " [ 9 69]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      0.97      0.90        80\n",
      "\n",
      "    accuracy                           0.81        96\n",
      "   macro avg       0.41      0.49      0.45        96\n",
      "weighted avg       0.69      0.81      0.75        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 2 78]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      0.99      0.91        81\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.42      0.49      0.45        96\n",
      "weighted avg       0.71      0.83      0.77        96\n",
      "\n",
      "[[ 0 15]\n",
      " [ 1 80]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.13      0.17        15\n",
      "           1       0.85      0.93      0.89        81\n",
      "\n",
      "    accuracy                           0.80        96\n",
      "   macro avg       0.55      0.53      0.53        96\n",
      "weighted avg       0.76      0.80      0.78        96\n",
      "\n",
      "[[ 2 13]\n",
      " [ 6 75]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.06      0.09        16\n",
      "           1       0.83      0.93      0.88        80\n",
      "\n",
      "    accuracy                           0.78        96\n",
      "   macro avg       0.49      0.49      0.48        96\n",
      "weighted avg       0.72      0.78      0.74        96\n",
      "\n",
      "[[ 1 15]\n",
      " [ 6 74]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.77      0.93      0.84        75\n",
      "\n",
      "    accuracy                           0.73        96\n",
      "   macro avg       0.38      0.47      0.42        96\n",
      "weighted avg       0.60      0.73      0.66        96\n",
      "\n",
      "[[ 0 21]\n",
      " [ 5 70]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.78      0.98      0.87        88\n",
      "\n",
      "    accuracy                           0.77       112\n",
      "   macro avg       0.39      0.49      0.43       112\n",
      "weighted avg       0.61      0.77      0.68       112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0 24]\n",
      " [ 2 86]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.09      0.15        22\n",
      "           1       0.81      0.98      0.89        90\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.66      0.53      0.52       112\n",
      "weighted avg       0.75      0.80      0.74       112\n",
      "\n",
      "[[ 2 20]\n",
      " [ 2 88]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.24      0.25        17\n",
      "           1       0.87      0.88      0.87        95\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.57      0.56      0.56       112\n",
      "weighted avg       0.78      0.79      0.78       112\n",
      "\n",
      "[[ 4 13]\n",
      " [11 84]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15        20\n",
      "           1       0.83      0.96      0.89        92\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.58      0.53      0.52       112\n",
      "weighted avg       0.74      0.80      0.76       112\n",
      "\n",
      "[[ 2 18]\n",
      " [ 4 88]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.10      0.14        20\n",
      "           1       0.83      0.92      0.87        92\n",
      "\n",
      "    accuracy                           0.78       112\n",
      "   macro avg       0.52      0.51      0.50       112\n",
      "weighted avg       0.72      0.78      0.74       112\n",
      "\n",
      "[[ 2 18]\n",
      " [ 7 85]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.83      0.94      0.88        94\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.42      0.47      0.44       112\n",
      "weighted avg       0.70      0.79      0.74       112\n",
      "\n",
      "[[ 0 18]\n",
      " [ 6 88]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.06      0.08        17\n",
      "           1       0.84      0.92      0.88        95\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.48      0.49      0.48       112\n",
      "weighted avg       0.73      0.79      0.76       112\n",
      "\n",
      "[[ 1 16]\n",
      " [ 8 87]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.06      0.08        17\n",
      "           1       0.85      0.94      0.89        95\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.50      0.50      0.49       112\n",
      "weighted avg       0.74      0.80      0.77       112\n",
      "\n",
      "[[ 1 16]\n",
      " [ 6 89]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.77      0.93      0.85        88\n",
      "\n",
      "    accuracy                           0.73       112\n",
      "   macro avg       0.39      0.47      0.42       112\n",
      "weighted avg       0.61      0.73      0.66       112\n",
      "\n",
      "[[ 0 24]\n",
      " [ 6 82]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.78      0.98      0.87        94\n",
      "\n",
      "    accuracy                           0.77       120\n",
      "   macro avg       0.39      0.49      0.43       120\n",
      "weighted avg       0.61      0.77      0.68       120\n",
      "\n",
      "[[ 0 26]\n",
      " [ 2 92]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.21        22\n",
      "           1       0.83      0.97      0.90        98\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.67      0.55      0.56       120\n",
      "weighted avg       0.77      0.82      0.77       120\n",
      "\n",
      "[[ 3 19]\n",
      " [ 3 95]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.15      0.17        20\n",
      "           1       0.84      0.88      0.86       100\n",
      "\n",
      "    accuracy                           0.76       120\n",
      "   macro avg       0.52      0.52      0.51       120\n",
      "weighted avg       0.73      0.76      0.74       120\n",
      "\n",
      "[[ 3 17]\n",
      " [12 88]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.09      0.14        22\n",
      "           1       0.82      0.95      0.88        98\n",
      "\n",
      "    accuracy                           0.79       120\n",
      "   macro avg       0.55      0.52      0.51       120\n",
      "weighted avg       0.72      0.79      0.75       120\n",
      "\n",
      "[[ 2 20]\n",
      " [ 5 93]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.09      0.13        22\n",
      "           1       0.82      0.92      0.87        98\n",
      "\n",
      "    accuracy                           0.77       120\n",
      "   macro avg       0.51      0.50      0.50       120\n",
      "weighted avg       0.70      0.77      0.73       120\n",
      "\n",
      "[[ 2 20]\n",
      " [ 8 90]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.83      0.93      0.88       101\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.42      0.47      0.44       120\n",
      "weighted avg       0.70      0.78      0.74       120\n",
      "\n",
      "[[ 0 19]\n",
      " [ 7 94]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.10      0.13        20\n",
      "           1       0.84      0.92      0.88       100\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.52      0.51      0.50       120\n",
      "weighted avg       0.73      0.78      0.75       120\n",
      "\n",
      "[[ 2 18]\n",
      " [ 8 92]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.12      0.14        17\n",
      "           1       0.86      0.91      0.89       103\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.52      0.52      0.51       120\n",
      "weighted avg       0.77      0.80      0.78       120\n",
      "\n",
      "[[ 2 15]\n",
      " [ 9 94]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.77      0.96      0.85        93\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.38      0.48      0.43       120\n",
      "weighted avg       0.59      0.74      0.66       120\n",
      "\n",
      "[[ 0 27]\n",
      " [ 4 89]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.05      0.08        22\n",
      "           1       0.76      0.99      0.86        69\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.63      0.52      0.47        91\n",
      "weighted avg       0.70      0.76      0.67        91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 1 21]\n",
      " [ 1 68]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.06      0.09        18\n",
      "           1       0.80      0.95      0.87        73\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.50      0.50      0.48        91\n",
      "weighted avg       0.68      0.77      0.71        91\n",
      "\n",
      "[[ 1 17]\n",
      " [ 4 69]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.31      0.32        13\n",
      "           1       0.89      0.90      0.89        78\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.61      0.60      0.61        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n",
      "[[ 4  9]\n",
      " [ 8 70]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.06      0.07        18\n",
      "           1       0.79      0.88      0.83        73\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.45      0.47      0.45        91\n",
      "weighted avg       0.65      0.71      0.68        91\n",
      "\n",
      "[[ 1 17]\n",
      " [ 9 64]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.97      0.90        76\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.42      0.49      0.45        91\n",
      "weighted avg       0.69      0.81      0.75        91\n",
      "\n",
      "[[ 0 15]\n",
      " [ 2 74]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.97      0.90        76\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.42      0.49      0.45        91\n",
      "weighted avg       0.69      0.81      0.75        91\n",
      "\n",
      "[[ 0 15]\n",
      " [ 2 74]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.13      0.17        15\n",
      "           1       0.84      0.91      0.87        76\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.53      0.52      0.52        91\n",
      "weighted avg       0.74      0.78      0.76        91\n",
      "\n",
      "[[ 2 13]\n",
      " [ 7 69]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.07      0.10        15\n",
      "           1       0.84      0.95      0.89        76\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.52      0.51      0.49        91\n",
      "weighted avg       0.73      0.80      0.76        91\n",
      "\n",
      "[[ 1 14]\n",
      " [ 4 72]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.77      0.96      0.86        71\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.39      0.48      0.43        91\n",
      "weighted avg       0.60      0.75      0.67        91\n",
      "\n",
      "[[ 0 20]\n",
      " [ 3 68]]\n",
      "Accuracy is  0.67\n",
      "The Average of All acuracies 0.7309876543209877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x271ea0cbd08>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length,AvgACC,XG=Xgboost_classifier(X,y)\n",
    "Sum_of_Acc_Dtree=sum(AvgACC)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc_Dtree/length))\n",
    "feautreimportance=pd.Series(XG.feature_importances_, index=Predictorvar)\n",
    "feautreimportance.nlargest(10).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientBoostClassifier(Data1,Data2):\n",
    "    Test_size=[0.30,0.25,0.21,0.22,0.33,0.36,0.42,0.45,0.34]\n",
    "    Random_state=[521457,7505,32578,5,2567,4789,8547,657,42]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            GBC=GradientBoostingClassifier(max_depth=5,learning_rate=0.01,n_estimators=300,)\n",
    "            predictModel=GBC.fit(X_train,y_train)\n",
    "            predictions=predictModel.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy, GBC ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.76      0.97      0.85        61\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.38      0.48      0.42        80\n",
      "weighted avg       0.58      0.74      0.65        80\n",
      "\n",
      "[[ 0 19]\n",
      " [ 2 59]]\n",
      "Accuracy is  0.65\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18        14\n",
      "           1       0.83      0.91      0.87        66\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.54      0.53      0.53        80\n",
      "weighted avg       0.73      0.78      0.75        80\n",
      "\n",
      "[[ 2 12]\n",
      " [ 6 60]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.23      0.25        13\n",
      "           1       0.86      0.88      0.87        67\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.56      0.56      0.56        80\n",
      "weighted avg       0.76      0.78      0.77        80\n",
      "\n",
      "[[ 3 10]\n",
      " [ 8 59]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.07      0.08        15\n",
      "           1       0.80      0.85      0.82        65\n",
      "\n",
      "    accuracy                           0.70        80\n",
      "   macro avg       0.44      0.46      0.45        80\n",
      "weighted avg       0.66      0.70      0.68        80\n",
      "\n",
      "[[ 1 14]\n",
      " [10 55]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.83      0.93      0.87        67\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.41      0.46      0.44        80\n",
      "weighted avg       0.69      0.78      0.73        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 5 62]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.81      0.91      0.86        66\n",
      "\n",
      "    accuracy                           0.75        80\n",
      "   macro avg       0.41      0.45      0.43        80\n",
      "weighted avg       0.67      0.75      0.71        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 6 60]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.08      0.08        13\n",
      "           1       0.83      0.85      0.84        67\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.46      0.46      0.46        80\n",
      "weighted avg       0.71      0.72      0.72        80\n",
      "\n",
      "[[ 1 12]\n",
      " [10 57]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.15      0.16        13\n",
      "           1       0.84      0.85      0.84        67\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.50      0.50      0.50        80\n",
      "weighted avg       0.73      0.74      0.73        80\n",
      "\n",
      "[[ 2 11]\n",
      " [10 57]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.18      0.27        17\n",
      "           1       0.81      0.97      0.88        63\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.71      0.57      0.58        80\n",
      "weighted avg       0.77      0.80      0.75        80\n",
      "\n",
      "[[ 3 14]\n",
      " [ 2 61]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.11        16\n",
      "           1       0.77      0.98      0.86        51\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.63      0.52      0.49        67\n",
      "weighted avg       0.70      0.76      0.68        67\n",
      "\n",
      "[[ 1 15]\n",
      " [ 1 50]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        12\n",
      "           1       0.83      0.95      0.88        55\n",
      "\n",
      "    accuracy                           0.79        67\n",
      "   macro avg       0.54      0.51      0.50        67\n",
      "weighted avg       0.72      0.79      0.75        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 3 52]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.33      0.27         9\n",
      "           1       0.89      0.83      0.86        58\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.56      0.58      0.56        67\n",
      "weighted avg       0.80      0.76      0.78        67\n",
      "\n",
      "[[ 3  6]\n",
      " [10 48]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.80      0.87      0.83        55\n",
      "\n",
      "    accuracy                           0.72        67\n",
      "   macro avg       0.40      0.44      0.42        67\n",
      "weighted avg       0.66      0.72      0.69        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 7 48]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.08      0.12        12\n",
      "           1       0.82      0.93      0.87        55\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.51      0.51      0.49        67\n",
      "weighted avg       0.71      0.78      0.74        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 4 51]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.79      0.89      0.83        54\n",
      "\n",
      "    accuracy                           0.72        67\n",
      "   macro avg       0.39      0.44      0.42        67\n",
      "weighted avg       0.63      0.72      0.67        67\n",
      "\n",
      "[[ 0 13]\n",
      " [ 6 48]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.09      0.10        11\n",
      "           1       0.82      0.84      0.83        56\n",
      "\n",
      "    accuracy                           0.72        67\n",
      "   macro avg       0.46      0.47      0.46        67\n",
      "weighted avg       0.71      0.72      0.71        67\n",
      "\n",
      "[[ 1 10]\n",
      " [ 9 47]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.25      0.24         8\n",
      "           1       0.90      0.88      0.89        59\n",
      "\n",
      "    accuracy                           0.81        67\n",
      "   macro avg       0.56      0.57      0.56        67\n",
      "weighted avg       0.82      0.81      0.81        67\n",
      "\n",
      "[[ 2  6]\n",
      " [ 7 52]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.07      0.11        15\n",
      "           1       0.78      0.94      0.85        52\n",
      "\n",
      "    accuracy                           0.75        67\n",
      "   macro avg       0.51      0.50      0.48        67\n",
      "weighted avg       0.66      0.75      0.68        67\n",
      "\n",
      "[[ 1 14]\n",
      " [ 3 49]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 521457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.10      0.13        10\n",
      "           1       0.82      0.91      0.87        46\n",
      "\n",
      "    accuracy                           0.77        56\n",
      "   macro avg       0.51      0.51      0.50        56\n",
      "weighted avg       0.71      0.77      0.74        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 4 42]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.10      0.14        10\n",
      "           1       0.83      0.93      0.88        46\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.54      0.52      0.51        56\n",
      "weighted avg       0.72      0.79      0.75        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 3 43]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.12      0.14         8\n",
      "           1       0.86      0.90      0.88        48\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.51      0.51      0.51        56\n",
      "weighted avg       0.76      0.79      0.77        56\n",
      "\n",
      "[[ 1  7]\n",
      " [ 5 43]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.82      0.87      0.85        47\n",
      "\n",
      "    accuracy                           0.73        56\n",
      "   macro avg       0.41      0.44      0.42        56\n",
      "weighted avg       0.69      0.73      0.71        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 6 41]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.80      0.96      0.87        45\n",
      "\n",
      "    accuracy                           0.77        56\n",
      "   macro avg       0.40      0.48      0.43        56\n",
      "weighted avg       0.64      0.77      0.70        56\n",
      "\n",
      "[[ 0 11]\n",
      " [ 2 43]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      0.92      0.88        48\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.42      0.46      0.44        56\n",
      "weighted avg       0.73      0.79      0.75        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 4 44]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.82      0.87      0.85        47\n",
      "\n",
      "    accuracy                           0.73        56\n",
      "   macro avg       0.41      0.44      0.42        56\n",
      "weighted avg       0.69      0.73      0.71        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 6 41]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25         8\n",
      "           1       0.88      0.88      0.88        48\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.56      0.56      0.56        56\n",
      "weighted avg       0.79      0.79      0.79        56\n",
      "\n",
      "[[ 2  6]\n",
      " [ 6 42]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.08      0.12        13\n",
      "           1       0.77      0.95      0.85        43\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.55      0.52      0.49        56\n",
      "weighted avg       0.67      0.75      0.68        56\n",
      "\n",
      "[[ 1 12]\n",
      " [ 2 41]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.78      0.98      0.87        46\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.39      0.49      0.43        59\n",
      "weighted avg       0.60      0.76      0.67        59\n",
      "\n",
      "[[ 0 13]\n",
      " [ 1 45]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.10      0.13        10\n",
      "           1       0.83      0.92      0.87        49\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.52      0.51      0.50        59\n",
      "weighted avg       0.73      0.78      0.75        59\n",
      "\n",
      "[[ 1  9]\n",
      " [ 4 45]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.22      0.21         9\n",
      "           1       0.86      0.84      0.85        50\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.53      0.53      0.53        59\n",
      "weighted avg       0.76      0.75      0.75        59\n",
      "\n",
      "[[ 2  7]\n",
      " [ 8 42]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.80      0.84      0.82        49\n",
      "\n",
      "    accuracy                           0.69        59\n",
      "   macro avg       0.40      0.42      0.41        59\n",
      "weighted avg       0.67      0.69      0.68        59\n",
      "\n",
      "[[ 0 10]\n",
      " [ 8 41]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.79      0.98      0.88        47\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.40      0.49      0.44        59\n",
      "weighted avg       0.63      0.78      0.70        59\n",
      "\n",
      "[[ 0 12]\n",
      " [ 1 46]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      0.92      0.88        50\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.42      0.46      0.44        59\n",
      "weighted avg       0.71      0.78      0.74        59\n",
      "\n",
      "[[ 0  9]\n",
      " [ 4 46]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.80      0.90      0.84        48\n",
      "\n",
      "    accuracy                           0.73        59\n",
      "   macro avg       0.40      0.45      0.42        59\n",
      "weighted avg       0.65      0.73      0.69        59\n",
      "\n",
      "[[ 0 11]\n",
      " [ 5 43]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.25      0.24         8\n",
      "           1       0.88      0.86      0.87        51\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.55      0.56      0.55        59\n",
      "weighted avg       0.79      0.78      0.79        59\n",
      "\n",
      "[[ 2  6]\n",
      " [ 7 44]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22        14\n",
      "           1       0.78      0.96      0.86        45\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.64      0.55      0.54        59\n",
      "weighted avg       0.71      0.76      0.71        59\n",
      "\n",
      "[[ 2 12]\n",
      " [ 2 43]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 521457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.05      0.08        21\n",
      "           1       0.76      0.94      0.84        67\n",
      "\n",
      "    accuracy                           0.73        88\n",
      "   macro avg       0.48      0.49      0.46        88\n",
      "weighted avg       0.63      0.73      0.66        88\n",
      "\n",
      "[[ 1 20]\n",
      " [ 4 63]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.17      0.22        18\n",
      "           1       0.81      0.91      0.86        70\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.57      0.54      0.54        88\n",
      "weighted avg       0.71      0.76      0.73        88\n",
      "\n",
      "[[ 3 15]\n",
      " [ 6 64]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.23      0.25        13\n",
      "           1       0.87      0.89      0.88        75\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.57      0.56      0.57        88\n",
      "weighted avg       0.78      0.80      0.79        88\n",
      "\n",
      "[[ 3 10]\n",
      " [ 8 67]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        18\n",
      "           1       0.78      0.84      0.81        70\n",
      "\n",
      "    accuracy                           0.68        88\n",
      "   macro avg       0.43      0.45      0.44        88\n",
      "weighted avg       0.63      0.68      0.66        88\n",
      "\n",
      "[[ 1 17]\n",
      " [11 59]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.83      0.95      0.89        74\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.42      0.47      0.44        88\n",
      "weighted avg       0.70      0.80      0.75        88\n",
      "\n",
      "[[ 0 14]\n",
      " [ 4 70]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.82      0.95      0.88        73\n",
      "\n",
      "    accuracy                           0.78        88\n",
      "   macro avg       0.41      0.47      0.44        88\n",
      "weighted avg       0.68      0.78      0.73        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 4 69]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.20      0.22        15\n",
      "           1       0.84      0.88      0.86        73\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.55      0.54      0.54        88\n",
      "weighted avg       0.74      0.76      0.75        88\n",
      "\n",
      "[[ 3 12]\n",
      " [ 9 64]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.07      0.08        15\n",
      "           1       0.82      0.89      0.86        73\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.47      0.48      0.47        88\n",
      "weighted avg       0.70      0.75      0.72        88\n",
      "\n",
      "[[ 1 14]\n",
      " [ 8 65]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.10      0.16        20\n",
      "           1       0.78      0.96      0.86        68\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.59      0.53      0.51        88\n",
      "weighted avg       0.70      0.76      0.70        88\n",
      "\n",
      "[[ 2 18]\n",
      " [ 3 65]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        23\n",
      "           1       0.76      0.92      0.83        73\n",
      "\n",
      "    accuracy                           0.72        96\n",
      "   macro avg       0.51      0.50      0.48        96\n",
      "weighted avg       0.64      0.72      0.66        96\n",
      "\n",
      "[[ 2 21]\n",
      " [ 6 67]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.05      0.08        19\n",
      "           1       0.80      0.94      0.86        77\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.48      0.49      0.47        96\n",
      "weighted avg       0.67      0.76      0.71        96\n",
      "\n",
      "[[ 1 18]\n",
      " [ 5 72]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.21      0.20        14\n",
      "           1       0.86      0.84      0.85        82\n",
      "\n",
      "    accuracy                           0.75        96\n",
      "   macro avg       0.53      0.53      0.53        96\n",
      "weighted avg       0.76      0.75      0.76        96\n",
      "\n",
      "[[ 3 11]\n",
      " [13 69]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.06      0.07        18\n",
      "           1       0.80      0.87      0.83        78\n",
      "\n",
      "    accuracy                           0.72        96\n",
      "   macro avg       0.45      0.46      0.45        96\n",
      "weighted avg       0.67      0.72      0.69        96\n",
      "\n",
      "[[ 1 17]\n",
      " [10 68]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      0.96      0.89        80\n",
      "\n",
      "    accuracy                           0.80        96\n",
      "   macro avg       0.41      0.48      0.45        96\n",
      "weighted avg       0.69      0.80      0.74        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 3 77]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      0.94      0.88        81\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.42      0.47      0.44        96\n",
      "weighted avg       0.70      0.79      0.75        96\n",
      "\n",
      "[[ 0 15]\n",
      " [ 5 76]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29        15\n",
      "           1       0.87      0.89      0.88        81\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.59      0.58      0.58        96\n",
      "weighted avg       0.78      0.79      0.79        96\n",
      "\n",
      "[[ 4 11]\n",
      " [ 9 72]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.06      0.08        16\n",
      "           1       0.83      0.90      0.86        80\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.47      0.48      0.47        96\n",
      "weighted avg       0.71      0.76      0.73        96\n",
      "\n",
      "[[ 1 15]\n",
      " [ 8 72]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15        21\n",
      "           1       0.79      0.95      0.86        75\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.56      0.52      0.50        96\n",
      "weighted avg       0.69      0.76      0.70        96\n",
      "\n",
      "[[ 2 19]\n",
      " [ 4 71]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 521457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.12      0.17        24\n",
      "           1       0.79      0.91      0.85        88\n",
      "\n",
      "    accuracy                           0.74       112\n",
      "   macro avg       0.53      0.52      0.51       112\n",
      "weighted avg       0.68      0.74      0.70       112\n",
      "\n",
      "[[ 3 21]\n",
      " [ 8 80]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.23      0.30        22\n",
      "           1       0.83      0.93      0.88        90\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.64      0.58      0.59       112\n",
      "weighted avg       0.76      0.79      0.77       112\n",
      "\n",
      "[[ 5 17]\n",
      " [ 6 84]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.18      0.19        17\n",
      "           1       0.86      0.88      0.87        95\n",
      "\n",
      "    accuracy                           0.78       112\n",
      "   macro avg       0.54      0.53      0.53       112\n",
      "weighted avg       0.76      0.78      0.77       112\n",
      "\n",
      "[[ 3 14]\n",
      " [11 84]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.10      0.11        20\n",
      "           1       0.81      0.86      0.84        92\n",
      "\n",
      "    accuracy                           0.72       112\n",
      "   macro avg       0.47      0.48      0.48       112\n",
      "weighted avg       0.69      0.72      0.71       112\n",
      "\n",
      "[[ 2 18]\n",
      " [13 79]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.15      0.21        20\n",
      "           1       0.83      0.93      0.88        92\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.58      0.54      0.54       112\n",
      "weighted avg       0.75      0.79      0.76       112\n",
      "\n",
      "[[ 3 17]\n",
      " [ 6 86]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.17      0.21        18\n",
      "           1       0.85      0.93      0.89        94\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.58      0.55      0.55       112\n",
      "weighted avg       0.76      0.80      0.78       112\n",
      "\n",
      "[[ 3 15]\n",
      " [ 7 87]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.18      0.21        17\n",
      "           1       0.86      0.91      0.88        95\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.55      0.54      0.54       112\n",
      "weighted avg       0.77      0.79      0.78       112\n",
      "\n",
      "[[ 3 14]\n",
      " [ 9 86]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        17\n",
      "           1       0.84      0.88      0.86        95\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.46      0.47      0.47       112\n",
      "weighted avg       0.73      0.76      0.74       112\n",
      "\n",
      "[[ 1 16]\n",
      " [11 84]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.08      0.12        24\n",
      "           1       0.78      0.91      0.84        88\n",
      "\n",
      "    accuracy                           0.73       112\n",
      "   macro avg       0.49      0.50      0.48       112\n",
      "weighted avg       0.66      0.73      0.69       112\n",
      "\n",
      "[[ 2 22]\n",
      " [ 8 80]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.12      0.16        26\n",
      "           1       0.79      0.91      0.85        94\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.53      0.52      0.50       120\n",
      "weighted avg       0.68      0.74      0.70       120\n",
      "\n",
      "[[ 3 23]\n",
      " [ 8 86]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.23      0.28        22\n",
      "           1       0.84      0.91      0.87        98\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.60      0.57      0.58       120\n",
      "weighted avg       0.75      0.78      0.76       120\n",
      "\n",
      "[[ 5 17]\n",
      " [ 9 89]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.15      0.19        20\n",
      "           1       0.84      0.91      0.87       100\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.55      0.53      0.53       120\n",
      "weighted avg       0.74      0.78      0.76       120\n",
      "\n",
      "[[ 3 17]\n",
      " [ 9 91]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.14      0.15        22\n",
      "           1       0.82      0.86      0.84        98\n",
      "\n",
      "    accuracy                           0.73       120\n",
      "   macro avg       0.50      0.50      0.49       120\n",
      "weighted avg       0.70      0.72      0.71       120\n",
      "\n",
      "[[ 3 19]\n",
      " [14 84]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.18      0.24        22\n",
      "           1       0.83      0.93      0.88        98\n",
      "\n",
      "    accuracy                           0.79       120\n",
      "   macro avg       0.60      0.56      0.56       120\n",
      "weighted avg       0.75      0.79      0.76       120\n",
      "\n",
      "[[ 4 18]\n",
      " [ 7 91]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.16      0.20        19\n",
      "           1       0.85      0.92      0.89       101\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.56      0.54      0.54       120\n",
      "weighted avg       0.76      0.80      0.78       120\n",
      "\n",
      "[[ 3 16]\n",
      " [ 8 93]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.20      0.22        20\n",
      "           1       0.84      0.87      0.86       100\n",
      "\n",
      "    accuracy                           0.76       120\n",
      "   macro avg       0.54      0.54      0.54       120\n",
      "weighted avg       0.74      0.76      0.75       120\n",
      "\n",
      "[[ 4 16]\n",
      " [13 87]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        17\n",
      "           1       0.85      0.89      0.87       103\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.47      0.48      0.47       120\n",
      "weighted avg       0.74      0.78      0.76       120\n",
      "\n",
      "[[ 1 16]\n",
      " [11 92]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.04      0.06        27\n",
      "           1       0.77      0.91      0.83        93\n",
      "\n",
      "    accuracy                           0.72       120\n",
      "   macro avg       0.44      0.48      0.44       120\n",
      "weighted avg       0.62      0.72      0.66       120\n",
      "\n",
      "[[ 1 26]\n",
      " [ 8 85]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 521457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.05      0.08        22\n",
      "           1       0.76      0.96      0.85        69\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.50      0.50      0.46        91\n",
      "weighted avg       0.64      0.74      0.66        91\n",
      "\n",
      "[[ 1 21]\n",
      " [ 3 66]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.17      0.24        18\n",
      "           1       0.82      0.95      0.88        73\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.62      0.56      0.56        91\n",
      "weighted avg       0.74      0.79      0.75        91\n",
      "\n",
      "[[ 3 15]\n",
      " [ 4 69]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.23      0.26        13\n",
      "           1       0.88      0.91      0.89        78\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.59      0.57      0.58        91\n",
      "weighted avg       0.79      0.81      0.80        91\n",
      "\n",
      "[[ 3 10]\n",
      " [ 7 71]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        18\n",
      "           1       0.78      0.85      0.82        73\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.43      0.45      0.44        91\n",
      "weighted avg       0.65      0.69      0.67        91\n",
      "\n",
      "[[ 1 17]\n",
      " [11 62]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.07      0.10        15\n",
      "           1       0.84      0.93      0.88        76\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.50      0.50      0.49        91\n",
      "weighted avg       0.73      0.79      0.75        91\n",
      "\n",
      "[[ 1 14]\n",
      " [ 5 71]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.95      0.88        76\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.41      0.47      0.44        91\n",
      "weighted avg       0.69      0.79      0.74        91\n",
      "\n",
      "[[ 0 15]\n",
      " [ 4 72]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.20      0.21        15\n",
      "           1       0.85      0.87      0.86        76\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.54      0.53      0.54        91\n",
      "weighted avg       0.74      0.76      0.75        91\n",
      "\n",
      "[[ 3 12]\n",
      " [10 66]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.07      0.08        15\n",
      "           1       0.83      0.88      0.85        76\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.46      0.47      0.47        91\n",
      "weighted avg       0.71      0.75      0.73        91\n",
      "\n",
      "[[ 1 14]\n",
      " [ 9 67]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.10      0.16        20\n",
      "           1       0.79      0.96      0.87        71\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.60      0.53      0.51        91\n",
      "weighted avg       0.70      0.77      0.71        91\n",
      "\n",
      "[[ 2 18]\n",
      " [ 3 68]]\n",
      "Accuracy is  0.71\n",
      "The Average of All acuracies 0.728395061728395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x271ea1590c8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length,AverageAcc,GB=GradientBoostClassifier(X,y)\n",
    "Sum_of_Acc_Dtree=sum(AverageAcc)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc_Dtree/length))\n",
    "feautreimportance=pd.Series(GB.feature_importances_, index=Predictorvar)\n",
    "feautreimportance.nlargest(10).plot(kind='bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightbgmclassifier(Data1,Data2):\n",
    "    Test_size=[0.30,0.25,0.21,0.22,0.33,0.36,0.42,0.45,0.34]\n",
    "    Random_state=[521457,7505,32578,5,2567,4789,8547,657,42]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            lgb=LGBMClassifier(max_depth=-1,learning_rate=0.1,n_estimators=300)\n",
    "            predictModel=lgb.fit(X_train,y_train)\n",
    "            predictions=predictModel.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy, lgb )             \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.11      0.15        19\n",
      "           1       0.77      0.92      0.84        61\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.53      0.51      0.49        80\n",
      "weighted avg       0.65      0.72      0.67        80\n",
      "\n",
      "[[ 2 17]\n",
      " [ 5 56]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.14      0.19        14\n",
      "           1       0.84      0.92      0.88        66\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.56      0.53      0.53        80\n",
      "weighted avg       0.74      0.79      0.76        80\n",
      "\n",
      "[[ 2 12]\n",
      " [ 5 61]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.31      0.33        13\n",
      "           1       0.87      0.90      0.88        67\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.62      0.60      0.61        80\n",
      "weighted avg       0.79      0.80      0.79        80\n",
      "\n",
      "[[ 4  9]\n",
      " [ 7 60]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.13      0.18        15\n",
      "           1       0.82      0.92      0.87        65\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.55      0.53      0.53        80\n",
      "weighted avg       0.72      0.78      0.74        80\n",
      "\n",
      "[[ 2 13]\n",
      " [ 5 60]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.08      0.10        13\n",
      "           1       0.84      0.91      0.87        67\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.49      0.49      0.49        80\n",
      "weighted avg       0.72      0.78      0.75        80\n",
      "\n",
      "[[ 1 12]\n",
      " [ 6 61]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      0.94      0.87        66\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.41      0.47      0.44        80\n",
      "weighted avg       0.67      0.78      0.72        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 4 62]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.23      0.29        13\n",
      "           1       0.86      0.93      0.89        67\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.62      0.58      0.59        80\n",
      "weighted avg       0.78      0.81      0.79        80\n",
      "\n",
      "[[ 3 10]\n",
      " [ 5 62]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.08      0.09        13\n",
      "           1       0.83      0.87      0.85        67\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.46      0.47      0.47        80\n",
      "weighted avg       0.71      0.74      0.72        80\n",
      "\n",
      "[[ 1 12]\n",
      " [ 9 58]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.29      0.33        17\n",
      "           1       0.82      0.87      0.85        63\n",
      "\n",
      "    accuracy                           0.75        80\n",
      "   macro avg       0.60      0.58      0.59        80\n",
      "weighted avg       0.73      0.75      0.74        80\n",
      "\n",
      "[[ 5 12]\n",
      " [ 8 55]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.06      0.09        16\n",
      "           1       0.75      0.88      0.81        51\n",
      "\n",
      "    accuracy                           0.69        67\n",
      "   macro avg       0.45      0.47      0.45        67\n",
      "weighted avg       0.61      0.69      0.64        67\n",
      "\n",
      "[[ 1 15]\n",
      " [ 6 45]]\n",
      "Accuracy is  0.64\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.17      0.24        12\n",
      "           1       0.84      0.95      0.89        55\n",
      "\n",
      "    accuracy                           0.81        67\n",
      "   macro avg       0.62      0.56      0.56        67\n",
      "weighted avg       0.76      0.81      0.77        67\n",
      "\n",
      "[[ 2 10]\n",
      " [ 3 52]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.33      0.26         9\n",
      "           1       0.89      0.81      0.85        58\n",
      "\n",
      "    accuracy                           0.75        67\n",
      "   macro avg       0.55      0.57      0.55        67\n",
      "weighted avg       0.80      0.75      0.77        67\n",
      "\n",
      "[[ 3  6]\n",
      " [11 47]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.08      0.12        12\n",
      "           1       0.82      0.93      0.87        55\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.51      0.51      0.49        67\n",
      "weighted avg       0.71      0.78      0.74        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 4 51]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.11        12\n",
      "           1       0.82      0.91      0.86        55\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.70      0.76      0.73        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 5 50]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.79      0.91      0.84        54\n",
      "\n",
      "    accuracy                           0.73        67\n",
      "   macro avg       0.40      0.45      0.42        67\n",
      "weighted avg       0.64      0.73      0.68        67\n",
      "\n",
      "[[ 0 13]\n",
      " [ 5 49]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.09      0.12        11\n",
      "           1       0.84      0.91      0.87        56\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.50      0.50      0.49        67\n",
      "weighted avg       0.73      0.78      0.75        67\n",
      "\n",
      "[[ 1 10]\n",
      " [ 5 51]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.25      0.21         8\n",
      "           1       0.89      0.85      0.87        59\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.54      0.55      0.54        67\n",
      "weighted avg       0.81      0.78      0.79        67\n",
      "\n",
      "[[ 2  6]\n",
      " [ 9 50]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.27      0.36        15\n",
      "           1       0.82      0.94      0.87        52\n",
      "\n",
      "    accuracy                           0.79        67\n",
      "   macro avg       0.69      0.60      0.62        67\n",
      "weighted avg       0.76      0.79      0.76        67\n",
      "\n",
      "[[ 4 11]\n",
      " [ 3 49]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.10      0.13        10\n",
      "           1       0.82      0.91      0.87        46\n",
      "\n",
      "    accuracy                           0.77        56\n",
      "   macro avg       0.51      0.51      0.50        56\n",
      "weighted avg       0.71      0.77      0.74        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 4 42]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 7505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.10      0.14        10\n",
      "           1       0.83      0.93      0.88        46\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.54      0.52      0.51        56\n",
      "weighted avg       0.72      0.79      0.75        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 3 43]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.25      0.22         8\n",
      "           1       0.87      0.83      0.85        48\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.53      0.54      0.54        56\n",
      "weighted avg       0.77      0.75      0.76        56\n",
      "\n",
      "[[ 2  6]\n",
      " [ 8 40]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.77        56\n",
      "   macro avg       0.41      0.46      0.43        56\n",
      "weighted avg       0.69      0.77      0.73        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 4 43]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.09      0.11        11\n",
      "           1       0.79      0.84      0.82        45\n",
      "\n",
      "    accuracy                           0.70        56\n",
      "   macro avg       0.46      0.47      0.46        56\n",
      "weighted avg       0.66      0.70      0.68        56\n",
      "\n",
      "[[ 1 10]\n",
      " [ 7 38]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.84      0.88      0.86        48\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.42      0.44      0.43        56\n",
      "weighted avg       0.72      0.75      0.73        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 6 42]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.27         9\n",
      "           1       0.86      0.91      0.89        47\n",
      "\n",
      "    accuracy                           0.80        56\n",
      "   macro avg       0.60      0.57      0.58        56\n",
      "weighted avg       0.78      0.80      0.79        56\n",
      "\n",
      "[[ 2  7]\n",
      " [ 4 43]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.12      0.12         8\n",
      "           1       0.85      0.85      0.85        48\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.49      0.49      0.49        56\n",
      "weighted avg       0.75      0.75      0.75        56\n",
      "\n",
      "[[ 1  7]\n",
      " [ 7 41]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.23      0.33        13\n",
      "           1       0.80      0.95      0.87        43\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.70      0.59      0.60        56\n",
      "weighted avg       0.76      0.79      0.75        56\n",
      "\n",
      "[[ 3 10]\n",
      " [ 2 41]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.11        13\n",
      "           1       0.77      0.89      0.83        46\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.47      0.48      0.47        59\n",
      "weighted avg       0.64      0.71      0.67        59\n",
      "\n",
      "[[ 1 12]\n",
      " [ 5 41]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25        10\n",
      "           1       0.85      0.92      0.88        49\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.59      0.56      0.57        59\n",
      "weighted avg       0.76      0.80      0.78        59\n",
      "\n",
      "[[ 2  8]\n",
      " [ 4 45]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33         9\n",
      "           1       0.88      0.88      0.88        50\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.61      0.61      0.61        59\n",
      "weighted avg       0.80      0.80      0.80        59\n",
      "\n",
      "[[ 3  6]\n",
      " [ 6 44]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.82      0.92      0.87        49\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.41      0.46      0.43        59\n",
      "weighted avg       0.68      0.76      0.72        59\n",
      "\n",
      "[[ 0 10]\n",
      " [ 4 45]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.11        12\n",
      "           1       0.79      0.89      0.84        47\n",
      "\n",
      "    accuracy                           0.73        59\n",
      "   macro avg       0.48      0.49      0.48        59\n",
      "weighted avg       0.67      0.73      0.69        59\n",
      "\n",
      "[[ 1 11]\n",
      " [ 5 42]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.83      0.88      0.85        50\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.42      0.44      0.43        59\n",
      "weighted avg       0.70      0.75      0.72        59\n",
      "\n",
      "[[ 0  9]\n",
      " [ 6 44]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.18      0.24        11\n",
      "           1       0.83      0.92      0.87        48\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.58      0.55      0.55        59\n",
      "weighted avg       0.74      0.78      0.75        59\n",
      "\n",
      "[[ 2  9]\n",
      " [ 4 44]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.25      0.21         8\n",
      "           1       0.88      0.82      0.85        51\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.53      0.54      0.53        59\n",
      "weighted avg       0.78      0.75      0.76        59\n",
      "\n",
      "[[ 2  6]\n",
      " [ 9 42]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.21      0.33        14\n",
      "           1       0.80      0.98      0.88        45\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.78      0.60      0.61        59\n",
      "weighted avg       0.79      0.80      0.75        59\n",
      "\n",
      "[[ 3 11]\n",
      " [ 1 44]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.19      0.24        21\n",
      "           1       0.77      0.87      0.82        67\n",
      "\n",
      "    accuracy                           0.70        88\n",
      "   macro avg       0.54      0.53      0.53        88\n",
      "weighted avg       0.66      0.70      0.68        88\n",
      "\n",
      "[[ 4 17]\n",
      " [ 9 58]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.06      0.08        18\n",
      "           1       0.79      0.91      0.85        70\n",
      "\n",
      "    accuracy                           0.74        88\n",
      "   macro avg       0.47      0.48      0.46        88\n",
      "weighted avg       0.66      0.74      0.69        88\n",
      "\n",
      "[[ 1 17]\n",
      " [ 6 64]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.38      0.33        13\n",
      "           1       0.89      0.84      0.86        75\n",
      "\n",
      "    accuracy                           0.77        88\n",
      "   macro avg       0.59      0.61      0.60        88\n",
      "weighted avg       0.80      0.77      0.78        88\n",
      "\n",
      "[[ 5  8]\n",
      " [12 63]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.11      0.15        18\n",
      "           1       0.80      0.91      0.85        70\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.53      0.51      0.50        88\n",
      "weighted avg       0.69      0.75      0.71        88\n",
      "\n",
      "[[ 2 16]\n",
      " [ 6 64]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      0.85      0.83        74\n",
      "\n",
      "    accuracy                           0.72        88\n",
      "   macro avg       0.41      0.43      0.42        88\n",
      "weighted avg       0.69      0.72      0.70        88\n",
      "\n",
      "[[ 0 14]\n",
      " [11 63]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.13      0.18        15\n",
      "           1       0.84      0.93      0.88        73\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.56      0.53      0.53        88\n",
      "weighted avg       0.75      0.80      0.76        88\n",
      "\n",
      "[[ 2 13]\n",
      " [ 5 68]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.27      0.31        15\n",
      "           1       0.86      0.90      0.88        73\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.61      0.59      0.59        88\n",
      "weighted avg       0.77      0.80      0.78        88\n",
      "\n",
      "[[ 4 11]\n",
      " [ 7 66]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.13      0.15        15\n",
      "           1       0.83      0.86      0.85        73\n",
      "\n",
      "    accuracy                           0.74        88\n",
      "   macro avg       0.50      0.50      0.50        88\n",
      "weighted avg       0.72      0.74      0.73        88\n",
      "\n",
      "[[ 2 13]\n",
      " [10 63]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.05      0.08        20\n",
      "           1       0.77      0.94      0.85        68\n",
      "\n",
      "    accuracy                           0.74        88\n",
      "   macro avg       0.49      0.50      0.46        88\n",
      "weighted avg       0.64      0.74      0.67        88\n",
      "\n",
      "[[ 1 19]\n",
      " [ 4 64]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.13      0.19        23\n",
      "           1       0.77      0.92      0.84        73\n",
      "\n",
      "    accuracy                           0.73        96\n",
      "   macro avg       0.55      0.52      0.51        96\n",
      "weighted avg       0.67      0.73      0.68        96\n",
      "\n",
      "[[ 3 20]\n",
      " [ 6 67]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.05      0.08        19\n",
      "           1       0.80      0.92      0.86        77\n",
      "\n",
      "    accuracy                           0.75        96\n",
      "   macro avg       0.47      0.49      0.47        96\n",
      "weighted avg       0.67      0.75      0.70        96\n",
      "\n",
      "[[ 1 18]\n",
      " [ 6 71]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.29      0.26        14\n",
      "           1       0.87      0.84      0.86        82\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.55      0.56      0.56        96\n",
      "weighted avg       0.78      0.76      0.77        96\n",
      "\n",
      "[[ 4 10]\n",
      " [13 69]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.06      0.08        18\n",
      "           1       0.81      0.92      0.86        78\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.48      0.49      0.47        96\n",
      "weighted avg       0.68      0.76      0.72        96\n",
      "\n",
      "[[ 1 17]\n",
      " [ 6 72]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.06      0.07        16\n",
      "           1       0.82      0.88      0.85        80\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.46      0.47      0.46        96\n",
      "weighted avg       0.70      0.74      0.72        96\n",
      "\n",
      "[[ 1 15]\n",
      " [10 70]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.07      0.09        15\n",
      "           1       0.84      0.93      0.88        81\n",
      "\n",
      "    accuracy                           0.79        96\n",
      "   macro avg       0.49      0.50      0.49        96\n",
      "weighted avg       0.73      0.79      0.76        96\n",
      "\n",
      "[[ 1 14]\n",
      " [ 6 75]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.20      0.22        15\n",
      "           1       0.86      0.89      0.87        81\n",
      "\n",
      "    accuracy                           0.78        96\n",
      "   macro avg       0.55      0.54      0.55        96\n",
      "weighted avg       0.76      0.78      0.77        96\n",
      "\n",
      "[[ 3 12]\n",
      " [ 9 72]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.06      0.07        16\n",
      "           1       0.82      0.88      0.85        80\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.46      0.47      0.46        96\n",
      "weighted avg       0.70      0.74      0.72        96\n",
      "\n",
      "[[ 1 15]\n",
      " [10 70]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15        21\n",
      "           1       0.79      0.95      0.86        75\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.56      0.52      0.50        96\n",
      "weighted avg       0.69      0.76      0.70        96\n",
      "\n",
      "[[ 2 19]\n",
      " [ 4 71]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.08      0.13        24\n",
      "           1       0.79      0.94      0.86        88\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.54      0.51      0.49       112\n",
      "weighted avg       0.68      0.76      0.70       112\n",
      "\n",
      "[[ 2 22]\n",
      " [ 5 83]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        22\n",
      "           1       0.81      0.93      0.87        90\n",
      "\n",
      "    accuracy                           0.77       112\n",
      "   macro avg       0.53      0.51      0.50       112\n",
      "weighted avg       0.70      0.77      0.72       112\n",
      "\n",
      "[[ 2 20]\n",
      " [ 6 84]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24        17\n",
      "           1       0.86      0.87      0.87        95\n",
      "\n",
      "    accuracy                           0.78       112\n",
      "   macro avg       0.56      0.55      0.56       112\n",
      "weighted avg       0.77      0.78      0.77       112\n",
      "\n",
      "[[ 4 13]\n",
      " [12 83]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.05      0.06        20\n",
      "           1       0.81      0.88      0.84        92\n",
      "\n",
      "    accuracy                           0.73       112\n",
      "   macro avg       0.45      0.47      0.45       112\n",
      "weighted avg       0.68      0.73      0.70       112\n",
      "\n",
      "[[ 1 19]\n",
      " [11 81]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.05      0.08        20\n",
      "           1       0.82      0.95      0.88        92\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.49      0.50      0.48       112\n",
      "weighted avg       0.70      0.79      0.74       112\n",
      "\n",
      "[[ 1 19]\n",
      " [ 5 87]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.17      0.20        18\n",
      "           1       0.85      0.90      0.88        94\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.55      0.54      0.54       112\n",
      "weighted avg       0.75      0.79      0.77       112\n",
      "\n",
      "[[ 3 15]\n",
      " [ 9 85]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.12      0.12        17\n",
      "           1       0.85      0.86      0.85        95\n",
      "\n",
      "    accuracy                           0.75       112\n",
      "   macro avg       0.49      0.49      0.49       112\n",
      "weighted avg       0.74      0.75      0.74       112\n",
      "\n",
      "[[ 2 15]\n",
      " [13 82]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.18      0.18        17\n",
      "           1       0.85      0.86      0.86        95\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.52      0.52      0.52       112\n",
      "weighted avg       0.75      0.76      0.76       112\n",
      "\n",
      "[[ 3 14]\n",
      " [13 82]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.04      0.06        24\n",
      "           1       0.78      0.92      0.84        88\n",
      "\n",
      "    accuracy                           0.73       112\n",
      "   macro avg       0.45      0.48      0.45       112\n",
      "weighted avg       0.64      0.73      0.68       112\n",
      "\n",
      "[[ 1 23]\n",
      " [ 7 81]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.15      0.20        26\n",
      "           1       0.79      0.88      0.83        94\n",
      "\n",
      "    accuracy                           0.73       120\n",
      "   macro avg       0.53      0.52      0.51       120\n",
      "weighted avg       0.68      0.72      0.70       120\n",
      "\n",
      "[[ 4 22]\n",
      " [11 83]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.14      0.16        22\n",
      "           1       0.82      0.87      0.84        98\n",
      "\n",
      "    accuracy                           0.73       120\n",
      "   macro avg       0.50      0.50      0.50       120\n",
      "weighted avg       0.70      0.73      0.72       120\n",
      "\n",
      "[[ 3 19]\n",
      " [13 85]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.20      0.24        20\n",
      "           1       0.85      0.90      0.87       100\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.57      0.55      0.55       120\n",
      "weighted avg       0.76      0.78      0.77       120\n",
      "\n",
      "[[ 4 16]\n",
      " [10 90]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        22\n",
      "           1       0.82      0.94      0.88        98\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.54      0.51      0.50       120\n",
      "weighted avg       0.72      0.78      0.74       120\n",
      "\n",
      "[[ 2 20]\n",
      " [ 6 92]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.14      0.18        22\n",
      "           1       0.83      0.92      0.87        98\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.55      0.53      0.53       120\n",
      "weighted avg       0.72      0.78      0.74       120\n",
      "\n",
      "[[ 3 19]\n",
      " [ 8 90]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.16      0.18        19\n",
      "           1       0.85      0.89      0.87       101\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.53      0.52      0.53       120\n",
      "weighted avg       0.75      0.78      0.76       120\n",
      "\n",
      "[[ 3 16]\n",
      " [11 90]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.05      0.06        20\n",
      "           1       0.82      0.89      0.86       100\n",
      "\n",
      "    accuracy                           0.75       120\n",
      "   macro avg       0.45      0.47      0.46       120\n",
      "weighted avg       0.70      0.75      0.72       120\n",
      "\n",
      "[[ 1 19]\n",
      " [11 89]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.24      0.21        17\n",
      "           1       0.87      0.83      0.85       103\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.52      0.53      0.53       120\n",
      "weighted avg       0.77      0.74      0.76       120\n",
      "\n",
      "[[ 4 13]\n",
      " [18 85]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.07      0.11        27\n",
      "           1       0.78      0.94      0.85        93\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.51      0.50      0.48       120\n",
      "weighted avg       0.66      0.74      0.68       120\n",
      "\n",
      "[[ 2 25]\n",
      " [ 6 87]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 521457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.18      0.26        22\n",
      "           1       0.78      0.93      0.85        69\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.61      0.55      0.55        91\n",
      "weighted avg       0.70      0.75      0.71        91\n",
      "\n",
      "[[ 4 18]\n",
      " [ 5 64]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.06      0.08        18\n",
      "           1       0.80      0.93      0.86        73\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.48      0.49      0.47        91\n",
      "weighted avg       0.67      0.76      0.71        91\n",
      "\n",
      "[[ 1 17]\n",
      " [ 5 68]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 32578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.31      0.28        13\n",
      "           1       0.88      0.85      0.86        78\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.56      0.58      0.57        91\n",
      "weighted avg       0.79      0.77      0.78        91\n",
      "\n",
      "[[ 4  9]\n",
      " [12 66]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.06      0.08        18\n",
      "           1       0.80      0.93      0.86        73\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.48      0.49      0.47        91\n",
      "weighted avg       0.67      0.76      0.71        91\n",
      "\n",
      "[[ 1 17]\n",
      " [ 5 68]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.07      0.08        15\n",
      "           1       0.82      0.87      0.85        76\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.46      0.47      0.46        91\n",
      "weighted avg       0.70      0.74      0.72        91\n",
      "\n",
      "[[ 1 14]\n",
      " [10 66]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.13      0.18        15\n",
      "           1       0.85      0.93      0.89        76\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.57      0.53      0.53        91\n",
      "weighted avg       0.75      0.80      0.77        91\n",
      "\n",
      "[[ 2 13]\n",
      " [ 5 71]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.20      0.24        15\n",
      "           1       0.85      0.91      0.88        76\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.58      0.55      0.56        91\n",
      "weighted avg       0.76      0.79      0.77        91\n",
      "\n",
      "[[ 3 12]\n",
      " [ 7 69]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.07      0.07        15\n",
      "           1       0.82      0.86      0.84        76\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.45      0.46      0.46        91\n",
      "weighted avg       0.70      0.73      0.71        91\n",
      "\n",
      "[[ 1 14]\n",
      " [11 65]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.05      0.08        20\n",
      "           1       0.78      0.94      0.85        71\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.49      0.50      0.47        91\n",
      "weighted avg       0.65      0.75      0.68        91\n",
      "\n",
      "[[ 1 19]\n",
      " [ 4 67]]\n",
      "Accuracy is  0.68\n",
      "The Average of All acuracies 0.7333333333333338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x271ea2e5f08>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length,AverageAcc,LGB=lightbgmclassifier(X,y)\n",
    "Sum_of_Acc_Dtree=sum(AverageAcc)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc_Dtree/length))\n",
    "feautreimportance=pd.Series(LGB.feature_importances_, index=Predictorvar)\n",
    "feautreimportance.nlargest(10).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmclassifier(Data1,Data2):\n",
    "    Test_size=[0.30,0.25,0.21,0.22,0.33,0.36,0.42,0.45,0.34]\n",
    "    Random_state=[525478,7505,32578,3257,2567,4789,8547,657,42]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            SVC=svm.SVC(C=5, kernel='rbf', gamma=0.01)\n",
    "            predictModel=SVC.fit(X_train,y_train)\n",
    "            predictions=predictModel.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy,SVC )             \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.15      0.21        13\n",
      "           1       0.85      0.94      0.89        67\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.59      0.55      0.55        80\n",
      "weighted avg       0.77      0.81      0.78        80\n",
      "\n",
      "[[ 2 11]\n",
      " [ 4 63]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.07      0.10        14\n",
      "           1       0.82      0.91      0.86        66\n",
      "\n",
      "    accuracy                           0.76        80\n",
      "   macro avg       0.48      0.49      0.48        80\n",
      "weighted avg       0.70      0.76      0.73        80\n",
      "\n",
      "[[ 1 13]\n",
      " [ 6 60]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        13\n",
      "           1       0.84      0.96      0.90        67\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.55      0.52      0.51        80\n",
      "weighted avg       0.75      0.81      0.77        80\n",
      "\n",
      "[[ 1 12]\n",
      " [ 3 64]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.21      0.27        14\n",
      "           1       0.85      0.92      0.88        66\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.61      0.57      0.58        80\n",
      "weighted avg       0.76      0.80      0.78        80\n",
      "\n",
      "[[ 3 11]\n",
      " [ 5 61]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.08      0.12        13\n",
      "           1       0.84      0.97      0.90        67\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.59      0.52      0.51        80\n",
      "weighted avg       0.76      0.82      0.78        80\n",
      "\n",
      "[[ 1 12]\n",
      " [ 2 65]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      0.94      0.87        66\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.41      0.47      0.44        80\n",
      "weighted avg       0.67      0.78      0.72        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 4 62]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.23      0.29        13\n",
      "           1       0.86      0.93      0.89        67\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.62      0.58      0.59        80\n",
      "weighted avg       0.78      0.81      0.79        80\n",
      "\n",
      "[[ 3 10]\n",
      " [ 5 62]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.83      0.93      0.87        67\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.41      0.46      0.44        80\n",
      "weighted avg       0.69      0.78      0.73        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 5 62]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.18      0.25        17\n",
      "           1       0.81      0.94      0.87        63\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.62      0.56      0.56        80\n",
      "weighted avg       0.73      0.78      0.74        80\n",
      "\n",
      "[[ 3 14]\n",
      " [ 4 59]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.18      0.29        11\n",
      "           1       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.85        67\n",
      "   macro avg       0.76      0.58      0.60        67\n",
      "weighted avg       0.83      0.85      0.81        67\n",
      "\n",
      "[[ 2  9]\n",
      " [ 1 55]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.11        12\n",
      "           1       0.82      0.91      0.86        55\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.70      0.76      0.73        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 5 50]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.27         9\n",
      "           1       0.89      0.93      0.91        58\n",
      "\n",
      "    accuracy                           0.84        67\n",
      "   macro avg       0.61      0.58      0.59        67\n",
      "weighted avg       0.81      0.84      0.82        67\n",
      "\n",
      "[[ 2  7]\n",
      " [ 4 54]]\n",
      "Accuracy is  0.82\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.08      0.13        12\n",
      "           1       0.83      0.96      0.89        55\n",
      "\n",
      "    accuracy                           0.81        67\n",
      "   macro avg       0.58      0.52      0.51        67\n",
      "weighted avg       0.74      0.81      0.76        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 2 53]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.08      0.14        12\n",
      "           1       0.83      0.98      0.90        55\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.67      0.53      0.52        67\n",
      "weighted avg       0.77      0.82      0.76        67\n",
      "\n",
      "[[ 1 11]\n",
      " [ 1 54]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.80      0.94      0.86        54\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.40      0.47      0.43        67\n",
      "weighted avg       0.64      0.76      0.70        67\n",
      "\n",
      "[[ 0 13]\n",
      " [ 3 51]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.09      0.14        11\n",
      "           1       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.59      0.53      0.52        67\n",
      "weighted avg       0.76      0.82      0.78        67\n",
      "\n",
      "[[ 1 10]\n",
      " [ 2 54]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.12      0.14         8\n",
      "           1       0.89      0.92      0.90        59\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.53      0.52      0.52        67\n",
      "weighted avg       0.80      0.82      0.81        67\n",
      "\n",
      "[[ 1  7]\n",
      " [ 5 54]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.20      0.27        15\n",
      "           1       0.80      0.92      0.86        52\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.61      0.56      0.56        67\n",
      "weighted avg       0.72      0.76      0.73        67\n",
      "\n",
      "[[ 3 12]\n",
      " [ 4 48]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.17        10\n",
      "           1       0.83      0.98      0.90        46\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.67      0.54      0.53        56\n",
      "weighted avg       0.77      0.82      0.77        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 1 45]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.10      0.12        10\n",
      "           1       0.82      0.89      0.85        46\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.49      0.50      0.49        56\n",
      "weighted avg       0.70      0.75      0.72        56\n",
      "\n",
      "[[ 1  9]\n",
      " [ 5 41]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.12      0.15         8\n",
      "           1       0.86      0.92      0.89        48\n",
      "\n",
      "    accuracy                           0.80        56\n",
      "   macro avg       0.53      0.52      0.52        56\n",
      "weighted avg       0.77      0.80      0.78        56\n",
      "\n",
      "[[ 1  7]\n",
      " [ 4 44]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.83      0.94      0.88        47\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.42      0.47      0.44        56\n",
      "weighted avg       0.70      0.79      0.74        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 3 44]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.09      0.15        11\n",
      "           1       0.81      0.98      0.89        45\n",
      "\n",
      "    accuracy                           0.80        56\n",
      "   macro avg       0.66      0.53      0.52        56\n",
      "weighted avg       0.75      0.80      0.74        56\n",
      "\n",
      "[[ 1 10]\n",
      " [ 1 44]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.85      0.96      0.90        48\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.43      0.48      0.45        56\n",
      "weighted avg       0.73      0.82      0.77        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 2 46]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.11      0.18         9\n",
      "           1       0.85      0.98      0.91        47\n",
      "\n",
      "    accuracy                           0.84        56\n",
      "   macro avg       0.68      0.54      0.55        56\n",
      "weighted avg       0.80      0.84      0.79        56\n",
      "\n",
      "[[ 1  8]\n",
      " [ 1 46]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.12      0.15         8\n",
      "           1       0.86      0.92      0.89        48\n",
      "\n",
      "    accuracy                           0.80        56\n",
      "   macro avg       0.53      0.52      0.52        56\n",
      "weighted avg       0.77      0.80      0.78        56\n",
      "\n",
      "[[ 1  7]\n",
      " [ 4 44]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.23      0.29        13\n",
      "           1       0.79      0.88      0.84        43\n",
      "\n",
      "    accuracy                           0.73        56\n",
      "   macro avg       0.58      0.56      0.56        56\n",
      "weighted avg       0.69      0.73      0.71        56\n",
      "\n",
      "[[ 3 10]\n",
      " [ 5 38]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.09      0.15        11\n",
      "           1       0.82      0.98      0.90        48\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.66      0.54      0.52        59\n",
      "weighted avg       0.76      0.81      0.76        59\n",
      "\n",
      "[[ 1 10]\n",
      " [ 1 47]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.10      0.12        10\n",
      "           1       0.83      0.90      0.86        49\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.50      0.50      0.49        59\n",
      "weighted avg       0.72      0.76      0.74        59\n",
      "\n",
      "[[ 1  9]\n",
      " [ 5 44]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      0.98      0.91        50\n",
      "\n",
      "    accuracy                           0.83        59\n",
      "   macro avg       0.42      0.49      0.45        59\n",
      "weighted avg       0.72      0.83      0.77        59\n",
      "\n",
      "[[ 0  9]\n",
      " [ 1 49]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.08      0.13        12\n",
      "           1       0.80      0.96      0.87        47\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.57      0.52      0.50        59\n",
      "weighted avg       0.71      0.78      0.72        59\n",
      "\n",
      "[[ 1 11]\n",
      " [ 2 45]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.08      0.14        12\n",
      "           1       0.81      0.98      0.88        47\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.65      0.53      0.51        59\n",
      "weighted avg       0.74      0.80      0.73        59\n",
      "\n",
      "[[ 1 11]\n",
      " [ 1 46]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      0.94      0.89        50\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.42      0.47      0.44        59\n",
      "weighted avg       0.71      0.80      0.75        59\n",
      "\n",
      "[[ 0  9]\n",
      " [ 3 47]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.09      0.15        11\n",
      "           1       0.82      0.98      0.90        48\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.66      0.54      0.52        59\n",
      "weighted avg       0.76      0.81      0.76        59\n",
      "\n",
      "[[ 1 10]\n",
      " [ 1 47]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.12      0.15         8\n",
      "           1       0.87      0.92      0.90        51\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.54      0.52      0.52        59\n",
      "weighted avg       0.78      0.81      0.79        59\n",
      "\n",
      "[[ 1  7]\n",
      " [ 4 47]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.21      0.29        14\n",
      "           1       0.79      0.91      0.85        45\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.61      0.56      0.57        59\n",
      "weighted avg       0.70      0.75      0.71        59\n",
      "\n",
      "[[ 3 11]\n",
      " [ 4 41]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.12      0.17        16\n",
      "           1       0.83      0.93      0.88        72\n",
      "\n",
      "    accuracy                           0.78        88\n",
      "   macro avg       0.56      0.53      0.52        88\n",
      "weighted avg       0.73      0.78      0.75        88\n",
      "\n",
      "[[ 2 14]\n",
      " [ 5 67]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.11      0.16        18\n",
      "           1       0.80      0.93      0.86        70\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.54      0.52      0.51        88\n",
      "weighted avg       0.70      0.76      0.72        88\n",
      "\n",
      "[[ 2 16]\n",
      " [ 5 65]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        13\n",
      "           1       0.86      0.96      0.91        75\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.55      0.52      0.51        88\n",
      "weighted avg       0.77      0.83      0.79        88\n",
      "\n",
      "[[ 1 12]\n",
      " [ 3 72]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.20      0.26        15\n",
      "           1       0.85      0.93      0.89        73\n",
      "\n",
      "    accuracy                           0.81        88\n",
      "   macro avg       0.61      0.57      0.57        88\n",
      "weighted avg       0.77      0.81      0.78        88\n",
      "\n",
      "[[ 3 12]\n",
      " [ 5 68]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.07      0.12        14\n",
      "           1       0.85      0.97      0.91        74\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.59      0.52      0.51        88\n",
      "weighted avg       0.77      0.83      0.78        88\n",
      "\n",
      "[[ 1 13]\n",
      " [ 2 72]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.07      0.10        15\n",
      "           1       0.83      0.95      0.88        73\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.52      0.51      0.49        88\n",
      "weighted avg       0.72      0.80      0.75        88\n",
      "\n",
      "[[ 1 14]\n",
      " [ 4 69]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.20      0.27        15\n",
      "           1       0.85      0.95      0.90        73\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.64      0.57      0.58        88\n",
      "weighted avg       0.78      0.82      0.79        88\n",
      "\n",
      "[[ 3 12]\n",
      " [ 4 69]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.82      0.93      0.87        73\n",
      "\n",
      "    accuracy                           0.77        88\n",
      "   macro avg       0.41      0.47      0.44        88\n",
      "weighted avg       0.68      0.77      0.72        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 5 68]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.05      0.09        20\n",
      "           1       0.78      0.97      0.86        68\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.55      0.51      0.47        88\n",
      "weighted avg       0.68      0.76      0.69        88\n",
      "\n",
      "[[ 1 19]\n",
      " [ 2 66]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.12      0.17        16\n",
      "           1       0.84      0.94      0.89        80\n",
      "\n",
      "    accuracy                           0.80        96\n",
      "   macro avg       0.56      0.53      0.53        96\n",
      "weighted avg       0.75      0.80      0.77        96\n",
      "\n",
      "[[ 2 14]\n",
      " [ 5 75]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.11      0.15        19\n",
      "           1       0.81      0.94      0.87        77\n",
      "\n",
      "    accuracy                           0.77        96\n",
      "   macro avg       0.55      0.52      0.51        96\n",
      "weighted avg       0.71      0.77      0.73        96\n",
      "\n",
      "[[ 2 17]\n",
      " [ 5 72]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.07      0.11        14\n",
      "           1       0.86      0.95      0.90        82\n",
      "\n",
      "    accuracy                           0.82        96\n",
      "   macro avg       0.53      0.51      0.50        96\n",
      "weighted avg       0.76      0.82      0.79        96\n",
      "\n",
      "[[ 1 13]\n",
      " [ 4 78]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.25      0.32        16\n",
      "           1       0.86      0.94      0.90        80\n",
      "\n",
      "    accuracy                           0.82        96\n",
      "   macro avg       0.65      0.59      0.61        96\n",
      "weighted avg       0.79      0.82      0.80        96\n",
      "\n",
      "[[ 4 12]\n",
      " [ 5 75]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.11        16\n",
      "           1       0.84      0.99      0.91        80\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.67      0.53      0.51        96\n",
      "weighted avg       0.78      0.83      0.78        96\n",
      "\n",
      "[[ 1 15]\n",
      " [ 1 79]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.07      0.10        15\n",
      "           1       0.85      0.95      0.90        81\n",
      "\n",
      "    accuracy                           0.81        96\n",
      "   macro avg       0.52      0.51      0.50        96\n",
      "weighted avg       0.75      0.81      0.77        96\n",
      "\n",
      "[[ 1 14]\n",
      " [ 4 77]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.20      0.27        15\n",
      "           1       0.87      0.95      0.91        81\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.65      0.58      0.59        96\n",
      "weighted avg       0.80      0.83      0.81        96\n",
      "\n",
      "[[ 3 12]\n",
      " [ 4 77]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.82      0.93      0.87        80\n",
      "\n",
      "    accuracy                           0.77        96\n",
      "   macro avg       0.41      0.46      0.44        96\n",
      "weighted avg       0.69      0.77      0.73        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 6 74]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.05      0.08        21\n",
      "           1       0.78      0.97      0.87        75\n",
      "\n",
      "    accuracy                           0.77        96\n",
      "   macro avg       0.56      0.51      0.48        96\n",
      "weighted avg       0.69      0.77      0.70        96\n",
      "\n",
      "[[ 1 20]\n",
      " [ 2 73]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.11      0.14        18\n",
      "           1       0.84      0.90      0.87        94\n",
      "\n",
      "    accuracy                           0.78       112\n",
      "   macro avg       0.51      0.51      0.50       112\n",
      "weighted avg       0.74      0.78      0.75       112\n",
      "\n",
      "[[ 2 16]\n",
      " [ 9 85]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.09      0.14        22\n",
      "           1       0.81      0.96      0.88        90\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.57      0.52      0.51       112\n",
      "weighted avg       0.72      0.79      0.73       112\n",
      "\n",
      "[[ 2 20]\n",
      " [ 4 86]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.84      0.97      0.90        95\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.42      0.48      0.45       112\n",
      "weighted avg       0.72      0.82      0.77       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 3 92]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.24      0.30        17\n",
      "           1       0.87      0.94      0.90        95\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.64      0.59      0.60       112\n",
      "weighted avg       0.80      0.83      0.81       112\n",
      "\n",
      "[[ 4 13]\n",
      " [ 6 89]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.05      0.09        20\n",
      "           1       0.83      0.99      0.90        92\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.66      0.52      0.50       112\n",
      "weighted avg       0.77      0.82      0.76       112\n",
      "\n",
      "[[ 1 19]\n",
      " [ 1 91]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17        18\n",
      "           1       0.85      0.96      0.90        94\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.59      0.53      0.53       112\n",
      "weighted avg       0.77      0.82      0.78       112\n",
      "\n",
      "[[ 2 16]\n",
      " [ 4 90]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.18      0.24        17\n",
      "           1       0.87      0.95      0.90        95\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.62      0.56      0.57       112\n",
      "weighted avg       0.79      0.83      0.80       112\n",
      "\n",
      "[[ 3 14]\n",
      " [ 5 90]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.06      0.08        17\n",
      "           1       0.84      0.92      0.88        95\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.48      0.49      0.48       112\n",
      "weighted avg       0.73      0.79      0.76       112\n",
      "\n",
      "[[ 1 16]\n",
      " [ 8 87]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.12      0.21        24\n",
      "           1       0.80      0.98      0.88        88\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.70      0.55      0.54       112\n",
      "weighted avg       0.76      0.79      0.74       112\n",
      "\n",
      "[[ 3 21]\n",
      " [ 2 86]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.10      0.14        21\n",
      "           1       0.83      0.94      0.88        99\n",
      "\n",
      "    accuracy                           0.79       120\n",
      "   macro avg       0.54      0.52      0.51       120\n",
      "weighted avg       0.73      0.79      0.75       120\n",
      "\n",
      "[[ 2 19]\n",
      " [ 6 93]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.09      0.14        22\n",
      "           1       0.82      0.96      0.89        98\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.58      0.53      0.51       120\n",
      "weighted avg       0.73      0.80      0.75       120\n",
      "\n",
      "[[ 2 20]\n",
      " [ 4 94]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.83      0.98      0.90       100\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.42      0.49      0.45       120\n",
      "weighted avg       0.69      0.82      0.75       120\n",
      "\n",
      "[[ 0 20]\n",
      " [ 2 98]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.24      0.28        17\n",
      "           1       0.88      0.92      0.90       103\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.61      0.58      0.59       120\n",
      "weighted avg       0.80      0.82      0.81       120\n",
      "\n",
      "[[ 4 13]\n",
      " [ 8 95]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.09      0.15        22\n",
      "           1       0.83      0.97      0.89        98\n",
      "\n",
      "    accuracy                           0.81       120\n",
      "   macro avg       0.61      0.53      0.52       120\n",
      "weighted avg       0.75      0.81      0.76       120\n",
      "\n",
      "[[ 2 20]\n",
      " [ 3 95]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.16      0.22        19\n",
      "           1       0.86      0.95      0.90       101\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.62      0.55      0.56       120\n",
      "weighted avg       0.78      0.82      0.79       120\n",
      "\n",
      "[[ 3 16]\n",
      " [ 5 96]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.15      0.21        20\n",
      "           1       0.85      0.95      0.90       100\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.61      0.55      0.56       120\n",
      "weighted avg       0.77      0.82      0.78       120\n",
      "\n",
      "[[ 3 17]\n",
      " [ 5 95]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.06      0.08        17\n",
      "           1       0.86      0.92      0.89       103\n",
      "\n",
      "    accuracy                           0.80       120\n",
      "   macro avg       0.48      0.49      0.48       120\n",
      "weighted avg       0.75      0.80      0.77       120\n",
      "\n",
      "[[ 1 16]\n",
      " [ 8 95]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.11      0.18        27\n",
      "           1       0.79      0.97      0.87        93\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.64      0.54      0.53       120\n",
      "weighted avg       0.72      0.78      0.71       120\n",
      "\n",
      "[[ 3 24]\n",
      " [ 3 90]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.12      0.17        16\n",
      "           1       0.83      0.93      0.88        75\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.56      0.53      0.53        91\n",
      "weighted avg       0.74      0.79      0.76        91\n",
      "\n",
      "[[ 2 14]\n",
      " [ 5 70]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.11      0.16        18\n",
      "           1       0.81      0.93      0.87        73\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.55      0.52      0.51        91\n",
      "weighted avg       0.71      0.77      0.73        91\n",
      "\n",
      "[[ 2 16]\n",
      " [ 5 68]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        13\n",
      "           1       0.86      0.96      0.91        78\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.56      0.52      0.51        91\n",
      "weighted avg       0.77      0.84      0.80        91\n",
      "\n",
      "[[ 1 12]\n",
      " [ 3 75]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.25      0.32        16\n",
      "           1       0.85      0.93      0.89        75\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.65      0.59      0.61        91\n",
      "weighted avg       0.78      0.81      0.79        91\n",
      "\n",
      "[[ 4 12]\n",
      " [ 5 70]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.13      0.21        15\n",
      "           1       0.85      0.97      0.91        76\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.68      0.55      0.56        91\n",
      "weighted avg       0.79      0.84      0.79        91\n",
      "\n",
      "[[ 2 13]\n",
      " [ 2 74]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.07      0.10        15\n",
      "           1       0.84      0.95      0.89        76\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.52      0.51      0.49        91\n",
      "weighted avg       0.73      0.80      0.76        91\n",
      "\n",
      "[[ 1 14]\n",
      " [ 4 72]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.20      0.27        15\n",
      "           1       0.86      0.95      0.90        76\n",
      "\n",
      "    accuracy                           0.82        91\n",
      "   macro avg       0.64      0.57      0.59        91\n",
      "weighted avg       0.79      0.82      0.80        91\n",
      "\n",
      "[[ 3 12]\n",
      " [ 4 72]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.82      0.92      0.87        76\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.41      0.46      0.43        91\n",
      "weighted avg       0.69      0.77      0.73        91\n",
      "\n",
      "[[ 0 15]\n",
      " [ 6 70]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.05      0.09        20\n",
      "           1       0.78      0.97      0.87        71\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.56      0.51      0.48        91\n",
      "weighted avg       0.69      0.77      0.70        91\n",
      "\n",
      "[[ 1 19]\n",
      " [ 2 69]]\n",
      "Accuracy is  0.70\n",
      "The Average of All acuracies 0.7596296296296294\n"
     ]
    }
   ],
   "source": [
    "length,AverageAcc,Svc=svmclassifier(X,y)\n",
    "Sum_of_Acc_Dtree=sum(AverageAcc)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc_Dtree/length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayesClassifier(Data1,Data2):\n",
    "    Test_size=[0.30,0.25,0.21,0.22,0.33,0.36,0.42,0.45,0.34]\n",
    "    Random_state=[525478,7505,32578,3257,2567,4789,8547,657,42]\n",
    "    AverageAccuracy=[]\n",
    "    k=0\n",
    "    print('/'*60)\n",
    "    for i in Test_size:\n",
    "        for j in Random_state:\n",
    "            print('/'*60)\n",
    "            print(\"The Test_size\",i,\"and random state is\",j) \n",
    "            X_train,X_test,y_train,y_test=train_test_split(Data1,Data2,test_size=i,random_state=j)\n",
    "            GNB=GaussianNB()\n",
    "            predictModel=GNB.fit(X_train,y_train)\n",
    "            predictions=predictModel.predict(X_test)\n",
    "            print(metrics.classification_report(y_test, predictions))\n",
    "            print(metrics.confusion_matrix(y_test, predictions))\n",
    "            F1score=metrics.classification_report(y_test, predictions).split()[-2]\n",
    "            F1=float(F1score)\n",
    "            AverageAccuracy.append(F1)\n",
    "            k=k+1\n",
    "            print(\"Accuracy is \",F1score)\n",
    "    return(k,AverageAccuracy,GNB)             \n",
    "                                       \n",
    "                       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      1.00      0.90        66\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.41      0.50      0.45        80\n",
      "weighted avg       0.68      0.82      0.75        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 66]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      0.98      0.90        66\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.41      0.49      0.45        80\n",
      "weighted avg       0.68      0.81      0.74        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 1 65]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.82      1.00      0.90        66\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.41      0.50      0.45        80\n",
      "weighted avg       0.68      0.82      0.75        80\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 66]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      0.99      0.90        67\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.42      0.49      0.45        80\n",
      "weighted avg       0.70      0.82      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 1 66]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.84      1.00      0.91        67\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.42      0.50      0.46        80\n",
      "weighted avg       0.70      0.84      0.76        80\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 67]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.3 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.79      1.00      0.88        63\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.39      0.50      0.44        80\n",
      "weighted avg       0.62      0.79      0.69        80\n",
      "\n",
      "[[ 0 17]\n",
      " [ 0 63]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.84      1.00      0.91        56\n",
      "\n",
      "    accuracy                           0.84        67\n",
      "   macro avg       0.42      0.50      0.46        67\n",
      "weighted avg       0.70      0.84      0.76        67\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0 56]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.82      1.00      0.90        55\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.41      0.50      0.45        67\n",
      "weighted avg       0.67      0.82      0.74        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 55]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.87      1.00      0.93        58\n",
      "\n",
      "    accuracy                           0.87        67\n",
      "   macro avg       0.43      0.50      0.46        67\n",
      "weighted avg       0.75      0.87      0.80        67\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 58]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.82      0.98      0.89        55\n",
      "\n",
      "    accuracy                           0.81        67\n",
      "   macro avg       0.41      0.49      0.45        67\n",
      "weighted avg       0.67      0.81      0.73        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 1 54]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.82      1.00      0.90        55\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.41      0.50      0.45        67\n",
      "weighted avg       0.67      0.82      0.74        67\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 55]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.80      0.98      0.88        54\n",
      "\n",
      "    accuracy                           0.79        67\n",
      "   macro avg       0.40      0.49      0.44        67\n",
      "weighted avg       0.65      0.79      0.71        67\n",
      "\n",
      "[[ 0 13]\n",
      " [ 1 53]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.82        67\n",
      "   macro avg       0.42      0.49      0.45        67\n",
      "weighted avg       0.70      0.82      0.75        67\n",
      "\n",
      "[[ 0 11]\n",
      " [ 1 55]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.22         8\n",
      "           1       0.89      1.00      0.94        59\n",
      "\n",
      "    accuracy                           0.90        67\n",
      "   macro avg       0.95      0.56      0.58        67\n",
      "weighted avg       0.91      0.90      0.86        67\n",
      "\n",
      "[[ 1  7]\n",
      " [ 0 59]]\n",
      "Accuracy is  0.86\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.25 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.78      1.00      0.87        52\n",
      "\n",
      "    accuracy                           0.78        67\n",
      "   macro avg       0.39      0.50      0.44        67\n",
      "weighted avg       0.60      0.78      0.68        67\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 52]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.82      1.00      0.90        46\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.41      0.50      0.45        56\n",
      "weighted avg       0.67      0.82      0.74        56\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.82      1.00      0.90        46\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.41      0.50      0.45        56\n",
      "weighted avg       0.67      0.82      0.74        56\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 46]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.86      1.00      0.92        48\n",
      "\n",
      "    accuracy                           0.86        56\n",
      "   macro avg       0.43      0.50      0.46        56\n",
      "weighted avg       0.73      0.86      0.79        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 48]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      0.98      0.90        47\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.42      0.49      0.45        56\n",
      "weighted avg       0.70      0.82      0.76        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 1 46]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.80      1.00      0.89        45\n",
      "\n",
      "    accuracy                           0.80        56\n",
      "   macro avg       0.40      0.50      0.45        56\n",
      "weighted avg       0.65      0.80      0.72        56\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0 45]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.86      1.00      0.92        48\n",
      "\n",
      "    accuracy                           0.86        56\n",
      "   macro avg       0.43      0.50      0.46        56\n",
      "weighted avg       0.73      0.86      0.79        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 48]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      0.98      0.90        47\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.42      0.49      0.45        56\n",
      "weighted avg       0.70      0.82      0.76        56\n",
      "\n",
      "[[ 0  9]\n",
      " [ 1 46]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.86      1.00      0.92        48\n",
      "\n",
      "    accuracy                           0.86        56\n",
      "   macro avg       0.43      0.50      0.46        56\n",
      "weighted avg       0.73      0.86      0.79        56\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 48]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.21 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.76      0.98      0.86        43\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.38      0.49      0.43        56\n",
      "weighted avg       0.59      0.75      0.66        56\n",
      "\n",
      "[[ 0 13]\n",
      " [ 1 42]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.81      1.00      0.90        48\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.41      0.50      0.45        59\n",
      "weighted avg       0.66      0.81      0.73        59\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0 48]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.83      1.00      0.91        49\n",
      "\n",
      "    accuracy                           0.83        59\n",
      "   macro avg       0.42      0.50      0.45        59\n",
      "weighted avg       0.69      0.83      0.75        59\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0 49]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.85      1.00      0.92        50\n",
      "\n",
      "    accuracy                           0.85        59\n",
      "   macro avg       0.42      0.50      0.46        59\n",
      "weighted avg       0.72      0.85      0.78        59\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 50]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.79      0.98      0.88        47\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.40      0.49      0.44        59\n",
      "weighted avg       0.63      0.78      0.70        59\n",
      "\n",
      "[[ 0 12]\n",
      " [ 1 46]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.80      1.00      0.89        47\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.40      0.50      0.44        59\n",
      "weighted avg       0.63      0.80      0.71        59\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0 47]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.84      0.98      0.91        50\n",
      "\n",
      "    accuracy                           0.83        59\n",
      "   macro avg       0.42      0.49      0.45        59\n",
      "weighted avg       0.72      0.83      0.77        59\n",
      "\n",
      "[[ 0  9]\n",
      " [ 1 49]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.81      0.98      0.89        48\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.41      0.49      0.44        59\n",
      "weighted avg       0.66      0.80      0.72        59\n",
      "\n",
      "[[ 0 11]\n",
      " [ 1 47]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.86      1.00      0.93        51\n",
      "\n",
      "    accuracy                           0.86        59\n",
      "   macro avg       0.43      0.50      0.46        59\n",
      "weighted avg       0.75      0.86      0.80        59\n",
      "\n",
      "[[ 0  8]\n",
      " [ 0 51]]\n",
      "Accuracy is  0.80\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.22 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.76      1.00      0.87        45\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.38      0.50      0.43        59\n",
      "weighted avg       0.58      0.76      0.66        59\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 45]]\n",
      "Accuracy is  0.66\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.82      1.00      0.90        72\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.67      0.82      0.74        88\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 72]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.80      1.00      0.89        70\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.40      0.50      0.44        88\n",
      "weighted avg       0.63      0.80      0.70        88\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 70]]\n",
      "Accuracy is  0.70\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.85      1.00      0.92        75\n",
      "\n",
      "    accuracy                           0.85        88\n",
      "   macro avg       0.43      0.50      0.46        88\n",
      "weighted avg       0.73      0.85      0.78        88\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 75]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.99      0.90        73\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.41      0.49      0.45        88\n",
      "weighted avg       0.69      0.82      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 1 72]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.84      1.00      0.91        74\n",
      "\n",
      "    accuracy                           0.84        88\n",
      "   macro avg       0.42      0.50      0.46        88\n",
      "weighted avg       0.71      0.84      0.77        88\n",
      "\n",
      "[[ 0 14]\n",
      " [ 0 74]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      1.00      0.91        73\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.69      0.83      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.99      0.90        73\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.41      0.49      0.45        88\n",
      "weighted avg       0.69      0.82      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 1 72]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      1.00      0.91        73\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.41      0.50      0.45        88\n",
      "weighted avg       0.69      0.83      0.75        88\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.33 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.77      1.00      0.87        68\n",
      "\n",
      "    accuracy                           0.77        88\n",
      "   macro avg       0.39      0.50      0.44        88\n",
      "weighted avg       0.60      0.77      0.67        88\n",
      "\n",
      "[[ 0 20]\n",
      " [ 0 68]]\n",
      "Accuracy is  0.67\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      1.00      0.91        80\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.42      0.50      0.45        96\n",
      "weighted avg       0.69      0.83      0.76        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 80]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.80      1.00      0.89        77\n",
      "\n",
      "    accuracy                           0.80        96\n",
      "   macro avg       0.40      0.50      0.45        96\n",
      "weighted avg       0.64      0.80      0.71        96\n",
      "\n",
      "[[ 0 19]\n",
      " [ 0 77]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.85      0.98      0.91        82\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.43      0.49      0.45        96\n",
      "weighted avg       0.73      0.83      0.78        96\n",
      "\n",
      "[[ 0 14]\n",
      " [ 2 80]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      0.99      0.90        80\n",
      "\n",
      "    accuracy                           0.82        96\n",
      "   macro avg       0.42      0.49      0.45        96\n",
      "weighted avg       0.69      0.82      0.75        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 1 79]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      1.00      0.91        80\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.42      0.50      0.45        96\n",
      "weighted avg       0.69      0.83      0.76        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 80]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      1.00      0.92        81\n",
      "\n",
      "    accuracy                           0.84        96\n",
      "   macro avg       0.42      0.50      0.46        96\n",
      "weighted avg       0.71      0.84      0.77        96\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 81]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      0.99      0.91        81\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.42      0.49      0.45        96\n",
      "weighted avg       0.71      0.83      0.77        96\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 15]\n",
      " [ 1 80]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.83      0.99      0.90        80\n",
      "\n",
      "    accuracy                           0.82        96\n",
      "   macro avg       0.42      0.49      0.45        96\n",
      "weighted avg       0.69      0.82      0.75        96\n",
      "\n",
      "[[ 0 16]\n",
      " [ 1 79]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.36 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.78      1.00      0.88        75\n",
      "\n",
      "    accuracy                           0.78        96\n",
      "   macro avg       0.39      0.50      0.44        96\n",
      "weighted avg       0.61      0.78      0.69        96\n",
      "\n",
      "[[ 0 21]\n",
      " [ 0 75]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.11      0.20        18\n",
      "           1       0.85      1.00      0.92        94\n",
      "\n",
      "    accuracy                           0.86       112\n",
      "   macro avg       0.93      0.56      0.56       112\n",
      "weighted avg       0.88      0.86      0.81       112\n",
      "\n",
      "[[ 2 16]\n",
      " [ 0 94]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.80      1.00      0.89        90\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.40      0.50      0.45       112\n",
      "weighted avg       0.65      0.80      0.72       112\n",
      "\n",
      "[[ 0 22]\n",
      " [ 0 90]]\n",
      "Accuracy is  0.72\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      0.99      0.91        95\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.42      0.49      0.46       112\n",
      "weighted avg       0.72      0.84      0.77       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 1 94]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      0.99      0.91        95\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.42      0.49      0.46       112\n",
      "weighted avg       0.72      0.84      0.77       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 1 94]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.82      1.00      0.90        92\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.41      0.50      0.45       112\n",
      "weighted avg       0.67      0.82      0.74       112\n",
      "\n",
      "[[ 0 20]\n",
      " [ 0 92]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.84      0.99      0.91        94\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.42      0.49      0.45       112\n",
      "weighted avg       0.70      0.83      0.76       112\n",
      "\n",
      "[[ 0 18]\n",
      " [ 1 93]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.85      0.98      0.91        95\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.42      0.49      0.45       112\n",
      "weighted avg       0.72      0.83      0.77       112\n",
      "\n",
      "[[ 0 17]\n",
      " [ 2 93]]\n",
      "Accuracy is  0.77\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.12      0.17        17\n",
      "           1       0.86      0.96      0.91        95\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.60      0.54      0.54       112\n",
      "weighted avg       0.78      0.83      0.79       112\n",
      "\n",
      "[[ 2 15]\n",
      " [ 4 91]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.42 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.79      1.00      0.88        88\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.39      0.50      0.44       112\n",
      "weighted avg       0.62      0.79      0.69       112\n",
      "\n",
      "[[ 0 24]\n",
      " [ 0 88]]\n",
      "Accuracy is  0.69\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.17        21\n",
      "           1       0.84      1.00      0.91        99\n",
      "\n",
      "    accuracy                           0.84       120\n",
      "   macro avg       0.92      0.55      0.54       120\n",
      "weighted avg       0.87      0.84      0.78       120\n",
      "\n",
      "[[ 2 19]\n",
      " [ 0 99]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.82      1.00      0.90        98\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.41      0.50      0.45       120\n",
      "weighted avg       0.67      0.82      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 0 98]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.83      0.98      0.90       100\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.42      0.49      0.45       120\n",
      "weighted avg       0.69      0.82      0.75       120\n",
      "\n",
      "[[ 0 20]\n",
      " [ 2 98]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.86      0.98      0.91       103\n",
      "\n",
      "    accuracy                           0.84       120\n",
      "   macro avg       0.43      0.49      0.46       120\n",
      "weighted avg       0.73      0.84      0.78       120\n",
      "\n",
      "[[  0  17]\n",
      " [  2 101]]\n",
      "Accuracy is  0.78\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.82      0.99      0.89        98\n",
      "\n",
      "    accuracy                           0.81       120\n",
      "   macro avg       0.41      0.49      0.45       120\n",
      "weighted avg       0.67      0.81      0.73       120\n",
      "\n",
      "[[ 0 22]\n",
      " [ 1 97]]\n",
      "Accuracy is  0.73\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.84      0.98      0.90       101\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.42      0.49      0.45       120\n",
      "weighted avg       0.71      0.82      0.76       120\n",
      "\n",
      "[[ 0 19]\n",
      " [ 2 99]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.83      0.98      0.90       100\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.42      0.49      0.45       120\n",
      "weighted avg       0.69      0.82      0.75       120\n",
      "\n",
      "[[ 0 20]\n",
      " [ 2 98]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.12      0.17        17\n",
      "           1       0.87      0.96      0.91       103\n",
      "\n",
      "    accuracy                           0.84       120\n",
      "   macro avg       0.60      0.54      0.54       120\n",
      "weighted avg       0.79      0.84      0.81       120\n",
      "\n",
      "[[ 2 15]\n",
      " [ 4 99]]\n",
      "Accuracy is  0.81\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.45 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.78      1.00      0.87        93\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.39      0.50      0.44       120\n",
      "weighted avg       0.60      0.78      0.68       120\n",
      "\n",
      "[[ 0 27]\n",
      " [ 0 93]]\n",
      "Accuracy is  0.68\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 525478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.82      1.00      0.90        75\n",
      "\n",
      "    accuracy                           0.82        91\n",
      "   macro avg       0.41      0.50      0.45        91\n",
      "weighted avg       0.68      0.82      0.74        91\n",
      "\n",
      "[[ 0 16]\n",
      " [ 0 75]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.80      1.00      0.89        73\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.40      0.50      0.45        91\n",
      "weighted avg       0.64      0.80      0.71        91\n",
      "\n",
      "[[ 0 18]\n",
      " [ 0 73]]\n",
      "Accuracy is  0.71\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 32578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.86      1.00      0.92        78\n",
      "\n",
      "    accuracy                           0.86        91\n",
      "   macro avg       0.43      0.50      0.46        91\n",
      "weighted avg       0.73      0.86      0.79        91\n",
      "\n",
      "[[ 0 13]\n",
      " [ 0 78]]\n",
      "Accuracy is  0.79\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.82      0.99      0.90        75\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.41      0.49      0.45        91\n",
      "weighted avg       0.68      0.81      0.74        91\n",
      "\n",
      "[[ 0 16]\n",
      " [ 1 74]]\n",
      "Accuracy is  0.74\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 2567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      1.00      0.91        76\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.42      0.50      0.46        91\n",
      "weighted avg       0.70      0.84      0.76        91\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 76]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 4789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      1.00      0.91        76\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.42      0.50      0.46        91\n",
      "weighted avg       0.70      0.84      0.76        91\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 76]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test_size 0.34 and random state is 8547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.83      0.99      0.90        76\n",
      "\n",
      "    accuracy                           0.82        91\n",
      "   macro avg       0.42      0.49      0.45        91\n",
      "weighted avg       0.70      0.82      0.75        91\n",
      "\n",
      "[[ 0 15]\n",
      " [ 1 75]]\n",
      "Accuracy is  0.75\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.84      1.00      0.91        76\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.42      0.50      0.46        91\n",
      "weighted avg       0.70      0.84      0.76        91\n",
      "\n",
      "[[ 0 15]\n",
      " [ 0 76]]\n",
      "Accuracy is  0.76\n",
      "////////////////////////////////////////////////////////////\n",
      "The Test_size 0.34 and random state is 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.78      1.00      0.88        71\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.39      0.50      0.44        91\n",
      "weighted avg       0.61      0.78      0.68        91\n",
      "\n",
      "[[ 0 20]\n",
      " [ 0 71]]\n",
      "Accuracy is  0.68\n",
      "The Average of All acuracies 0.7475308641975309\n"
     ]
    }
   ],
   "source": [
    "length,AverageAcc,GNB=NaiveBayesClassifier(X,y)\n",
    "Sum_of_Acc_Dtree=sum(AverageAcc)\n",
    "print(\"The Average of All acuracies\",(Sum_of_Acc_Dtree/length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6756 - accuracy: 0.8095\n",
      "Epoch 2/30\n",
      "210/210 [==============================] - 0s 461us/step - loss: 0.6481 - accuracy: 0.8095\n",
      "Epoch 3/30\n",
      "210/210 [==============================] - 0s 367us/step - loss: 0.6210 - accuracy: 0.8095\n",
      "Epoch 4/30\n",
      "210/210 [==============================] - 0s 362us/step - loss: 0.5942 - accuracy: 0.8095\n",
      "Epoch 5/30\n",
      "210/210 [==============================] - 0s 353us/step - loss: 0.5701 - accuracy: 0.8095\n",
      "Epoch 6/30\n",
      "210/210 [==============================] - 0s 388us/step - loss: 0.5492 - accuracy: 0.8095\n",
      "Epoch 7/30\n",
      "210/210 [==============================] - 0s 354us/step - loss: 0.5328 - accuracy: 0.8095\n",
      "Epoch 8/30\n",
      "210/210 [==============================] - 0s 363us/step - loss: 0.5207 - accuracy: 0.8095\n",
      "Epoch 9/30\n",
      "210/210 [==============================] - 0s 361us/step - loss: 0.5113 - accuracy: 0.8095\n",
      "Epoch 10/30\n",
      "210/210 [==============================] - 0s 363us/step - loss: 0.5052 - accuracy: 0.8095\n",
      "Epoch 11/30\n",
      "210/210 [==============================] - 0s 350us/step - loss: 0.4997 - accuracy: 0.8095\n",
      "Epoch 12/30\n",
      "210/210 [==============================] - 0s 352us/step - loss: 0.4966 - accuracy: 0.8095\n",
      "Epoch 13/30\n",
      "210/210 [==============================] - 0s 366us/step - loss: 0.4939 - accuracy: 0.8095\n",
      "Epoch 14/30\n",
      "210/210 [==============================] - 0s 381us/step - loss: 0.4920 - accuracy: 0.8095\n",
      "Epoch 15/30\n",
      "210/210 [==============================] - 0s 360us/step - loss: 0.4908 - accuracy: 0.8095\n",
      "Epoch 16/30\n",
      "210/210 [==============================] - 0s 371us/step - loss: 0.4897 - accuracy: 0.8095\n",
      "Epoch 17/30\n",
      "210/210 [==============================] - 0s 363us/step - loss: 0.4889 - accuracy: 0.8095\n",
      "Epoch 18/30\n",
      "210/210 [==============================] - 0s 380us/step - loss: 0.4885 - accuracy: 0.8095\n",
      "Epoch 19/30\n",
      "210/210 [==============================] - 0s 384us/step - loss: 0.4886 - accuracy: 0.8095\n",
      "Epoch 20/30\n",
      "210/210 [==============================] - 0s 366us/step - loss: 0.4877 - accuracy: 0.8095\n",
      "Epoch 21/30\n",
      "210/210 [==============================] - 0s 351us/step - loss: 0.4877 - accuracy: 0.8095\n",
      "Epoch 22/30\n",
      "210/210 [==============================] - 0s 400us/step - loss: 0.4873 - accuracy: 0.8095\n",
      "Epoch 23/30\n",
      "210/210 [==============================] - 0s 370us/step - loss: 0.4872 - accuracy: 0.8095\n",
      "Epoch 24/30\n",
      "210/210 [==============================] - 0s 349us/step - loss: 0.4878 - accuracy: 0.8095\n",
      "Epoch 25/30\n",
      "210/210 [==============================] - 0s 357us/step - loss: 0.4871 - accuracy: 0.8095\n",
      "Epoch 26/30\n",
      "210/210 [==============================] - 0s 357us/step - loss: 0.4868 - accuracy: 0.8095\n",
      "Epoch 27/30\n",
      "210/210 [==============================] - 0s 353us/step - loss: 0.4873 - accuracy: 0.8095\n",
      "Epoch 28/30\n",
      "210/210 [==============================] - 0s 366us/step - loss: 0.4868 - accuracy: 0.8095\n",
      "Epoch 29/30\n",
      "210/210 [==============================] - 0s 357us/step - loss: 0.4866 - accuracy: 0.8095\n",
      "Epoch 30/30\n",
      "210/210 [==============================] - 0s 382us/step - loss: 0.4865 - accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.21,random_state=458)\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=15, input_dim=5, kernel_initializer='uniform', activation='sigmoid'))\n",
    "classifier.add(Dense(units=5, kernel_initializer='uniform', activation='sigmoid'))\n",
    "classifier.add(Dense(units=3, kernel_initializer='uniform', activation='sigmoid'))\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "ANNModel=classifier.fit(X_train,y_train,batch_size=5,epochs=30,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANNModel.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictprob=classifier.predict(X_test)\n",
    "Loantestdata=pd.DataFrame(data=X_test, columns=Predictorvar)\n",
    "Loantestdata['TrueLoanStatus']=y_test\n",
    "Loantestdata['prdictedprobability']=Predictprob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilitythreshold(inpdata):\n",
    "    if(inpdata>0.2):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loantestdata['predictedprediction']=Loantestdata['prdictedprobability'].apply(probabilitythreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.88      1.00      0.93        49\n",
      "\n",
      "    accuracy                           0.88        56\n",
      "   macro avg       0.44      0.50      0.47        56\n",
      "weighted avg       0.77      0.88      0.82        56\n",
      "\n",
      "[[ 0  7]\n",
      " [ 0 49]]\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Loantestdata['TrueLoanStatus'],Loantestdata['predictedprediction']))\n",
    "print(metrics.confusion_matrix(Loantestdata['TrueLoanStatus'],Loantestdata['predictedprediction']))      \n",
    "print(metrics.classification_report(Loantestdata['TrueLoanStatus'],Loantestdata['predictedprediction']).split()[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Education</th>\n",
       "      <th>TrueLoanStatus</th>\n",
       "      <th>prdictedprobability</th>\n",
       "      <th>predictedprediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2816.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3806.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2417.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1667.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2791.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.798921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3053.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Property_Area  CoapplicantIncome  LoanAmount  Credit_History  Education  \\\n",
       "0             3.0                0.0       160.0             1.0        1.0   \n",
       "1             2.0             5625.0       187.0             1.0        1.0   \n",
       "2             1.0             3167.0       165.0             1.0        1.0   \n",
       "3             2.0             2223.0       150.0             1.0        1.0   \n",
       "4             2.0             1032.0        26.0             1.0        1.0   \n",
       "5             2.0             2816.0       113.0             1.0        1.0   \n",
       "6             2.0             1387.0       150.0             1.0        1.0   \n",
       "7             1.0             1833.0       180.0             1.0        1.0   \n",
       "8             2.0                0.0        76.0             1.0        1.0   \n",
       "9             3.0             2917.0       161.0             1.0        1.0   \n",
       "10            3.0             1560.0        90.0             1.0        1.0   \n",
       "11            3.0                0.0       138.0             1.0        1.0   \n",
       "12            2.0                0.0       116.0             1.0        1.0   \n",
       "13            3.0                0.0        60.0             1.0        1.0   \n",
       "14            2.0             1851.0        50.0             1.0        1.0   \n",
       "15            2.0             1775.0       131.0             1.0        1.0   \n",
       "16            3.0             1398.0        85.0             1.0        1.0   \n",
       "17            3.0              240.0       253.0             1.0        1.0   \n",
       "18            2.0             3806.0       151.0             1.0        1.0   \n",
       "19            3.0                0.0       118.0             1.0        1.0   \n",
       "20            3.0             1522.0       104.0             1.0        1.0   \n",
       "21            3.0             2417.0       136.0             1.0        1.0   \n",
       "22            2.0              997.0        50.0             1.0        1.0   \n",
       "23            2.0                0.0       120.0             1.0        1.0   \n",
       "24            2.0                0.0        70.0             1.0        1.0   \n",
       "25            3.0             2569.0       173.0             1.0        1.0   \n",
       "26            1.0             1800.0       135.0             1.0        1.0   \n",
       "27            3.0             1213.0        47.0             1.0        1.0   \n",
       "28            3.0                0.0       141.0             1.0        1.0   \n",
       "29            2.0             1667.0       114.0             1.0        1.0   \n",
       "30            1.0             5500.0       216.0             1.0        1.0   \n",
       "31            2.0             3167.0       200.0             1.0        1.0   \n",
       "32            3.0             2250.0       180.0             1.0        1.0   \n",
       "33            3.0                0.0       210.0             1.0        1.0   \n",
       "34            2.0             2034.0       122.0             1.0        1.0   \n",
       "35            3.0             1425.0        30.0             1.0        1.0   \n",
       "36            2.0             2791.0       144.0             1.0        1.0   \n",
       "37            1.0                0.0       140.0             1.0        1.0   \n",
       "38            3.0             1803.0        96.0             1.0        1.0   \n",
       "39            2.0                0.0        96.0             1.0        1.0   \n",
       "40            1.0             3750.0       187.0             1.0        1.0   \n",
       "41            1.0             4300.0       121.0             1.0        1.0   \n",
       "42            1.0             2500.0       140.0             1.0        1.0   \n",
       "43            3.0                0.0       134.0             1.0        1.0   \n",
       "44            3.0             2134.0        88.0             1.0        1.0   \n",
       "45            2.0                0.0        81.0             1.0        1.0   \n",
       "46            3.0                0.0       244.0             1.0        1.0   \n",
       "47            3.0             2067.0       210.0             1.0        1.0   \n",
       "48            3.0             1459.0        95.0             1.0        1.0   \n",
       "49            3.0                0.0        94.0             1.0        1.0   \n",
       "50            1.0             3053.0        89.0             1.0        1.0   \n",
       "51            2.0             5625.0       255.0             1.0        1.0   \n",
       "52            2.0                0.0       175.0             1.0        1.0   \n",
       "53            2.0             2004.0       250.0             1.0        1.0   \n",
       "54            2.0                0.0       115.0             1.0        1.0   \n",
       "55            2.0             1459.0       144.0             1.0        1.0   \n",
       "\n",
       "    TrueLoanStatus  prdictedprobability  predictedprediction  \n",
       "0                0             0.800527                    1  \n",
       "1                1             0.808864                    1  \n",
       "2                1             0.808864                    1  \n",
       "3                1             0.808864                    1  \n",
       "4                1             0.808864                    1  \n",
       "5                1             0.808864                    1  \n",
       "6                1             0.808864                    1  \n",
       "7                1             0.808864                    1  \n",
       "8                1             0.799610                    1  \n",
       "9                1             0.808864                    1  \n",
       "10               1             0.808864                    1  \n",
       "11               0             0.799989                    1  \n",
       "12               1             0.800293                    1  \n",
       "13               1             0.798377                    1  \n",
       "14               1             0.808864                    1  \n",
       "15               1             0.808864                    1  \n",
       "16               1             0.808864                    1  \n",
       "17               1             0.808842                    1  \n",
       "18               1             0.808864                    1  \n",
       "19               1             0.799485                    1  \n",
       "20               1             0.808864                    1  \n",
       "21               1             0.808864                    1  \n",
       "22               1             0.808864                    1  \n",
       "23               1             0.800374                    1  \n",
       "24               1             0.799545                    1  \n",
       "25               0             0.808864                    1  \n",
       "26               0             0.808864                    1  \n",
       "27               1             0.808864                    1  \n",
       "28               1             0.800064                    1  \n",
       "29               1             0.808864                    1  \n",
       "30               1             0.808864                    1  \n",
       "31               1             0.808864                    1  \n",
       "32               1             0.808864                    1  \n",
       "33               1             0.801564                    1  \n",
       "34               1             0.808864                    1  \n",
       "35               1             0.808864                    1  \n",
       "36               1             0.808864                    1  \n",
       "37               1             0.801480                    1  \n",
       "38               1             0.808864                    1  \n",
       "39               1             0.799912                    1  \n",
       "40               1             0.808864                    1  \n",
       "41               1             0.808864                    1  \n",
       "42               1             0.808864                    1  \n",
       "43               0             0.799888                    1  \n",
       "44               1             0.808864                    1  \n",
       "45               1             0.799675                    1  \n",
       "46               0             0.802089                    1  \n",
       "47               1             0.808864                    1  \n",
       "48               1             0.808864                    1  \n",
       "49               0             0.798921                    1  \n",
       "50               1             0.808864                    1  \n",
       "51               1             0.808864                    1  \n",
       "52               1             0.801468                    1  \n",
       "53               1             0.808864                    1  \n",
       "54               1             0.800273                    1  \n",
       "55               1             0.808864                    1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loantestdata.tail(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Dependents'={'1':1,'0':0,'2':2,'3+':3} Education ={'Graduate':1,'Not Graduate':2} 'Self_Employed ={'Yes':1,'No':0} Loan_Status={'Y':1,'N':0} Property_Area ={'Rural':1,'Semiurban':2,'Urban':3}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Reading the Test data And preprocessing it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_test=pd.read_csv('C:/Users/user/Desktop/IVY WORK BOOK/PYTHON/Python Datasets/Classification Datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LP001015</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LP001022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LP001031</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LP001035</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LP001051</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001015   Male     Yes          0      Graduate            No   \n",
       "1  LP001022   Male     Yes          1      Graduate            No   \n",
       "2  LP001031   Male     Yes          2      Graduate            No   \n",
       "3  LP001035   Male     Yes          2      Graduate            No   \n",
       "4  LP001051   Male      No          0  Not Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5720                  0       110.0             360.0   \n",
       "1             3076               1500       126.0             360.0   \n",
       "2             5000               1800       208.0             360.0   \n",
       "3             2340               2546       100.0             360.0   \n",
       "4             3276                  0        78.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area  \n",
       "0             1.0         Urban  \n",
       "1             1.0         Urban  \n",
       "2             1.0         Urban  \n",
       "3             NaN         Urban  \n",
       "4             1.0         Urban  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_test['Credit_History']=loan_test['Credit_History'].interpolate(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              367\n",
       "Gender                 2\n",
       "Married                2\n",
       "Dependents             4\n",
       "Education              2\n",
       "Self_Employed          2\n",
       "ApplicantIncome      314\n",
       "CoapplicantIncome    194\n",
       "LoanAmount           148\n",
       "Loan_Amount_Term      12\n",
       "Credit_History         2\n",
       "Property_Area          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LP001015</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LP001022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LP001031</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LP001051</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>LP001054</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2165</td>\n",
       "      <td>3422</td>\n",
       "      <td>152.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>LP002969</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2269</td>\n",
       "      <td>2167</td>\n",
       "      <td>99.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>LP002971</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4009</td>\n",
       "      <td>1777</td>\n",
       "      <td>113.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>LP002975</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4158</td>\n",
       "      <td>709</td>\n",
       "      <td>115.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>LP002986</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2393</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>LP002989</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID Gender Married  Dependents  Education  Self_Employed  \\\n",
       "0    LP001015   Male     Yes         0.0          1            0.0   \n",
       "1    LP001022   Male     Yes         1.0          1            0.0   \n",
       "2    LP001031   Male     Yes         2.0          1            0.0   \n",
       "4    LP001051   Male      No         0.0          2            0.0   \n",
       "5    LP001054   Male     Yes         0.0          2            1.0   \n",
       "..        ...    ...     ...         ...        ...            ...   \n",
       "361  LP002969   Male     Yes         1.0          1            0.0   \n",
       "362  LP002971   Male     Yes         3.0          2            1.0   \n",
       "363  LP002975   Male     Yes         0.0          1            0.0   \n",
       "365  LP002986   Male     Yes         0.0          1            0.0   \n",
       "366  LP002989   Male      No         0.0          1            1.0   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5720                  0       110.0             360.0   \n",
       "1               3076               1500       126.0             360.0   \n",
       "2               5000               1800       208.0             360.0   \n",
       "4               3276                  0        78.0             360.0   \n",
       "5               2165               3422       152.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "361             2269               2167        99.0             360.0   \n",
       "362             4009               1777       113.0             360.0   \n",
       "363             4158                709       115.0             360.0   \n",
       "365             5000               2393       158.0             360.0   \n",
       "366             9200                  0        98.0             180.0   \n",
       "\n",
       "     Credit_History  Property_Area  \n",
       "0               1.0              3  \n",
       "1               1.0              3  \n",
       "2               1.0              3  \n",
       "4               1.0              3  \n",
       "5               1.0              3  \n",
       "..              ...            ...  \n",
       "361             1.0              2  \n",
       "362             1.0              3  \n",
       "363             1.0              3  \n",
       "365             1.0              1  \n",
       "366             1.0              1  \n",
       "\n",
       "[289 rows x 12 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>367</td>\n",
       "      <td>367</td>\n",
       "      <td>367</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>367</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>LP002420</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>1</td>\n",
       "      <td>291</td>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847411</td>\n",
       "      <td>1.228883</td>\n",
       "      <td>0.103542</td>\n",
       "      <td>4805.599455</td>\n",
       "      <td>1569.577657</td>\n",
       "      <td>136.427793</td>\n",
       "      <td>342.332425</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>2.079019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.080699</td>\n",
       "      <td>0.420687</td>\n",
       "      <td>0.305082</td>\n",
       "      <td>4910.685399</td>\n",
       "      <td>2334.232099</td>\n",
       "      <td>61.481857</td>\n",
       "      <td>65.208104</td>\n",
       "      <td>0.372780</td>\n",
       "      <td>0.824337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3786.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5060.000000</td>\n",
       "      <td>2430.500000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72529.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Loan_ID Gender Married  Dependents   Education  Self_Employed  \\\n",
       "count        367    367     367  367.000000  367.000000     367.000000   \n",
       "unique       367      2       2         NaN         NaN            NaN   \n",
       "top     LP002420   Male     Yes         NaN         NaN            NaN   \n",
       "freq           1    291     233         NaN         NaN            NaN   \n",
       "mean         NaN    NaN     NaN    0.847411    1.228883       0.103542   \n",
       "std          NaN    NaN     NaN    1.080699    0.420687       0.305082   \n",
       "min          NaN    NaN     NaN    0.000000    1.000000       0.000000   \n",
       "25%          NaN    NaN     NaN    0.000000    1.000000       0.000000   \n",
       "50%          NaN    NaN     NaN    0.000000    1.000000       0.000000   \n",
       "75%          NaN    NaN     NaN    2.000000    1.000000       0.000000   \n",
       "max          NaN    NaN     NaN    3.000000    2.000000       1.000000   \n",
       "\n",
       "        ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count        367.000000         367.000000  367.000000        367.000000   \n",
       "unique              NaN                NaN         NaN               NaN   \n",
       "top                 NaN                NaN         NaN               NaN   \n",
       "freq                NaN                NaN         NaN               NaN   \n",
       "mean        4805.599455        1569.577657  136.427793        342.332425   \n",
       "std         4910.685399        2334.232099   61.481857         65.208104   \n",
       "min            0.000000           0.000000   28.000000          6.000000   \n",
       "25%         2864.000000           0.000000  101.000000        360.000000   \n",
       "50%         3786.000000        1025.000000  125.000000        360.000000   \n",
       "75%         5060.000000        2430.500000  158.000000        360.000000   \n",
       "max        72529.000000       24000.000000  550.000000        480.000000   \n",
       "\n",
       "        Credit_History  Property_Area  \n",
       "count       367.000000     367.000000  \n",
       "unique             NaN            NaN  \n",
       "top                NaN            NaN  \n",
       "freq               NaN            NaN  \n",
       "mean          0.833787       2.079019  \n",
       "std           0.372780       0.824337  \n",
       "min           0.000000       1.000000  \n",
       "25%           1.000000       1.000000  \n",
       "50%           1.000000       2.000000  \n",
       "75%           1.000000       3.000000  \n",
       "max           1.000000       3.000000  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependents              2.0\n",
      "Education               0.0\n",
      "Self_Employed           0.0\n",
      "ApplicantIncome      2196.0\n",
      "CoapplicantIncome    2430.5\n",
      "LoanAmount             57.0\n",
      "Loan_Amount_Term        0.0\n",
      "Credit_History          0.0\n",
      "Property_Area           2.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Q1=loan_test.quantile(0.25)\n",
    "Q3=loan_test.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 12)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_test=loan_test[~((loan_test<(Q1-1.5*IQR))|(loan_test>(Q3+1.5*IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 12)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
       "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selcols=['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History', 'Property_Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predvariable=['Property_Area','CoapplicantIncome','LoanAmount','Credit_History','Education']\n",
    "\n",
    "\n",
    "Test_Value=loan_test[Predvariable].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testprobability=classifier.predict(Test_Value)\n",
    "LoanTestingData=pd.DataFrame(data=loan_test,columns=Selcols)\n",
    "LoanTestingData['Testprobabilitytest']=Testprobability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilitythresholdonTest(inpdata1):\n",
    "    if(inpdata1>0.5):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoanTestingData['Testprediction']=LoanTestingData['Testprobabilitytest'].apply(probabilitythresholdonTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2370cf264c8>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LoanTestingData.groupby('Testprediction').size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Testprobabilitytest</th>\n",
       "      <th>Testprediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>LP002212</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2166</td>\n",
       "      <td>2166</td>\n",
       "      <td>108.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>LP002257</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2545</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.796273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>LP002264</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2553</td>\n",
       "      <td>1768</td>\n",
       "      <td>102.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>LP002270</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>3809</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>LP002279</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2412</td>\n",
       "      <td>2755</td>\n",
       "      <td>130.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>LP002310</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7600</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>LP002311</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2157</td>\n",
       "      <td>1788</td>\n",
       "      <td>104.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>LP002344</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3510</td>\n",
       "      <td>828</td>\n",
       "      <td>105.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>LP002389</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4028</td>\n",
       "      <td>0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.798138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>LP002394</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4010</td>\n",
       "      <td>1025</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>LP002397</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3719</td>\n",
       "      <td>1585</td>\n",
       "      <td>114.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>LP002400</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3833</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>LP002402</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3333</td>\n",
       "      <td>4288</td>\n",
       "      <td>160.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>LP002412</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3007</td>\n",
       "      <td>3725</td>\n",
       "      <td>151.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>LP002415</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1850</td>\n",
       "      <td>4583</td>\n",
       "      <td>81.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>LP002420</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2982</td>\n",
       "      <td>1550</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>LP002425</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3417</td>\n",
       "      <td>738</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>LP002440</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2995</td>\n",
       "      <td>1120</td>\n",
       "      <td>184.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>LP002441</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3579</td>\n",
       "      <td>3308</td>\n",
       "      <td>138.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>LP002471</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3508</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>LP002523</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2773</td>\n",
       "      <td>1497</td>\n",
       "      <td>108.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>LP002542</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6500</td>\n",
       "      <td>0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.797783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>LP002554</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2166</td>\n",
       "      <td>2057</td>\n",
       "      <td>122.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>LP002561</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798578</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>LP002566</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5530</td>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.797633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>LP002584</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1972</td>\n",
       "      <td>4347</td>\n",
       "      <td>106.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>LP002592</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4983</td>\n",
       "      <td>0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.797735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>LP002593</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8333</td>\n",
       "      <td>4000</td>\n",
       "      <td>155.5</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>LP002599</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3667</td>\n",
       "      <td>2000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>LP002604</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3166</td>\n",
       "      <td>2833</td>\n",
       "      <td>145.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>LP002614</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6478</td>\n",
       "      <td>0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>LP002639</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4120</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>LP002711</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>700</td>\n",
       "      <td>96.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>LP002744</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6825</td>\n",
       "      <td>0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>LP002745</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3708</td>\n",
       "      <td>4700</td>\n",
       "      <td>132.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>LP002746</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5314</td>\n",
       "      <td>0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.797831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>LP002759</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>LP002769</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4283</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>LP002781</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3083</td>\n",
       "      <td>2738</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>LP002782</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2667</td>\n",
       "      <td>1542</td>\n",
       "      <td>148.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>LP002793</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5333</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>LP002805</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5041</td>\n",
       "      <td>700</td>\n",
       "      <td>150.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>LP002816</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3500</td>\n",
       "      <td>1658</td>\n",
       "      <td>104.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>LP002823</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5509</td>\n",
       "      <td>0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>LP002843</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4709</td>\n",
       "      <td>0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>LP002849</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1516</td>\n",
       "      <td>1951</td>\n",
       "      <td>35.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>LP002850</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.795448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>LP002856</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2292</td>\n",
       "      <td>1558</td>\n",
       "      <td>119.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>LP002870</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4700</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.796435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>LP002876</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6858</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>LP002907</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5817</td>\n",
       "      <td>910</td>\n",
       "      <td>109.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>LP002920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5119</td>\n",
       "      <td>3769</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>LP002932</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7603</td>\n",
       "      <td>1213</td>\n",
       "      <td>197.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>LP002935</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3791</td>\n",
       "      <td>1936</td>\n",
       "      <td>85.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>LP002952</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.795874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>LP002962</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>2667</td>\n",
       "      <td>152.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>LP002969</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2269</td>\n",
       "      <td>2167</td>\n",
       "      <td>99.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>LP002975</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4158</td>\n",
       "      <td>709</td>\n",
       "      <td>115.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>LP002980</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3250</td>\n",
       "      <td>1993</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>LP002986</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2393</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married  Dependents  Education  Self_Employed  \\\n",
       "220  LP002212    Male     Yes         0.0          1            0.0   \n",
       "225  LP002257  Female      No         0.0          1            0.0   \n",
       "226  LP002264    Male     Yes         0.0          1            0.0   \n",
       "227  LP002270    Male     Yes         1.0          1            0.0   \n",
       "228  LP002279    Male      No         0.0          1            0.0   \n",
       "233  LP002310  Female      No         1.0          1            0.0   \n",
       "234  LP002311  Female     Yes         0.0          1            0.0   \n",
       "242  LP002344    Male     Yes         0.0          1            0.0   \n",
       "252  LP002389  Female      No         1.0          1            0.0   \n",
       "253  LP002394    Male     Yes         2.0          1            0.0   \n",
       "254  LP002397  Female     Yes         1.0          1            0.0   \n",
       "256  LP002400  Female     Yes         0.0          1            0.0   \n",
       "257  LP002402    Male     Yes         0.0          1            0.0   \n",
       "258  LP002412    Male     Yes         0.0          1            0.0   \n",
       "259  LP002415  Female      No         1.0          1            0.0   \n",
       "261  LP002420    Male     Yes         0.0          1            0.0   \n",
       "262  LP002425    Male      No         0.0          1            0.0   \n",
       "264  LP002440    Male     Yes         2.0          1            0.0   \n",
       "265  LP002441    Male      No         2.0          1            0.0   \n",
       "269  LP002471    Male      No         0.0          1            0.0   \n",
       "275  LP002523    Male     Yes         3.0          1            0.0   \n",
       "276  LP002542    Male     Yes         0.0          1            0.0   \n",
       "280  LP002554    Male      No         0.0          1            0.0   \n",
       "281  LP002561    Male     Yes         0.0          1            0.0   \n",
       "282  LP002566  Female      No         0.0          1            0.0   \n",
       "287  LP002584    Male      No         0.0          1            0.0   \n",
       "288  LP002592    Male      No         0.0          1            0.0   \n",
       "289  LP002593    Male     Yes         1.0          1            0.0   \n",
       "290  LP002599    Male     Yes         0.0          1            0.0   \n",
       "291  LP002604    Male     Yes         2.0          1            0.0   \n",
       "296  LP002614  Female      No         0.0          1            0.0   \n",
       "299  LP002639    Male     Yes         2.0          1            0.0   \n",
       "304  LP002711    Male     Yes         0.0          1            0.0   \n",
       "308  LP002744    Male     Yes         1.0          1            0.0   \n",
       "309  LP002745    Male     Yes         0.0          1            0.0   \n",
       "310  LP002746    Male      No         0.0          1            0.0   \n",
       "313  LP002759    Male     Yes         2.0          1            0.0   \n",
       "316  LP002769  Female     Yes         0.0          1            0.0   \n",
       "319  LP002781    Male      No         0.0          1            0.0   \n",
       "320  LP002782    Male     Yes         1.0          1            0.0   \n",
       "324  LP002793    Male     Yes         0.0          1            0.0   \n",
       "327  LP002805    Male     Yes         2.0          1            0.0   \n",
       "329  LP002816    Male     Yes         1.0          1            0.0   \n",
       "330  LP002823    Male     Yes         0.0          1            0.0   \n",
       "333  LP002843  Female     Yes         0.0          1            0.0   \n",
       "334  LP002849    Male     Yes         0.0          1            0.0   \n",
       "335  LP002850    Male      No         2.0          1            0.0   \n",
       "337  LP002856    Male     Yes         0.0          1            0.0   \n",
       "343  LP002870    Male     Yes         1.0          1            0.0   \n",
       "344  LP002876    Male      No         0.0          1            0.0   \n",
       "352  LP002907    Male     Yes         0.0          1            0.0   \n",
       "353  LP002920    Male     Yes         0.0          1            0.0   \n",
       "355  LP002932    Male     Yes         3.0          1            0.0   \n",
       "356  LP002935    Male     Yes         1.0          1            0.0   \n",
       "357  LP002952    Male      No         0.0          1            0.0   \n",
       "359  LP002962    Male      No         0.0          1            0.0   \n",
       "361  LP002969    Male     Yes         1.0          1            0.0   \n",
       "363  LP002975    Male     Yes         0.0          1            0.0   \n",
       "364  LP002980    Male      No         0.0          1            0.0   \n",
       "365  LP002986    Male     Yes         0.0          1            0.0   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "220             2166               2166       108.0             360.0   \n",
       "225             2545                  0        74.0             360.0   \n",
       "226             2553               1768       102.0             360.0   \n",
       "227             3436               3809       100.0             360.0   \n",
       "228             2412               2755       130.0             360.0   \n",
       "233             7600                  0        92.0             360.0   \n",
       "234             2157               1788       104.0             360.0   \n",
       "242             3510                828       105.0             360.0   \n",
       "252             4028                  0       131.0             360.0   \n",
       "253             4010               1025       120.0             360.0   \n",
       "254             3719               1585       114.0             360.0   \n",
       "256             3833                  0        92.0             360.0   \n",
       "257             3333               4288       160.0             360.0   \n",
       "258             3007               3725       151.0             360.0   \n",
       "259             1850               4583        81.0             360.0   \n",
       "261             2982               1550       110.0             360.0   \n",
       "262             3417                738       100.0             360.0   \n",
       "264             2995               1120       184.0             360.0   \n",
       "265             3579               3308       138.0             360.0   \n",
       "269             3508                  0        99.0             360.0   \n",
       "275             2773               1497       108.0             360.0   \n",
       "276             6500                  0       144.0             360.0   \n",
       "280             2166               2057       122.0             360.0   \n",
       "281             5000                  0       126.0             360.0   \n",
       "282             5530                  0       135.0             360.0   \n",
       "287             1972               4347       106.0             360.0   \n",
       "288             4983                  0       141.0             360.0   \n",
       "289             8333               4000       155.5             360.0   \n",
       "290             3667               2000       170.0             360.0   \n",
       "291             3166               2833       145.0             360.0   \n",
       "296             6478                  0       108.0             360.0   \n",
       "299             4120                  0       128.0             360.0   \n",
       "304             2600                700        96.0             360.0   \n",
       "308             6825                  0       162.0             360.0   \n",
       "309             3708               4700       132.0             360.0   \n",
       "310             5314                  0       147.0             360.0   \n",
       "313             5000                  0       149.0             360.0   \n",
       "316             4283                  0       120.0             360.0   \n",
       "319             3083               2738       120.0             360.0   \n",
       "320             2667               1542       148.0             360.0   \n",
       "324             5333                  0        90.0             360.0   \n",
       "327             5041                700       150.0             360.0   \n",
       "329             3500               1658       104.0             360.0   \n",
       "330             5509                  0       143.0             360.0   \n",
       "333             4709                  0       113.0             360.0   \n",
       "334             1516               1951        35.0             360.0   \n",
       "335             2400                  0        46.0             360.0   \n",
       "337             2292               1558       119.0             360.0   \n",
       "343             4700                  0        80.0             360.0   \n",
       "344             6858                  0       176.0             360.0   \n",
       "352             5817                910       109.0             360.0   \n",
       "353             5119               3769       120.0             360.0   \n",
       "355             7603               1213       197.0             360.0   \n",
       "356             3791               1936        85.0             360.0   \n",
       "357             2500                  0        60.0             360.0   \n",
       "359             4000               2667       152.0             360.0   \n",
       "361             2269               2167        99.0             360.0   \n",
       "363             4158                709       115.0             360.0   \n",
       "364             3250               1993       126.0             360.0   \n",
       "365             5000               2393       158.0             360.0   \n",
       "\n",
       "     Credit_History  Property_Area  Testprobabilitytest  Testprediction  \n",
       "220             1.0              3             0.801068               1  \n",
       "225             1.0              3             0.796273               1  \n",
       "226             1.0              3             0.801068               1  \n",
       "227             1.0              1             0.801068               1  \n",
       "228             1.0              1             0.801068               1  \n",
       "233             1.0              2             0.797444               1  \n",
       "234             1.0              3             0.801068               1  \n",
       "242             1.0              2             0.801068               1  \n",
       "252             1.0              2             0.798138               1  \n",
       "253             1.0              3             0.801068               1  \n",
       "254             1.0              3             0.801068               1  \n",
       "256             1.0              1             0.798065               1  \n",
       "257             1.0              3             0.801068               1  \n",
       "258             1.0              1             0.801068               1  \n",
       "259             1.0              1             0.801068               1  \n",
       "261             1.0              2             0.801068               1  \n",
       "262             1.0              1             0.801068               1  \n",
       "264             1.0              1             0.801068               1  \n",
       "265             1.0              2             0.801068               1  \n",
       "269             1.0              1             0.798183               1  \n",
       "275             1.0              2             0.801068               1  \n",
       "276             1.0              3             0.797783               1  \n",
       "280             1.0              2             0.801068               1  \n",
       "281             1.0              1             0.798578               1  \n",
       "282             1.0              3             0.797633               1  \n",
       "287             1.0              1             0.801068               1  \n",
       "288             1.0              3             0.797735               1  \n",
       "289             1.0              3             0.801068               1  \n",
       "290             1.0              2             0.801068               1  \n",
       "291             1.0              3             0.801068               1  \n",
       "296             1.0              2             0.797757               1  \n",
       "299             1.0              1             0.798604               1  \n",
       "304             1.0              2             0.801068               1  \n",
       "308             1.0              1             0.798978               1  \n",
       "309             1.0              2             0.801068               1  \n",
       "310             1.0              3             0.797831               1  \n",
       "313             1.0              1             0.798848               1  \n",
       "316             1.0              1             0.798498               1  \n",
       "319             1.0              3             0.801068               1  \n",
       "320             1.0              1             0.801068               1  \n",
       "324             1.0              1             0.798030               1  \n",
       "327             1.0              3             0.801068               1  \n",
       "329             1.0              2             0.801068               1  \n",
       "330             1.0              1             0.798783               1  \n",
       "333             1.0              2             0.797846               1  \n",
       "334             1.0              2             0.801068               1  \n",
       "335             1.0              3             0.795448               1  \n",
       "337             1.0              3             0.801068               1  \n",
       "343             1.0              3             0.796435               1  \n",
       "344             1.0              1             0.799104               1  \n",
       "352             1.0              3             0.801068               1  \n",
       "353             1.0              1             0.801068               1  \n",
       "355             1.0              3             0.801068               1  \n",
       "356             1.0              3             0.801068               1  \n",
       "357             1.0              3             0.795874               1  \n",
       "359             1.0              2             0.801068               1  \n",
       "361             1.0              2             0.801068               1  \n",
       "363             1.0              3             0.801068               1  \n",
       "364             1.0              2             0.801068               1  \n",
       "365             1.0              1             0.801068               1  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoanTestingData.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Dependents'={'1':1,'0':0,'2':2,'3+':3} Education ={'Graduate':1,'Not Graduate':2} 'Self_Employed ={'Yes':1,'No':0} Loan_Status={'Y':1,'N':0} Property_Area ={'Rural':1,'Semiurban':2,'Urban':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoanTestingDataxl=pd.DataFrame(LoanTestingData,columns=Selcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter('pandas_simple.xlsx', engine='xlsxwriter')\n",
    "\n",
    "LoanTestingData.to_excel(writer,'sheet1')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
